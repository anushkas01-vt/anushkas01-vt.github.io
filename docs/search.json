[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Clustering with K-Means\nIdentifying the most dominant colours in an image using K-Means Clustering.\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport cv2\nimport numpy as np\n\nRGB_values = pd.DataFrame(columns=['R', 'G', 'B'])\nimage = cv2.imread(\"beach.jpg\")\n\n# get image shape\nnumPixels = image.shape\nprint(numPixels)\n\ny, x = numPixels[0], numPixels[1]\nfor i, j in zip(range(y), range(x)):\n    BGR_values = image[i, j]\n    RGB_values.loc[len(RGB_values)] = np.flip(BGR_values)\n\nRGB_values.head(10)\n\n(1200, 1920, 3)\n\n\n\n\n\n\n\n\n\nR\nG\nB\n\n\n\n\n0\n161\n195\n240\n\n\n1\n161\n195\n240\n\n\n2\n160\n194\n239\n\n\n3\n159\n193\n238\n\n\n4\n159\n193\n238\n\n\n5\n158\n192\n237\n\n\n6\n157\n191\n237\n\n\n7\n157\n191\n237\n\n\n8\n156\n190\n236\n\n\n9\n156\n190\n236\n\n\n\n\n\n\n\n\n# plot the RGB values on a graph\nfrom mpl_toolkits import mplot3d\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport colorsys\n\n# normalize the RGB values\nRGB_values = RGB_values/255\n\nRGB_values.head(5)\n\nRGB_unique = RGB_values.drop_duplicates()\nRGB_unique = list(RGB_unique.to_numpy())\nRGB_unique.sort(key=lambda rgb: colorsys.rgb_to_hls(*rgb))\ncmap_RGB = matplotlib.colors.ListedColormap(RGB_unique, \"Colours in the image\")\ncmap_RGB\n\nColours in the image  underbad over \n\n\n\nfig = plt.figure(figsize = (15,15))\nax = fig.add_subplot(111, projection='3d')\n# Data for three-dimensional scattered points\nzdata = RGB_values['B']\nxdata = RGB_values['R']\nydata = RGB_values['G']\nax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='hsv');\n\nax.set_xlabel('R')\nax.set_ylabel('G')\nax.set_zlabel('B')\nax.set_title('RGB value of input image');\n\n\n\n\n\nimport sklearn.cluster\nfrom yellowbrick.cluster import KElbowVisualizer\nmodel = KElbowVisualizer(sklearn.cluster.KMeans(), k=10)\nmodel.fit(RGB_values.to_numpy());\nmodel.show();\nelbow_value = model.elbow_value_\n\n\n\n\n\nimport math\nimport random\n\nx = RGB_values.to_numpy()\ncentroid1 = x[random.randint(0,len(x))]\ncentroids = []\ncentroids.append([centroid1])\nnumClusters = elbow_value\n\n# pick cluster centroid with probability proportional to the centroid1\ndistance = [math.dist(centroid1, x[i])**2 for i in range(len(x))]\n\nfor i in range(1, numClusters):\n    # so above has just chosen the highest dist ones, but we still want random choice where the probability is depending on the distance\n    # also, normalize dists\n    # calculates probabilities\n    prob = distance/np.sum(distance)\n    # choose next centroid with probability proportional to distance squared\n    new_centroid = x[np.random.choice(range(len(x)), size=1, p=prob)]\n    centroids.append(new_centroid)\n    # update distances between newly chosen centroid and other points now\n    distance = [math.dist(new_centroid[0], x[i])**2 for i in range(len(x))]\n\n\ncentroids = np.array(centroids)\nsorted_points = [[] for _ in range(4)]\nfor point in x:\n    dists = [math.dist(point, np.squeeze(i)) for i in centroids]\n    centroid_idx = np.argmin(dists)\n    sorted_points[centroid_idx].append(point)\n    \n# new centroid is mean of the points in each cluster\nprev_centroids = centroids[:]\n\n# sorted points is of size num_clusters, num_points in each cluster\ncentroids = [np.mean(cluster, axis=0) for cluster in sorted_points]\n\n# make sure that none of the centroid values are nan\nfor points in range(len(centroids)):\n    if np.isnan(centroids[points]).any():\n        centroids[points] = prev_centroids[points]\n\n\ncolors = []\n\nfor i in centroids:\n    r, g, b = i\n    colors.append((\n    r,\n    g,\n    b\n    ))\n\nfig = plt.figure(figsize = (15,15))\nax = fig.add_subplot(111, projection='3d')\n\n\n# plot the sorted clusters\n\nfor i in range(len(sorted_points)):\n    a, b, c = zip(*sorted_points[i])\n    ax.scatter(a, b, c, s = 40 , color = colors[i], marker = 'o', label = \"cluster \"+str(i))\n    label = \"centroid of cluster\" if i == len(sorted_points)-1 else \"\"\n    ax.scatter(colors[i][0], colors[i][1], colors[i][2], s = 100 , marker = 'x', color = [0,0,0], label = label)\n\nax.set_xlabel('R')\nax.set_ylabel('G')\nax.set_zlabel('B')\nax.legend()\nplt.show()\n\n\n\n\n\nplt.grid(False)\nplt.imshow([colors])\nplt.show()\n\n\n\n\n\ntotal_points = len(RGB_values.to_numpy())\nlabels = ['Colour' + str(i+1) for i in range(len(colors))]\nsizes = [len(sorted_points[i])/total_points for i in range(len(sorted_points))]\nfig, ax = plt.subplots()\nax.pie(sizes,\n       colors=colors, autopct='%1.1f%%', pctdistance=1.15);\n\n\n\n\nDone!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CS5805",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "codeFiles/Probability_Theory.html",
    "href": "codeFiles/Probability_Theory.html",
    "title": "CS5805",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nCoding Baum-Welch Algorithm from scratch\n\ndef forward(states, sequence, a, b, pi, key):\n    N = len(states)\n    T = len(sequence)\n    pi = pi[key] # prob of state i, since 2 states, let's half it be 0.5, 0.5 initially\n    i = key # holds the first state\n\n    # Pseudocount to handle zeros\n    pseudocount = 1e-100\n    # for all possible states, and the first actual state (alpha)\n    # i.e. alpha i for all i has been caluclated given yt\n    alpha = np.zeros((N, T))\n    alpha[:,0] = pi * b[:,int(sequence[0])] + pseudocount\n\n\n    # next, we have to do iterations to calculate alpha at different times t\n    # we need all alpha values since it is going to be summed up to calculate gamma\n    \n    for t in range(1, T):\n        for j in range(N):\n            alpha[j][t] = sum(alpha[i][t-1]*a[i][j]*b[j][int(sequence[t])] for i in range(N)) + pseudocount\n\n    return alpha\n\n\ndef backward(states, sequence, a, b):\n    N = len(states)\n    T = len(sequence)\n    beta = np.zeros((N, T))\n\n    # Pseudocount to handle zeros\n    pseudocount = 1e-100\n\n    # Initialization\n    beta[:, -1] = 1  # Set the last column to 1\n\n    # Recursion\n    for t in range(T - 2, -1, -1):\n        for i in range(N):\n            beta[i, t] = sum(a[i, j] * b[j, int(sequence[t + 1])] * beta[j, t + 1] for j in range(N)) + pseudocount\n\n    return beta\n\n\ndef train(a, b, pi, sequence, states, key, n_iterations = 100, tol=1e-6):\n    #Baum-Welch algorithm for HMM\n    # calculate gamma, xi, and then update a and b parameters\n    N = len(states)\n    T = len(sequence)\n    \n    # M is the number of possible observations i.e. number of columns\n    M = b.shape[1]\n\n    prev_log_likelihood = 0\n\n    for iteration in range(n_iterations):\n        alpha = forward(states, sequence, a, b, pi, key)\n        beta = backward(states, sequence, a, b)\n\n        print(f\"Alpha: {alpha}\")\n        print(f\"Beta:{beta}\")\n\n        # Pseudocount to handle zeros\n        pseudocount = 1e-100\n        gamma = alpha * beta\n        # print(gamma)\n        denominator = np.sum(gamma, axis=0, keepdims=True) # same for all i\n        gamma = gamma/denominator + pseudocount\n\n        print(f\"gamma:{gamma}\") \n\n        xi = np.zeros((N, N, T - 1))\n\n        for i in range(N):\n            for j in range(N):\n                for t in range(T - 1):\n                    numerator = alpha[i, t] * a[i, j] * b[j, int(sequence[t + 1])] * beta[j, t + 1]\n                    denominator = np.sum(alpha[k, t] * a[k, l] * b[l, int(sequence[t + 1])] * beta[l, t + 1] for k in range(N) for l in range(N))\n                    xi[i, j, t] = (numerator / denominator) + pseudocount\n\n        print(f\"Xi: {xi}\")\n\n\n        # update a and b\n        # M-step\n        '''\n        sequence == k creates a boolean array of the same length as sequence, where each element is True if the corresponding element in sequence is equal to k, and False otherwise.\n    mask = (sequence == k) assigns this boolean array to the variable mask.\n    In the context of the Baum-Welch algorithm or similar algorithms for Hidden Markov Models (HMMs), this kind of mask is often used to select specific observations in the computation of probabilities. For example, \n    it might be used to sum over only the observations that match a particular value, which is relevant when updating the emission matrix b.\n        '''\n        # a = (np.sum(xi, axis=2) + pseudocount)/ np.sum(gamma[:, :-1], axis=1, keepdims=True) \n        for i in range(N):  # N is the number of states\n            for j in range(N):  # N is the number of states\n                numerator = np.sum(xi[i, j, :])\n                denominator = np.sum(gamma[i, :])\n                a[i, j] = (numerator+pseudocount) / (denominator+pseudocount) \n\n\n        b = np.zeros((N, M))\n        # print(gamma.shape)\n        gamma_sum = np.sum(gamma, axis=1)\n        \n        obs = []\n        for i in sequence:\n            obs.append(int(i))\n        obs = np.array(obs)\n\n        for j in range(N):\n            for k in range(M):\n                mask = (obs==k) # for indicative function i.e. 1 if observed = yt, else 0\n                b[j, k] = (np.sum(gamma[j]*mask)+ pseudocount) / (np.sum(gamma[j]) + pseudocount) \n        \n\n        # Normalize rows to ensure each row sums to 1.0\n        a = a / np.sum(a, axis=1)[:, np.newaxis]\n        b = b / np.sum(b, axis=1)[:, np.newaxis]\n\n        print(f\"a = {a}, b = {b}\")\n\n        # Log Likelihood Calculation\n        log_likelihood = np.sum(np.log(np.sum(alpha, axis=0)))\n\n        # Convergence Check\n        if np.abs(log_likelihood - prev_log_likelihood) &lt; tol:\n            print(f\"Converged after {iteration + 1} iterations.\")\n            break\n\n        prev_log_likelihood = log_likelihood\n\n    return a, b, pi\n\n\ndef predict(sequence, states, a, b, pi):\n    # Makes use of the viterbi algorithm to predict best path\n    # Initialize Variables\n    T = len(sequence)\n    N = len(states)\n\n    # Pseudocount to handle zeros\n    pseudocount = 1e-100\n\n    viterbi_table = np.zeros((N, T)) # delta\n    backpointer = np.zeros((N, T)) # psi\n\n    # Initialization step, for t = 0\n    print(int(sequence[0]))\n    viterbi_table[:, 0] = pi * b[:, int(sequence[0])] + pseudocount\n\n    # Calculate Probabilities\n    for t in range(1, T):\n        for s in range(N):\n            \n            max_prob = max(viterbi_table[prev_s][t-1] * a[prev_s][s] for prev_s in range(N)) * b[s][int(sequence[t])] \n            viterbi_table[s][t] = max_prob + pseudocount\n            backpointer[s][t] = np.argmax([viterbi_table[prev_s][t-1] * a[prev_s][s]for prev_s in range(N)])\n\n    #Traceback and Find Best Path\n    best_path = []\n    last_state = np.argmax(viterbi_table[:, -1])\n\n    best_path.append(last_state)\n    best_prob = 1.0\n    for t in range(T-2, -1, -1):\n        last_state = last_state = np.argmax(viterbi_table[:, t])\n        best_prob *= (viterbi_table[last_state, t] + pseudocount)\n        best_path.append(last_state) # i.e. add to start of list\n\n        \n    return best_path\n\nExplain this, prepare some more datasets, read them from csv files etc at least shows data prep etc Talk about Baum-Welch algorithm and viterbi and show code for it (even though it does not work. Can add a small note towards the end of the blog and say you are still debugging its implementation that would be cute)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom hmmlearn import hmm\n\ngen_model = hmm.CategoricalHMM(n_components=2, random_state=99)\n\n\ngen_model.startprob_ = np.array([1.0, 0.0])\n\ngen_model.transmat_ = np.array([[0.95, 0.05],\n                                [0.1, 0.9]])\n\ngen_model.emissionprob_ = \\\n    np.array([[1 / 6, 1 / 6, 1 / 6, 1 / 6, 1 / 6, 1 / 6],\n              [1 / 10, 1 / 10, 1 / 10, 1 / 10, 1 / 10, 1 / 2]])\n\n# simulate the loaded dice rolls\nrolls, gen_states = gen_model.sample(30000)\n\nprint(\"ROLLS\",rolls)\n\n# plot states over time, let's just look at the first rolls for clarity\nfig, ax = plt.subplots()\nax.plot(gen_states[:500])\nax.set_title('States over time')\nax.set_xlabel('Time (# of rolls)')\nax.set_ylabel('State')\nfig.show()\n\n# plot rolls for the fair and loaded states\nfig, ax = plt.subplots()\nax.hist(rolls[gen_states == 0], label='fair', alpha=0.5,\n        bins=np.arange(7) - 0.5, density=True)\nax.hist(rolls[gen_states == 1], label='loaded', alpha=0.5,\n        bins=np.arange(7) - 0.5, density=True)\nax.set_title('Roll probabilities by state')\nax.set_xlabel('Count')\nax.set_ylabel('Roll')\nax.legend()\nfig.show()\n\n# %%\n# Now, let's see if we can recover our hidden states, transmission matrix\n# and emission probabilities.\n\n# split our data into training and validation sets (50/50 split)\nX_train = rolls[:rolls.shape[0] // 2]\nX_validate = rolls[rolls.shape[0] // 2:]\n\n# check optimal score\ngen_score = gen_model.score(X_validate)\n\nbest_score = best_model = None\nn_fits = 50\nnp.random.seed(13)\nfor idx in range(n_fits):\n    model = hmm.CategoricalHMM(\n        n_components=2, random_state=idx,\n        init_params='se')  # don't init transition, set it below\n    # we need to initialize with random transition matrix probabilities\n    # because the default is an even likelihood transition\n    # we know transitions are rare (otherwise the casino would get caught!)\n    # so let's have an Dirichlet random prior with an alpha value of\n    # (0.1, 0.9) to enforce our assumption transitions happen roughly 10%\n    # of the time\n    model.transmat_ = np.array([np.random.dirichlet([0.9, 0.1]),\n                                np.random.dirichlet([0.1, 0.9])])\n    model.fit(X_train)\n    score = model.score(X_validate)\n    print(f'Model #{idx}\\tScore: {score}')\n    if best_score is None or score &gt; best_score:\n        best_model = model\n        best_score = score\n\nprint(f'Generated score: {gen_score}\\nBest score:      {best_score}')\n\n# use the Viterbi algorithm to predict the most likely sequence of states\n# given the model\nstates = best_model.predict(rolls)\n\n# plot our recovered states compared to generated (aim 1)\nfig, ax = plt.subplots()\nax.plot(gen_states[:500], label='generated')\nax.plot(states[:500] + 1.5, label='recovered')\nax.set_yticks([])\nax.set_title('States compared to generated')\nax.set_xlabel('Time (# rolls)')\nax.set_xlabel('State')\nax.legend()\nfig.show()\n\n# %%\n# Let's check our learned transition probabilities and see if they match.\n\nprint(f'Transmission Matrix Generated:\\n{gen_model.transmat_.round(3)}\\n\\n'\n      f'Transmission Matrix Recovered:\\n{best_model.transmat_.round(3)}\\n\\n')\n\n# %%\n# Finally, let's see if we can tell how the die is loaded.\n\nprint(f'Emission Matrix Generated:\\n{gen_model.emissionprob_.round(3)}\\n\\n'\n      f'Emission Matrix Recovered:\\n{best_model.emissionprob_.round(3)}\\n\\n')\n\n# %%\n# In this case, we were able to get very good estimates of the transition and\n# emission matrices, but decoding the states was imperfect. That's because\n# the decoding algorithm is greedy and picks the most likely series of states\n# which isn't necessarily what happens in real life. Even so, our model could\n# tell us when to watch for the loaded die and we'd have a better chance at\n# catching them red-handed.\n\n\n# Additionally, do tests with comparison so you can do confusion matrix, roc curve or something, but i feel like hmm model would be nice and confusion matrix\n# cri time"
  },
  {
    "objectID": "codeFiles/Classification.html",
    "href": "codeFiles/Classification.html",
    "title": "CS5805",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf_diabetes = pd.read_csv(\"diabetes.csv\")\n\n\ndf_diabetes.head(10)\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n5\n5\n116\n74\n0\n0\n25.6\n0.201\n30\n0\n\n\n6\n3\n78\n50\n32\n88\n31.0\n0.248\n26\n1\n\n\n7\n10\n115\n0\n0\n0\n35.3\n0.134\n29\n0\n\n\n8\n2\n197\n70\n45\n543\n30.5\n0.158\n53\n1\n\n\n9\n8\n125\n96\n0\n0\n0.0\n0.232\n54\n1\n\n\n\n\n\n\n\n\nprint(df_diabetes.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\nNone\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nf, ax = plt.subplots(figsize=(10, 8))\n\ncorr = df_diabetes.corr()\nsns.heatmap(corr,\n    cmap=sns.diverging_palette(220, 10, as_cmap=True),\n    vmin=-1.0, vmax=1.0,\n    annot = True,\n    square=True, ax=ax)\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n# data with 0 value instead of null values\ndf_diabetes.drop(columns=['Pregnancies', 'Outcome']).isin([0, 0.0]).sum()\n\nGlucose                       5\nBloodPressure                35\nSkinThickness               227\nInsulin                     374\nBMI                          11\nDiabetesPedigreeFunction      0\nAge                           0\ndtype: int64\n\n\n\n# storing outcomes in dataframe y, and storing pregnancies in a separate list temporarily\n# instead of creating a copy of another dataframe\npregnancies = df_diabetes['Pregnancies']\ny = df_diabetes['Outcome']\ndf_diabetes = df_diabetes.drop(columns=['Pregnancies', 'Outcome'])\n\n\n# making the 0 missing values into Nan values for imputing\ndf_diabetes.replace(0, np.nan, inplace=True)\nprint(f\"Number of missing values = {np.isnan(df_diabetes.to_numpy()).sum()}\")\n\nNumber of missing values = 652\n\n\n\ndf_diabetes['Pregnancies'] = pregnancies\ncolumns = df_diabetes.columns\ndf_diabetes.head(5)\n\n\n\n\n\n\n\n\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nPregnancies\n\n\n\n\n0\n148.0\n72.0\n35.0\nNaN\n33.6\n0.627\n50\n6\n\n\n1\n85.0\n66.0\n29.0\nNaN\n26.6\n0.351\n31\n1\n\n\n2\n183.0\n64.0\nNaN\nNaN\n23.3\n0.672\n32\n8\n\n\n3\n89.0\n66.0\n23.0\n94.0\n28.1\n0.167\n21\n1\n\n\n4\n137.0\n40.0\n35.0\n168.0\n43.1\n2.288\n33\n0\n\n\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\ny = y\nX = (df_diabetes).to_numpy()\n# 80-20 Train-Test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n\nscaling_x=StandardScaler()\nX_train=scaling_x.fit_transform(X_train)\nX_test_imputed=scaling_x.transform(X_test)\n\n\n# Imputing missing values using knn\n\n# knn imputation transform for the horse colic dataset\n\nfrom sklearn.impute import KNNImputer\n\n# print total missing\nprint('Missing: %d' % sum(np.isnan(X).flatten()))\n# define imputer\nimputer = KNNImputer(n_neighbors=5) # taking 5 neighbours\n# fit transform on the dataset for training and testing set\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n# print total missing\nX_trans = np.concatenate((X_train_imputed, X_test_imputed), axis=0)\nprint('Missing: %d' % sum(np.isnan(X_trans).flatten()))\n\nMissing: 652\nMissing: 0\n\n\n\ndf_diabetes_cleaned = pd.DataFrame(X_trans, columns = columns)\ndf_diabetes_cleaned.head(5)\n\n\n\n\n\n\n\n\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nPregnancies\n\n\n\n\n0\n0.478034\n-0.188555\n0.315640\n-0.421253\n0.708354\n-0.946901\n0.810205\n3.353608\n\n\n1\n-0.824024\n-0.648467\n0.695029\n-0.508571\n0.664997\n0.396130\n-0.695262\n-1.121017\n\n\n2\n-0.189688\n-0.188555\n-0.063750\n-0.615099\n-0.693521\n-0.793670\n-1.029810\n-0.822709\n\n\n3\n-0.523549\n-0.648467\n0.600182\n-0.342666\n-0.245499\n2.799765\n0.057471\n-0.524401\n\n\n4\n0.044015\n1.191181\n0.789876\n-0.047530\n0.433760\n-0.814702\n-0.360714\n-1.121017\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom pprint import pprint\nbest_preds = []\nmodel_names = []\n\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\nmodel_names.append('Support Vector Machine')\n# Define the parameter grid\nparam_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': [0.001, 0.01, 0.1, 1]}\n\n# Create an SVM model\nsvm_model = SVC()\n\n# print(\"Current params:\")\n# pprint(svm_model.get_params())\n\nsvm_model.fit(X_train_imputed, y_train)\n\n# Instantiate GridSearchCV with cross-validation\ngrid_search_svm = GridSearchCV(svm_model, param_grid, cv=3, scoring='accuracy')\n\n# Fit the model to the data and perform hyperparameter tuning\ngrid_search_svm.fit(X_train_imputed, y_train)\n\n# Print the best hyperparameters\n# print(\"Best Hyperparameters:\")\n# pprint(grid_search_svm.best_params_)\n\n# Get the best model\nbest_model_svm = grid_search_svm.best_estimator_\n\ny_pred = svm_model.predict(X_test_imputed)\ny_pred_best = best_model_svm.predict(X_test_imputed)\nprint(\"SVM without hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred)}\")\n\nprint(\"SVM with hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_best)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred_best)}\")    \n\nbest_preds.append([accuracy_score(y_test, y_pred_best), precision_score(y_test, y_pred_best), recall_score(y_test, y_pred_best), f1_score(y_test, y_pred_best)])\n\ncm = confusion_matrix(y_test, y_pred_best, labels=best_model_svm.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Diabetic', 'Diabetic'])\ndisp.plot()\nplt.show()\n\nSVM without hyperparameter tuning\nAccuracy: 0.7878787878787878\nF1 score: 0.6620689655172414\nSVM with hyperparameter tuning\nAccuracy: 0.7835497835497836\nF1 score: 0.6527777777777778\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nmodel_names.append('Random Forest')\n\nrf = RandomForestClassifier()\n# print(\"Current params:\")\n# pprint(rf.get_params())\n\nrf.fit(X_train_imputed, y_train)\n\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\n# Create the random grid\nrandom_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n               'max_features': ['auto', 'sqrt'],\n               'max_depth': max_depth,\n               'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4],\n               'bootstrap': [True, False]}\n\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train_imputed, y_train)\n\n# Print the best hyperparameters\n# print(\"Best Hyperparameters:\")\n# pprint(rf_random.best_params_)\n\n# Get the best model\nbest_model_rf = rf_random.best_estimator_\n\ny_pred = rf.predict(X_test_imputed)\ny_pred_best = best_model_rf.predict(X_test_imputed)\nprint(\"RF without hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred)}\")\n\nprint(\"RF with hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_best)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred_best)}\")    \n\nbest_preds.append([accuracy_score(y_test, y_pred_best), precision_score(y_test, y_pred_best), recall_score(y_test, y_pred_best), f1_score(y_test, y_pred_best)])\n\ncm = confusion_matrix(y_test, y_pred_best, labels=best_model_rf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Diabetic', 'Diabetic'])\ndisp.plot()\nplt.show()\n\nFitting 3 folds for each of 100 candidates, totalling 300 fits\nRF without hyperparameter tuning\nAccuracy: 0.8095238095238095\nF1 score: 0.7027027027027026\nRF with hyperparameter tuning\nAccuracy: 0.8095238095238095\nF1 score: 0.7105263157894737\n\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_names.append('Decision Tree')\n\ndt = DecisionTreeClassifier()\n\n# print(\"Current params:\")\n# pprint(dt.get_params())\n\ndt.fit(X_train_imputed, y_train)\n\nparams = {\n    'max_depth': [None, 5, 10, 15],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': range(1, 5),\n    'max_features': ['auto', 'sqrt', 'log2', None],\n    'criterion': ['gini', 'entropy'],\n}\n\ngrid_search_dt = GridSearchCV(dt, params, cv=3, scoring='accuracy')\n\n# Fit the model to the data and perform hyperparameter tuning\ngrid_search_dt.fit(X_train_imputed, y_train)\n\n# Print the best hyperparameters\n# print(\"Best Hyperparameters:\")\n# pprint(grid_search_dt.best_params_)\n\n# Get the best model\nbest_model_dt = grid_search_dt.best_estimator_\n\ny_pred = dt.predict(X_test_imputed)\ny_pred_best = best_model_dt.predict(X_test_imputed)\n\n\nprint(\"DT without hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred)}\")\n\nprint(\"DT with hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_best)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred_best)}\")    \n\nbest_preds.append([accuracy_score(y_test, y_pred_best), precision_score(y_test, y_pred_best), recall_score(y_test, y_pred_best), f1_score(y_test, y_pred_best)])\n\ncm = confusion_matrix(y_test, y_pred_best, labels=best_model_dt.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Diabetic', 'Diabetic'])\n\ndisp.plot()\nplt.show()\n\nDT without hyperparameter tuning\nAccuracy: 0.7489177489177489\nF1 score: 0.6741573033707865\nDT with hyperparameter tuning\nAccuracy: 0.696969696969697\nF1 score: 0.513888888888889\n\n\n\n\n\n\nfrom xgboost import XGBClassifier\nfrom skopt import BayesSearchCV\n\nmodel_names.append('XGBoost')\n\n# Create an XGBoost classifier\nxgb = XGBClassifier()\n\n# print(\"Current params:\")\n# pprint(xgb.get_params())\n\nxgb.fit(X_train_imputed, y_train)\n\n# Define the parameter search space\nparam_space = {\n    'max_depth': (3, 10),\n    'learning_rate': (0.01, 1.0, 'log-uniform'),\n    'n_estimators': (50, 200),\n    'min_child_weight': (1, 10),\n    'subsample': (0.1, 1.0, 'uniform'),\n    'gamma': (0.0, 1.0, 'uniform'),\n    'colsample_bytree': (0.1, 1.0, 'uniform'),\n}\n\n# Instantiate BayesSearchCV\nbayes_search_xgb = BayesSearchCV(\n    xgb,\n    param_space,\n    cv=3,  # Number of cross-validation folds\n)\n\nnp.int = np.int_\n# Fit the model to the training data and perform hyperparameter tuning\nbayes_search_xgb.fit(X_train_imputed, y_train)\n\n# Print the best hyperparameters\n# print(\"Best Hyperparameters:\")\n# pprint(bayes_search_xgb.best_params_)\n\n# Get the best model\nbest_model_xgb = bayes_search_xgb.best_estimator_\n\n\ny_pred = xgb.predict(X_test_imputed)\ny_pred_best = best_model_xgb.predict(X_test_imputed)\nprint(\"XGB without hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred)}\")\n\nprint(\"XGB with hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_best)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred_best)}\")    \n\nbest_preds.append([accuracy_score(y_test, y_pred_best), precision_score(y_test, y_pred_best), recall_score(y_test, y_pred_best), f1_score(y_test, y_pred_best)])\n\ncm = confusion_matrix(y_test, y_pred_best, labels=best_model_xgb.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Diabetic', 'Diabetic'])\ndisp.plot()\nplt.show()\n\nXGB without hyperparameter tuning\nAccuracy: 0.7316017316017316\nF1 score: 0.6219512195121951\nXGB with hyperparameter tuning\nAccuracy: 0.8138528138528138\nF1 score: 0.7295597484276729\n\n\n\n\n\n\n# tabulate their classification report\nevaluation_metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\nplt.rcParams[\"figure.figsize\"] = [30, 7]\nplt.rcParams[\"figure.autolayout\"] = True\nfig, axs = plt.subplots(1, 1)\naxs.axis('tight')\naxs.axis('off')\n\ntable1 = axs.table(cellText=best_preds,\n                      cellLoc = 'left',\n                      rowLabels = model_names,\n                      rowColours= [\"palegreen\"] * 10,\n                      colLabels=evaluation_metrics,\n                      colColours= [\"palegreen\"] * 10,\n                      loc='center')\n\n# Highlight cells with minimum value in each column\nfor col_idx, metric in enumerate(evaluation_metrics):\n    col_values = [row[col_idx] for row in best_preds]\n    max_value_idx = col_values.index(max(col_values))\n\n    # Highlight the cell with maximum value in coral color\n    table1[max_value_idx + 1, col_idx].set_facecolor(\"coral\")\n        \ntable1.auto_set_font_size(False)\ntable1.set_fontsize(14)\ntable1.scale(1, 4)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n%pip install graphviz\n\nCollecting graphviz\n  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n     ---------------------------------------- 47.0/47.0 kB 1.1 MB/s eta 0:00:00\nInstalling collected packages: graphviz\nSuccessfully installed graphviz-0.20.1\nNote: you may need to restart the kernel to use updated packages.\n\n\nWARNING: There was an error checking the latest version of pip.\n\n\n\nimport graphviz\n\n\nfrom sklearn.tree import export_graphviz\n# Export as dot file\nexport_graphviz(grid_search_dt.best_estimator_, out_file='tree.dot', \n                feature_names = df_diabetes_cleaned.columns,\n                class_names = ['Non-Diabetic', 'Diabetic'],\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\n# # Convert to png using system command (requires Graphviz)\n# from subprocess import call\n# call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# # Display in jupyter notebook\n# from IPython.display import Image\n# Image(filename = 'tree.png')\n\n\n\n!dot -Tpng {\"tree.dot\"} -o {\"tree.png\"}\n\n'dot' is not recognized as an internal or external command,\noperable program or batch file.\n\n\n\nfrom graphviz import Source\n\nSource.from_file(\"tree.dot\")\n\nExecutableNotFound: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH\n\n\n&lt;graphviz.sources.Source at 0x23bcdb11bd0&gt;\n\n\n\n%pip install scikit-optimize\n\nCollecting scikit-optimize\n  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n     ---------------------------------------- 0.0/100.3 kB ? eta -:--:--\n     ---- ----------------------------------- 10.2/100.3 kB ? eta -:--:--\n     ---- ----------------------------------- 10.2/100.3 kB ? eta -:--:--\n     ---- ----------------------------------- 10.2/100.3 kB ? eta -:--:--\n     ---- ----------------------------------- 10.2/100.3 kB ? eta -:--:--\n     ----------- ------------------------- 30.7/100.3 kB 131.3 kB/s eta 0:00:01\n     --------------- --------------------- 41.0/100.3 kB 151.3 kB/s eta 0:00:01\n     -------------------------- ---------- 71.7/100.3 kB 231.8 kB/s eta 0:00:01\n     ------------------------------------ 100.3/100.3 kB 304.1 kB/s eta 0:00:00\nRequirement already satisfied: joblib&gt;=0.11 in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\nCollecting pyaml&gt;=16.9 (from scikit-optimize)\n  Downloading pyaml-23.9.7-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy&gt;=1.13.3 in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.26.0)\nRequirement already satisfied: scipy&gt;=0.19.1 in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.11.3)\nRequirement already satisfied: scikit-learn&gt;=0.20.0 in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.3.0)\nRequirement already satisfied: PyYAML in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (from pyaml&gt;=16.9-&gt;scikit-optimize) (6.0)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (from scikit-learn&gt;=0.20.0-&gt;scikit-optimize) (2.2.0)\nDownloading pyaml-23.9.7-py3-none-any.whl (23 kB)\nInstalling collected packages: pyaml, scikit-optimize\nSuccessfully installed pyaml-23.9.7 scikit-optimize-0.9.0\nNote: you may need to restart the kernel to use updated packages.\n\n\nWARNING: There was an error checking the latest version of pip.\n\n\n\nfrom xgboost import XGBClassifier\nfrom skopt import BayesSearchCV\n\n# Create an XGBoost classifier\nxgb = XGBClassifier()\n\nprint(\"Current params:\", xgb.get_params)\n\n# Define the parameter search space\nparam_space = {\n    'max_depth': (3, 10),\n    'learning_rate': (0.01, 1.0, 'log-uniform'),\n    'n_estimators': (50, 200),\n    'min_child_weight': (1, 10),\n    'subsample': (0.1, 1.0, 'uniform'),\n    'gamma': (0.0, 1.0, 'uniform'),\n    'colsample_bytree': (0.1, 1.0, 'uniform'),\n}\n\n# Instantiate BayesSearchCV\nbayes_search_xgb = BayesSearchCV(\n    xgb,\n    param_space,\n    cv=3,  # Number of cross-validation folds\n)\n\nnp.int = np.int_\n# Fit the model to the training data and perform hyperparameter tuning\nbayes_search_xgb.fit(X_train, y_train)\n\n# Print the best hyperparameters\nprint(\"Best Hyperparameters:\", bayes_search_xgb.best_params_)\n\n# Get the best model\nbest_model_xgb = bayes_search_xgb.best_estimator_\n\n\ny_pred = xgb.fit(X_test_imputed)\ny_pred_best = best_model_xgb.fit(X_test_imputed)\nprint(\"XGB without hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred)}\")\n\nprint(\"XGB with hyperparameter tuning\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_best)}\")\nprint(f\"F1 score: {f1_score(y_test, y_pred_best)}\")    \n\nbest_preds.append([accuracy_score(y_test, y_pred_best), precision_score(y_test, y_pred_best), recall_score(y_test, y_pred_best), f1_score(y_test, y_pred_best)])\n\ncm = confusion_matrix(y_test, y_pred_best, labels=best_model_xgb.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Diabetic', 'Diabetic'])\n\n\n%pip install numpy --upgrade\n\nRequirement already satisfied: numpy in c:\\users\\anu2001\\anaconda3\\lib\\site-packages (1.26.0)\nCollecting numpy\n  Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)\n     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n     --------------------------------- ------ 51.2/61.2 kB 2.7 MB/s eta 0:00:01\n     -------------------------------------- 61.2/61.2 kB 822.1 kB/s eta 0:00:00\nDownloading numpy-1.26.2-cp310-cp310-win_amd64.whl (15.8 MB)\n   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n    --------------------------------------- 0.2/15.8 MB 4.9 MB/s eta 0:00:04\n   - -------------------------------------- 0.5/15.8 MB 5.7 MB/s eta 0:00:03\n   -- ------------------------------------- 1.2/15.8 MB 9.3 MB/s eta 0:00:02\n   ---- ----------------------------------- 1.6/15.8 MB 8.7 MB/s eta 0:00:02\n   ----- ---------------------------------- 2.3/15.8 MB 10.6 MB/s eta 0:00:02\n   ------- -------------------------------- 2.9/15.8 MB 10.9 MB/s eta 0:00:02\n   --------- ------------------------------ 3.6/15.8 MB 11.5 MB/s eta 0:00:02\n   --------- ------------------------------ 3.6/15.8 MB 11.5 MB/s eta 0:00:02\n   ------------ --------------------------- 5.0/15.8 MB 12.2 MB/s eta 0:00:01\n   ------------- -------------------------- 5.4/15.8 MB 12.0 MB/s eta 0:00:01\n   -------------- ------------------------- 5.9/15.8 MB 12.1 MB/s eta 0:00:01\n   ----------------- ---------------------- 6.8/15.8 MB 11.7 MB/s eta 0:00:01\n   ----------------- ---------------------- 6.9/15.8 MB 11.7 MB/s eta 0:00:01\n   ------------------- -------------------- 7.8/15.8 MB 11.6 MB/s eta 0:00:01\n   --------------------- ------------------ 8.4/15.8 MB 11.7 MB/s eta 0:00:01\n   ---------------------- ----------------- 8.9/15.8 MB 11.6 MB/s eta 0:00:01\n   ------------------------ --------------- 9.6/15.8 MB 11.8 MB/s eta 0:00:01\n   -------------------------- ------------- 10.3/15.8 MB 12.1 MB/s eta 0:00:01\n   --------------------------- ------------ 11.0/15.8 MB 12.6 MB/s eta 0:00:01\n   ----------------------------- ---------- 11.7/15.8 MB 13.1 MB/s eta 0:00:01\n   ------------------------------- -------- 12.3/15.8 MB 13.1 MB/s eta 0:00:01\n   -------------------------------- ------- 13.0/15.8 MB 12.8 MB/s eta 0:00:01\n   ---------------------------------- ----- 13.5/15.8 MB 12.6 MB/s eta 0:00:01\n   ------------------------------------ --- 14.2/15.8 MB 13.1 MB/s eta 0:00:01\n   ------------------------------------- -- 14.8/15.8 MB 12.6 MB/s eta 0:00:01\n   ---------------------------------------  15.5/15.8 MB 12.4 MB/s eta 0:00:01\n   ---------------------------------------  15.8/15.8 MB 12.1 MB/s eta 0:00:01\n   ---------------------------------------  15.8/15.8 MB 12.1 MB/s eta 0:00:01\n   ---------------------------------------- 15.8/15.8 MB 10.9 MB/s eta 0:00:00\nInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.0\n    Uninstalling numpy-1.26.0:\n      Successfully uninstalled numpy-1.26.0\nSuccessfully installed numpy-1.26.2\nNote: you may need to restart the kernel to use updated packages.\n\n\n  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Anu2001\\anaconda3\\Lib\\site-packages\\~umpy'.\n  You can safely remove it manually.\nWARNING: There was an error checking the latest version of pip.\n\n\n\n\n\n# Evaluate the performance on the test set\naccuracy_test = best_model.score(X_test_imputed, y_test)\nprint(\"Test Accuracy with Best Model:\", accuracy_test)\n\nBest Hyperparameters: OrderedDict([('colsample_bytree', 0.5409711145688327), ('gamma', 0.9405602407275063), ('learning_rate', 0.13424666072348485), ('max_depth', 7), ('min_child_weight', 6), ('n_estimators', 174), ('subsample', 0.5828594193918621)])\nTest Accuracy with Best Model: 1.0\n\n\n\n# compare f1 and accuracy for the hyperparameter tuning\n# then compare classification reports for the different algorithms (best version)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "codeFiles/AnomalyDetection.html",
    "href": "codeFiles/AnomalyDetection.html",
    "title": "CS5805",
    "section": "",
    "text": "from ucimlrepo import fetch_ucirepo \nimport pandas as pd\n  \n# fetch dataset \nionosphere = fetch_ucirepo(id=52) \n  \n# data (as pandas dataframes) \nX = ionosphere.data.features \ny = ionosphere.data.targets \n  \n# metadata \nprint(ionosphere.metadata) \n  \n# variable information \nprint(ionosphere.variables) \n\n{'uci_id': 52, 'name': 'Ionosphere', 'repository_url': 'https://archive.ics.uci.edu/dataset/52/ionosphere', 'data_url': 'https://archive.ics.uci.edu/static/public/52/data.csv', 'abstract': 'Classification of radar returns from the ionosphere', 'area': 'Physics and Chemistry', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 351, 'num_features': 34, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1989, 'last_updated': 'Sun Jan 01 1989', 'dataset_doi': '10.24432/C5W01B', 'creators': ['V. Sigillito', 'S. Wing', 'L. Hutton', 'K. Baker'], 'intro_paper': None, 'additional_info': {'summary': 'This radar data was collected by a system in Goose Bay, Labrador.  This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.  See the paper for more details.  The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere.  \"Bad\" returns are those that do not; their signals pass through the ionosphere.  \\r\\n\\r\\nReceived signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number.  There were 17 pulse numbers for the Goose Bay system.  Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '-- All 34 are continuous\\r\\n-- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above.  This is a binary classification task.\\r\\n', 'citation': None}}\n           name     role         type demographic description units  \\\n0    Attribute1  Feature   Continuous        None        None  None   \n1    Attribute2  Feature   Continuous        None        None  None   \n2    Attribute3  Feature   Continuous        None        None  None   \n3    Attribute4  Feature   Continuous        None        None  None   \n4    Attribute5  Feature   Continuous        None        None  None   \n5    Attribute6  Feature   Continuous        None        None  None   \n6    Attribute7  Feature   Continuous        None        None  None   \n7    Attribute8  Feature   Continuous        None        None  None   \n8    Attribute9  Feature   Continuous        None        None  None   \n9   Attribute10  Feature   Continuous        None        None  None   \n10  Attribute11  Feature   Continuous        None        None  None   \n11  Attribute12  Feature   Continuous        None        None  None   \n12  Attribute13  Feature   Continuous        None        None  None   \n13  Attribute14  Feature   Continuous        None        None  None   \n14  Attribute15  Feature   Continuous        None        None  None   \n15  Attribute16  Feature   Continuous        None        None  None   \n16  Attribute17  Feature   Continuous        None        None  None   \n17  Attribute18  Feature   Continuous        None        None  None   \n18  Attribute19  Feature   Continuous        None        None  None   \n19  Attribute20  Feature   Continuous        None        None  None   \n20  Attribute21  Feature   Continuous        None        None  None   \n21  Attribute22  Feature   Continuous        None        None  None   \n22  Attribute23  Feature   Continuous        None        None  None   \n23  Attribute24  Feature   Continuous        None        None  None   \n24  Attribute25  Feature   Continuous        None        None  None   \n25  Attribute26  Feature   Continuous        None        None  None   \n26  Attribute27  Feature   Continuous        None        None  None   \n27  Attribute28  Feature   Continuous        None        None  None   \n28  Attribute29  Feature   Continuous        None        None  None   \n29  Attribute30  Feature   Continuous        None        None  None   \n30  Attribute31  Feature   Continuous        None        None  None   \n31  Attribute32  Feature   Continuous        None        None  None   \n32  Attribute33  Feature   Continuous        None        None  None   \n33  Attribute34  Feature   Continuous        None        None  None   \n34        Class   Target  Categorical        None        None  None   \n\n   missing_values  \n0              no  \n1              no  \n2              no  \n3              no  \n4              no  \n5              no  \n6              no  \n7              no  \n8              no  \n9              no  \n10             no  \n11             no  \n12             no  \n13             no  \n14             no  \n15             no  \n16             no  \n17             no  \n18             no  \n19             no  \n20             no  \n21             no  \n22             no  \n23             no  \n24             no  \n25             no  \n26             no  \n27             no  \n28             no  \n29             no  \n30             no  \n31             no  \n32             no  \n33             no  \n34             no  \n\n\n\nprint(len(X.columns))\n\n34\n\n\n\nX.head(5) # already normalized between [-1,1] as seen\n\n\n\n\n\n\n\n\nAttribute1\nAttribute2\nAttribute3\nAttribute4\nAttribute5\nAttribute6\nAttribute7\nAttribute8\nAttribute9\nAttribute10\n...\nAttribute25\nAttribute26\nAttribute27\nAttribute28\nAttribute29\nAttribute30\nAttribute31\nAttribute32\nAttribute33\nAttribute34\n\n\n\n\n0\n1\n0\n0.99539\n-0.05889\n0.85243\n0.02306\n0.83398\n-0.37708\n1.00000\n0.03760\n...\n0.56811\n-0.51171\n0.41078\n-0.46168\n0.21266\n-0.34090\n0.42267\n-0.54487\n0.18641\n-0.45300\n\n\n1\n1\n0\n1.00000\n-0.18829\n0.93035\n-0.36156\n-0.10868\n-0.93597\n1.00000\n-0.04549\n...\n-0.20332\n-0.26569\n-0.20468\n-0.18401\n-0.19040\n-0.11593\n-0.16626\n-0.06288\n-0.13738\n-0.02447\n\n\n2\n1\n0\n1.00000\n-0.03365\n1.00000\n0.00485\n1.00000\n-0.12062\n0.88965\n0.01198\n...\n0.57528\n-0.40220\n0.58984\n-0.22145\n0.43100\n-0.17365\n0.60436\n-0.24180\n0.56045\n-0.38238\n\n\n3\n1\n0\n1.00000\n-0.45161\n1.00000\n1.00000\n0.71216\n-1.00000\n0.00000\n0.00000\n...\n1.00000\n0.90695\n0.51613\n1.00000\n1.00000\n-0.20099\n0.25682\n1.00000\n-0.32382\n1.00000\n\n\n4\n1\n0\n1.00000\n-0.02401\n0.94140\n0.06531\n0.92106\n-0.23255\n0.77152\n-0.16399\n...\n0.03286\n-0.65158\n0.13290\n-0.53206\n0.02431\n-0.62197\n-0.05707\n-0.59573\n-0.04608\n-0.65697\n\n\n\n\n5 rows × 34 columns\n\n\n\n\nfrom sklearn.decomposition import PCA\n\n#define PCA model to use\npca = PCA(n_components=len(X.columns))\n\n#fit PCA model to data\npca_fit = pca.fit(X)\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nPC_values = np.arange(pca.n_components_) + 1\nplt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.show()\n\nprint(pca.explained_variance_ratio_)\n\n\n\n\n[3.13442567e-01 1.22715916e-01 7.47531588e-02 6.93713827e-02\n 4.87451555e-02 3.67628972e-02 3.00194104e-02 2.87417744e-02\n 2.70258301e-02 2.25412044e-02 2.06320031e-02 1.83866023e-02\n 1.74260667e-02 1.64547193e-02 1.44493400e-02 1.39720397e-02\n 1.28249614e-02 1.18505458e-02 1.13257238e-02 1.08961135e-02\n 1.00825974e-02 9.50662790e-03 7.79732167e-03 7.23070868e-03\n 6.96611126e-03 6.21700612e-03 5.76370177e-03 5.19643141e-03\n 4.86322151e-03 4.29335970e-03 4.07318815e-03 3.36833665e-03\n 2.30397592e-03 6.18156468e-32]\n\n\n\nfrom sklearn.neighbors import NearestNeighbors\nnbrs = NearestNeighbors(n_neighbors=2, metric='cosine').fit(X)\ndistances, indices = nbrs.kneighbors(X)\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\n\n# Plot the k-distance graph\nplt.plot(distances)\nplt.title('k-distance plot')\nplt.xlabel('Data Point Index')\nplt.ylabel('Distance to k-th nearest neighbor')\n\n\n# Find the optimal epsilon (knee point)\nknee_point_index = np.argmax(np.diff(distances))  # Find the index with the maximum difference in distances\nepsilon = distances[knee_point_index]\nplt.axvline(x=knee_point_index, color='r', linestyle='--', label=f'Optimal Epsilon = {epsilon:.2f}')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\nfrom sklearn.cluster import DBSCAN\n\nprincipalComponents = PCA(n_components=3).fit_transform(X)\n\nprincipalDf = pd.DataFrame(data = principalComponents)\ncluster = DBSCAN(eps=epsilon).fit(principalDf)\n\n\nprincipalDf.columns=['PCA1','PCA2','PCA3']\nprincipalDf\n\n\n\n\n\n\n\n\nPCA1\nPCA2\nPCA3\n\n\n\n\n0\n-0.859333\n-0.961407\n-0.586082\n\n\n1\n0.765524\n-1.062714\n-1.397339\n\n\n2\n-1.116817\n-0.392256\n0.007988\n\n\n3\n0.981679\n0.590445\n0.478505\n\n\n4\n0.132848\n-0.788272\n-0.714253\n\n\n...\n...\n...\n...\n\n\n346\n-1.812768\n-0.085462\n0.222245\n\n\n347\n-2.047168\n0.064722\n0.374502\n\n\n348\n-2.009686\n0.007021\n0.345604\n\n\n349\n-1.878506\n-0.258263\n0.279973\n\n\n350\n-1.548783\n-0.187526\n0.217571\n\n\n\n\n351 rows × 3 columns\n\n\n\n\nimport collections\nprint(collections.Counter(cluster.labels_))\n\nCounter({0: 251, -1: 50, 1: 32, 2: 18})\n\n\n\n\n# clustering = DBSCAN().fit(project2D)\nimport seaborn as sns\nimport numpy as np\n\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.colors import ListedColormap\n\n\n# axes instance\nfig = plt.figure(figsize=(6,6))\nax = Axes3D(fig, auto_add_to_figure=False)\nfig.add_axes(ax)\n\n# get colormap from seaborn\ncmap = plt.cm.get_cmap('viridis', 2) \nx = principalDf['PCA1']\ny = principalDf['PCA2']\nz = principalDf['PCA3']\n\n# plot\nax.scatter(x, y, z, s=40, c=np.array(cluster.labels_)&gt;-1, marker='o', cmap=cmap, alpha=1)\n\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\n\nplt.show()\n# legend\n#plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n\nC:\\Users\\Anu2001\\AppData\\Local\\Temp\\ipykernel_2712\\188791831.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = plt.cm.get_cmap('viridis', 2)\n\n\n\n\n\n\ndef plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n    bool_labels = dbscan.labels_&gt;-1\n    core_mask = np.zeros_like(bool_labels, dtype=bool)\n    core_mask[dbscan.core_sample_indices_] = True\n    anomalies_mask = bool_labels == 0\n    non_core_mask = ~(core_mask | anomalies_mask)\n\n    \n    cores = dbscan.components_\n    anomalies = X[anomalies_mask]\n    non_cores = X[non_core_mask]\n\n    # axes instance\n    fig = plt.figure(figsize=(6,6))\n    ax = Axes3D(fig, auto_add_to_figure=False)\n    fig.add_axes(ax)\n    ax.scatter(cores[:, 0], cores[:, 1], cores[:, 2],\n                c=bool_labels[core_mask], marker='o', s=size)\n    ax.scatter(cores[:, 0], cores[:, 1], cores[:, 2], marker='o', s=20,\n                c=bool_labels[core_mask])\n    ax.scatter(anomalies[:, 0], anomalies[:, 1], anomalies[:, 2],\n                c=\"r\", marker=\"x\", s=100)\n    ax.scatter(non_cores[:, 0], non_cores[:, 1], non_cores[:, 2],\n                c=bool_labels[non_core_mask], marker=\"o\")\n\n    plt.title(f\"eps={dbscan.eps:.2f}, min_samples={dbscan.min_samples}\")\n    plt.grid()\n    plt.gca().set_axisbelow(True)\n\ndbscan = DBSCAN(eps=epsilon)\ndbscan.fit(principalDf)\n\nplot_dbscan(dbscan, principalDf.to_numpy(), size=100)\n\n\n\n\n\n\nprincipalDf['labels'] = cluster.labels_ &gt; -1\n\n\nsns.pairplot(data=principalDf, hue='labels')\n\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)"
  },
  {
    "objectID": "codeFiles/Clustering_K-means.html",
    "href": "codeFiles/Clustering_K-means.html",
    "title": "CS5805",
    "section": "",
    "text": "import pandas as pd\nimport cv2\nimport numpy as np\n\n\nRGB_values = pd.DataFrame(columns=['R', 'G', 'B'])\nimage = cv2.imread(\"beach.jpg\")\n\n# get image shape\nnumPixels = image.shape\nprint(numPixels)\n\ny, x = numPixels[0], numPixels[1]\nfor i, j in zip(range(y), range(x)):\n    BGR_values = image[i, j]\n    RGB_values.loc[len(RGB_values)] = np.flip(BGR_values)\n\nprint(RGB_values)\n\n(1200, 1920, 3)\n        R    G    B\n0     161  195  240\n1     161  195  240\n2     160  194  239\n3     159  193  238\n4     159  193  238\n...   ...  ...  ...\n1195   53   42   58\n1196   49   38   55\n1197   47   36   53\n1198   49   37   57\n1199   49   37   57\n\n[1200 rows x 3 columns]\n\n\n\n# plot the RGB values on a graph\nfrom mpl_toolkits import mplot3d\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nRGB_values = RGB_values/255\n\n\nRGB_values.head(5)\n\n\n\n\n\n\n\n\nR\nG\nB\n\n\n\n\n0\n0.631373\n0.764706\n0.941176\n\n\n1\n0.631373\n0.764706\n0.941176\n\n\n2\n0.627451\n0.760784\n0.937255\n\n\n3\n0.623529\n0.756863\n0.933333\n\n\n4\n0.623529\n0.756863\n0.933333\n\n\n\n\n\n\n\n\nimport colorsys\nRGB_unique = RGB_values.drop_duplicates()\nRGB_unique = list(RGB_unique.to_numpy())\nRGB_unique.sort(key=lambda rgb: colorsys.rgb_to_hls(*rgb))\ncmap_RGB = matplotlib.colors.ListedColormap(RGB_unique, \"Colours in the image\")\ncmap_RGB\n\nColours in the image  underbad over \n\n\n\nfig = plt.figure(figsize = (15,15))\nax = fig.add_subplot(111, projection='3d')\n# Data for three-dimensional scattered points\nzdata = RGB_values['B']\nxdata = RGB_values['R']\nydata = RGB_values['G']\nax.scatter3D(xdata, ydata, zdata, c=zdata, cmap='hsv');\n\nax.set_xlabel('R')\nax.set_ylabel('G')\nax.set_zlabel('B')\nax.set_title('RGB value of input image');\n\n\n\n\n\nfrom sklearn.cluster import KMeans\n\n\nfrom yellowbrick.cluster import KElbowVisualizer\nmodel = KElbowVisualizer(KMeans(), k=(2,10))\nmodel.fit(RGB_values.to_numpy());\nmodel.show();\nelbow_value = model.elbow_value_\n\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\nc:\\Users\\Anu2001\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\n\n\n# using the library\nnum_clusters = elbow_value\nkmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=\"auto\")\ny_clusters = kmeans.fit_predict(RGB_values.to_numpy())\n\n\nimport math\nimport random\n\nx = RGB_values.to_numpy()\ncentroid1 = x[random.randint(0,len(x))]\ncentroids = []\ncentroids.append([centroid1])\nnumClusters = elbow_value\n\n# pick cluster centroid with probability proportional to the centroid1\ndistance = [math.dist(centroid1, x[i])**2 for i in range(len(x))]\n\nfor i in range(1, numClusters):\n    # so above has just chosen the highest dist ones, but we still want random choice where the probability is depending on the distance\n    # also, normalize dists\n    # calculates probabilities\n    prob = distance/np.sum(distance)\n    # choose next centroid with probability proportional to distance squared\n    new_centroid = x[np.random.choice(range(len(x)), size=1, p=prob)]\n    centroids.append(new_centroid)\n    # update distances between newly chosen centroid and other points now\n    distance = [math.dist(new_centroid[0], x[i])**2 for i in range(len(x))]\n\n\ncentroids = np.array(centroids)\nsorted_points = [[] for _ in range(4)]\nfor point in x:\n    dists = [math.dist(point, np.squeeze(i)) for i in centroids]\n    centroid_idx = np.argmin(dists)\n    sorted_points[centroid_idx].append(point)\n    \n# new centroid is mean of the points in each cluster\nprev_centroids = centroids[:]\n\n# sorted points is of size num_clusters, num_points in each cluster\ncentroids = [np.average(i) for i in sorted_points]\n\n\n\n\n\ncentroids = [np.mean(cluster, axis=0) for cluster in sorted_points]\n\n# make sure that none of the centroid values are nan\nfor points in range(len(centroids)):\n    if np.isnan(centroids[points]).any():\n        centroids[points] = prev_centroids[points]\n\n\ncolors = []\n\nfor i in centroids:\n    r, g, b = i\n    colors.append((\n    r,\n    g,\n    b\n    ))\n\n\n\nfig = plt.figure(figsize = (15,15))\nax = fig.add_subplot(111, projection='3d')\n\n\n# plot the sorted clusters\n\nfor i in range(len(sorted_points)):\n    a, b, c = zip(*sorted_points[i])\n    ax.scatter(a, b, c, s = 40 , color = colors[i], marker = 'o', label = \"cluster \"+str(i))\n    label = \"centroid of cluster\" if i == len(sorted_points)-1 else \"\"\n    ax.scatter(colors[i][0], colors[i][1], colors[i][2], s = 100 , marker = 'x', color = [0,0,0], label = label)\n\nax.set_xlabel('R')\nax.set_ylabel('G')\nax.set_zlabel('B')\nax.legend()\nplt.show()\n\n\n\n\n\nplt.grid(False)\nplt.imshow([colors])\nplt.show()\n\n\n\n\n\ntotal_points = len(RGB_values.to_numpy())\nlabels = ['Colour' + str(i+1) for i in range(len(colors))]\nsizes = [len(sorted_points[i])/total_points for i in range(len(sorted_points))]\nfig, ax = plt.subplots()\nax.pie(sizes,\n       colors=colors, autopct='%1.1f%%', pctdistance=1.15);"
  },
  {
    "objectID": "codeFiles/Regression_Analysis.html",
    "href": "codeFiles/Regression_Analysis.html",
    "title": "CS5805",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf_bike = pd.read_csv(\"SeoulBikeData.csv\")\ndf_bike.head(5)\n\n\n\n\n\n\n\n\nDate\nRented Bike Count\nHour\nTemperature(C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nSeasons\nHoliday\nFunctioning Day\n\n\n\n\n0\n01/12/2017\n254\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n1\n01/12/2017\n204\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n2\n01/12/2017\n173\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n3\n01/12/2017\n107\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n4\n01/12/2017\n78\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n\n\n\n\n\nhttps://stackoverflow.com/questions/29432629/plot-correlation-matrix-using-pandas\n\ndf_bike.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 8760 entries, 0 to 8759\nData columns (total 14 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Date                      8760 non-null   object \n 1   Rented Bike Count         8760 non-null   int64  \n 2   Hour                      8760 non-null   int64  \n 3   Temperature(C)            8760 non-null   float64\n 4   Humidity(%)               8760 non-null   int64  \n 5   Wind speed (m/s)          8760 non-null   float64\n 6   Visibility (10m)          8760 non-null   int64  \n 7   Dew point temperature(C)  8760 non-null   float64\n 8   Solar Radiation (MJ/m2)   8760 non-null   float64\n 9   Rainfall(mm)              8760 non-null   float64\n 10  Snowfall (cm)             8760 non-null   float64\n 11  Seasons                   8760 non-null   object \n 12  Holiday                   8760 non-null   object \n 13  Functioning Day           8760 non-null   object \ndtypes: float64(6), int64(4), object(4)\nmemory usage: 958.2+ KB\n\n\n\n#check for count of missing values in each column.\ndf_bike.isna().sum()\ndf_bike.isnull().sum()\n\nDate                        0\nRented Bike Count           0\nHour                        0\nTemperature(C)              0\nHumidity(%)                 0\nWind speed (m/s)            0\nVisibility (10m)            0\nDew point temperature(C)    0\nSolar Radiation (MJ/m2)     0\nRainfall(mm)                0\nSnowfall (cm)               0\nSeasons                     0\nHoliday                     0\nFunctioning Day             0\ndtype: int64\n\n\n\n# Can break the date into date, month, year columns and convert them into integers (from strings) for the purpose of correlation map\n\ndays = [int((df_bike['Date'].iloc[i])[0:2]) for i in range(len(df_bike))]\nmonth = [int((df_bike['Date'].iloc[i])[3:5]) for i in range(len(df_bike))]\nyear = [int((df_bike['Date'].iloc[i])[6:]) for i in range(len(df_bike))]\ndf_bike['Day'], df_bike['Month'], df_bike['Year'] = days, month, year\n\n\ndf_bike.head(5)\n\n\n\n\n\n\n\n\nDate\nRented Bike Count\nHour\nTemperature(C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nSeasons\nHoliday\nFunctioning Day\nDay\nMonth\nYear\n\n\n\n\n0\n01/12/2017\n254\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n1\n12\n2017\n\n\n1\n01/12/2017\n204\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n1\n12\n2017\n\n\n2\n01/12/2017\n173\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n1\n12\n2017\n\n\n3\n01/12/2017\n107\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n1\n12\n2017\n\n\n4\n01/12/2017\n78\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n1\n12\n2017\n\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndf1_bike = df_bike.drop(columns = ['Date'])\n# map unique season to numbers, map holiday to binary, and functioning day to binary\nseasons = {}\nfor idx, i in enumerate(df_bike['Seasons'].drop_duplicates()):\n    seasons[i] = idx\nholiday = {\"No Holiday\": 0, \"Holiday\": 1}\nfunctioning = {\"Yes\": 0, \"No\": 1}\ndf1_bike.Holiday = [holiday[item] for item in df_bike.Holiday]\ndf1_bike.Seasons = [seasons[item] for item in df_bike.Seasons]\ndf1_bike['Functioning Day'] = [functioning[item] for item in df1_bike['Functioning Day'] ]\n\ndf1_bike.head(3)\n\n\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = df1_bike.corr()\nsns.heatmap(corr,\n    cmap=sns.diverging_palette(220, 10, as_cmap=True),\n    vmin=-1.0, vmax=1.0,\n    square=True, ax=ax)\n\n   Rented Bike Count  Hour  Temperature(C)  Humidity(%)  Wind speed (m/s)  \\\n0                254     0            -5.2           37               2.2   \n1                204     1            -5.5           38               0.8   \n2                173     2            -6.0           39               1.0   \n\n   Visibility (10m)  Dew point temperature(C)  Solar Radiation (MJ/m2)  \\\n0              2000                     -17.6                      0.0   \n1              2000                     -17.6                      0.0   \n2              2000                     -17.7                      0.0   \n\n   Rainfall(mm)  Snowfall (cm)  Seasons  Holiday  Functioning Day  Day  Month  \\\n0           0.0            0.0        0        0                0    1     12   \n1           0.0            0.0        0        0                0    1     12   \n2           0.0            0.0        0        0                0    1     12   \n\n   Year  \n0  2017  \n1  2017  \n2  2017  \n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nplt.rcParams[\"figure.autolayout\"] = True\nfig, ax = plt.subplots(2, 2, figsize=(18, 6));\n# hour vs bike count\nsns.barplot(data=df1_bike,x='Hour',y='Rented Bike Count',ax=ax[0][0], palette='viridis');\nax[0][0].set(title='Count of Rented bikes acording to Hour');\n\n# Functioning vs bike count\nsns.barplot(data=df1_bike,x='Functioning Day',y='Rented Bike Count',ax=ax[0][1], palette='inferno');\nax[0][1].set(title='Count of Rented bikes acording to Functioning Day');\nax[0][1].set_xticklabels(['Yes', 'No'])\n\n# season vs bike count\nsns.barplot(data=df1_bike,x='Seasons', y='Rented Bike Count',ax=ax[1][0], palette='plasma');\nax[1][0].set(title='Count of Rented bikes acording to Seasons');\nax[1][0].set_xticklabels(['Winter', 'Spring', 'Summer', 'Autumn'])\n\n# month vs bike count\nsns.barplot(data=df1_bike,x='Month',y='Rented Bike Count',ax=ax[1][1], palette='cividis');\nax[1][1].set(title='Count of Rented bikes acording to Month ');\n\nplt.show()\n\n\n\n\n\n\nfig,ax=plt.subplots(figsize=(20,8))\nsns.pointplot(data=df1_bike,x='Hour',y='Rented Bike Count',hue='Seasons',ax=ax);\nax.set(title='Count of Rented bikes acording to seasons and hour of the day');\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(30, 6));\n# temperature vs bike count\n# Convert temperature in groups of 5C and average the rented bike counts for that range (rounding to 5s)\ntemp_min, temp_max = round(min(df1_bike['Temperature(C)'])/5)*5, round(max(df1_bike['Temperature(C)'])/5)*5\ndict_temp = {}\nfor i in range(temp_min, temp_max, 5):\n    # Filter rows based on the temperature interval\n    filtered_df = df1_bike[(df1_bike['Temperature(C)'] &gt;= i) & (df1_bike['Temperature(C)'] &lt; i+5)]\n    dict_temp[i] = filtered_df['Rented Bike Count'].mean()\n# print(dict_temp)\n# print(temp_max, temp_min)\nsns.barplot(data=dict_temp,ax=ax, palette='plasma');\nax.set(title='Count of Rented bikes acording to Temperature');\n\n# plt.show()\n\n\n\n\n\n# printing the regression plot for all the numerical features\nfig,ax=plt.subplots(4, 4, figsize=(40,40)) # since we know there are 16 features\nfor idx, col in enumerate(df1_bike.columns):\n  sns.regplot(x=df1_bike[col],y=df1_bike['Rented Bike Count'],scatter_kws={\"color\": 'blue'}, line_kws={\"color\": \"black\"}, ax=ax[idx//4][idx%4])\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\ny = df1_bike['Rented Bike Count']\nX = (df1_bike.drop(columns = ['Rented Bike Count'])).to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn import linear_model\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n\nmodel_names = ['Linear Regression Model',\n 'Support Vector Machine (Regression)',\n 'Ridge Regression',\n  'Lasso Regression',\n 'Gradient Boosting Regression',\n  'Random Forest',\n  'Decision Tree']\nmodels = [LinearRegression(),\n    SVR(), \n    linear_model.Ridge(), \n    linear_model.Lasso(),\n    GradientBoostingRegressor(),\n    RandomForestRegressor(),\n    DecisionTreeRegressor()]\n\nevaluation_metrics = ['Mean Squared Error (MSE)',\n 'Root MSE (RMSE)',\n  'Mean Absolute Error',\n  'R2 Score', \n  'Explained Variance Score']\n\n\n\ny_preds = [] # list of model predictions\nmodel_scores = [] # list of model scores based on the evaluation metrics defined\nfor model in models:\n    reg = model\n    reg.fit(X_train, y_train)\n    y_pred = reg.predict(X_test)\n    y_preds.append(y_pred)\n\n    mse = mean_squared_error(y_test.values, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_test.values, y_pred)\n    r2 = r2_score(y_test.values, y_pred)\n    evs = explained_variance_score(y_test.values, y_pred)\n\n    model_scores.append([mse, rmse, mae, r2, evs])\n\n\nplt.rcParams[\"figure.figsize\"] = [30, 7]\nplt.rcParams[\"figure.autolayout\"] = True\nfig, axs = plt.subplots(1, 1)\naxs.axis('tight')\naxs.axis('off')\n\ntable1 = axs.table(cellText=model_scores[0:4],\n                      cellLoc = 'left',\n                      rowLabels = model_names[0:4],\n                      rowColours= [\"palegreen\"] * 10,\n                      colLabels=evaluation_metrics,\n                      colColours= [\"palegreen\"] * 10,\n                      loc='center')\n\n# Highlight cells with minimum value in each column\nfor col_idx, metric in enumerate(evaluation_metrics):\n    col_values = [row[col_idx] for row in model_scores[0:4]]\n    min_value_idx = col_values.index(min(col_values))\n\n    # Highlight the cell with minimum value in coral color\n    table1[min_value_idx + 1, col_idx].set_facecolor(\"coral\")\n        \ntable1.auto_set_font_size(False)\ntable1.set_fontsize(14)\ntable1.scale(1, 4)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\nplt.rcParams[\"figure.figsize\"] = [30, 7]\nplt.rcParams[\"figure.autolayout\"] = True\nfig, axs = plt.subplots(1, 1)\naxs.axis('tight')\naxs.axis('off')\ntable2 = axs.table(cellText=model_scores,\n                      cellLoc = 'left',\n                      rowLabels = model_names,\n                      rowColours= [\"palegreen\"] * 10,\n                      colLabels=evaluation_metrics,\n                      colColours= [\"palegreen\"] * 10,\n                      loc='center')\n\n# Highlight cells with minimum value in each column\nfor col_idx, metric in enumerate(evaluation_metrics):\n    col_values = [row[col_idx] for row in model_scores]\n    min_value_idx = col_values.index(min(col_values))\n\n    # Highlight the cell with minimum value in coral color\n    table2[min_value_idx + 1, col_idx].set_facecolor(\"coral\")\n        \ntable2.auto_set_font_size(False)\ntable2.set_fontsize(14)\ntable2.scale(1, 4)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n# printing how far the predicted value is to the actual value for a random row in X\nimport random\nfig, ax = plt.subplots(figsize=(30, 5));\n\nlength = len(model_names)\n\nfor i in range(3):\n    idx = random.randint(0,len(y_test)-1)\n    plt.plot(range(length), [(y_test.values)[idx]]*length, label='True Value');\n    plt.scatter(range(length), [y_preds[q][idx] for q in range(length)], label='Predicted Values');\n    for j in range(length):\n        plt.plot([j, j], [(y_test.values)[idx], y_preds[j][idx]], color='gray', linestyle='--', linewidth=0.8)\n    plt.xticks(range(length), model_names)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ndf_gdp = pd.read_csv(\"China_GDP.csv\")\ndf_gdp.head(5)\n\n\nprint(df_gdp.info())\nprint(df_gdp.isna().sum())\n\n\n# plot Year vs GDP_value\nsns.scatterplot(data=df_gdp, x = 'Value', y = 'Year');\nplt.show()\n\n\nsns.regplot(x=df_gdp['Value'],y=df_gdp['Year'],scatter_kws={\"color\": 'blue'}, line_kws={\"color\": \"black\"})\n\n\nfrom sklearn.model_selection import train_test_split\ny = df_gdp['Year']\nX = (df_gdp.drop(columns = ['Year'])).to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\nfig, ax = plt.subplots(2,2, figsize=(10, 10));\nfor idx, model in enumerate(models[0:4]):\n    reg = model\n    reg.fit(X_train, y_train)\n    y_pred = reg.predict(X_test)\n    # Plot the data points for training set\n    ax[idx//2][idx%2].scatter(X_train, y_train, marker='o', color='black', label='Train');\n    # Plot the data points for testing set (true)\n    ax[idx//2][idx%2].scatter(X_test, y_test, color='purple', marker='o', label='True');\n    # Plot the data points for testing set (predicted)\n    ax[idx//2][idx%2].scatter(X_test, y_pred, color='blue', marker='o', label='Predicted');\n    ax[idx//2][idx%2].set_title(model_names[idx])\n    ax[idx//2][idx%2].set_xlabel(\"GDP\")\n    ax[idx//2][idx%2].set_xlabel(\"Year\")\n    ax[idx//2][idx%2].legend()\nplt.title(\"True vs Predicted Performance of Linear Regression Models\")\nplt.show()\n\n\n\ny_preds = [] # list of model predictions\nmodel_scores = [] # list of model scores based on the evaluation metrics defined\n\nfig, ax = plt.subplots(3, 1, figsize=(10, 10));\nfor idx, model in enumerate(models[4:]):\n    reg = model\n    reg.fit(X_train, y_train)\n    y_pred = reg.predict(X_test)\n    # Plot the data points for training set\n    ax[idx].scatter(X_train, y_train, marker='o', color='black', label='Train');\n    # Plot the data points for testing set (true)\n    ax[idx].scatter(X_test, y_test, color='purple', marker='o', label='True');\n    # Plot the data points for testing set (predicted)\n    ax[idx].scatter(X_test, y_pred, color='blue', marker='o', label='Predicted');\n    ax[idx].set_title(model_names[4+idx])\n    ax[idx].set_xlabel(\"GDP\")\n    ax[idx].set_xlabel(\"Year\")\n    ax[idx].legend()\n    \n    y_preds.append(y_pred)\n\n    mse = mean_squared_error(y_test.values, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_test.values, y_pred)\n    r2 = r2_score(y_test.values, y_pred)\n    evs = explained_variance_score(y_test.values, y_pred)\n\n    model_scores.append([mse, rmse, mae, r2, evs])\n    \nplt.title(\"True vs Predicted Performance of Non-Linear Regression Models\")\nplt.show()\n\n\nplt.rcParams[\"figure.figsize\"] = [30, 7]\nplt.rcParams[\"figure.autolayout\"] = True\nfig, axs = plt.subplots(1, 1)\naxs.axis('tight')\naxs.axis('off')\n\ntable1 = axs.table(cellText=model_scores,\n                      cellLoc = 'left',\n                      rowLabels = model_names[4:],\n                      rowColours= [\"palegreen\"] * 10,\n                      colLabels=evaluation_metrics,\n                      colColours= [\"palegreen\"] * 10,\n                      loc='center')\n\n# Highlight cells with minimum value in each column\nfor col_idx, metric in enumerate(evaluation_metrics):\n    col_values = [row[col_idx] for row in model_scores]\n    min_value_idx = col_values.index(min(col_values))\n\n    # Highlight the cell with minimum value in coral color\n    table1[min_value_idx + 1, col_idx].set_facecolor(\"coral\")\n        \ntable1.auto_set_font_size(False)\ntable1.set_fontsize(14)\ntable1.scale(1, 4)\nfig.tight_layout()\nplt.show()\n\n\n# printing how far the predicted value is to the actual value for a random row in X\nimport random\nfig, ax = plt.subplots(figsize=(30, 5));\n\nlength = len(model_names[4:])\n\nfor i in range(3):\n    idx = random.randint(0,len(y_test)-1)\n    plt.plot(range(length), [(y_test.values)[idx]]*length, label='True Value');\n    plt.scatter(range(length), [y_preds[q][idx] for q in range(length)], label='Predicted Values');\n    for j in range(length):\n        plt.plot([j, j], [(y_test.values)[idx], y_preds[j][idx]], color='gray', linestyle='--', linewidth=0.8)\n    plt.xticks(range(length), model_names[4:])\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code. Testing Git Commit and push settings!\nprint(\"Trying to see how it gets rendered as code. Typing a reallly long sentence to see if it wraps or nott\")\n\n\nRunnable cell\n\n\n\n\nRunnable Cell 2, does it get updated?\n\n\nSeeing how images get rendered  # https://quarto.org/docs/authoring/figures.html figure layout documentation\nAdding latex equations to see how these get rendered \\[\ny = x\n\\]\nAdding links Link\n\nCan add bib file to quarto for referencing https://quarto.org/docs/authoring/footnotes-and-citations.html"
  }
]