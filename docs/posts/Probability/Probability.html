<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Anushka S">
<meta name="dcterms.date" content="2023-12-03">

<title>CS5805 - Probability Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">CS5805</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Probability Theory</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Probability Theory</div>
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Random Variables</div>
                <div class="quarto-category">Hidden Markov Models</div>
                <div class="quarto-category">Viterbi algorithm</div>
                <div class="quarto-category">Baum Welch</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Anushka S </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Hidden Markov Models (HMMs) are a powerful statistical tool used in various fields, including speech recognition, bioinformatics, and natural language processing. Grounded in probability theory, HMMs are a type of stochastic model that represents a system evolving over time with hidden states. The model assumes that the observed data result from a probabilistic process involving these hidden states, making it particularly effective in situations where the underlying dynamics are not directly observable but can be inferred through observed data and the probabilities governing state transitions and emissions. Probability theory forms the backbone of HMMs, allowing them to make predictions and decisions based on the likelihood of sequences of observations given the modelâ€™s parameters.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <a href="https://hmmlearn.readthedocs.io/en/latest/">hmmlearn</a> library in Python performs Unsupervised learning and inference of Hidden Markov Models.</p>
<p>Let us take the common Hidden Markov Model example of the ocassionally dishonest casino. In a casino, they use a fair die most of the time, but switch to the loaded die once in a while. The purpose of making use of the Hidden Markov Model is to identify instances when the dice roll is probabilistically from the fair die or the loaded die.</p>
<p>The probabilities for the various outcome variables have been adapted from <a href="https://doi.org/10.1017/CBO9780511790492">this textbook</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dice_prob.JPG" class="img-fluid figure-img" style="width:30.0%"></p>
<figcaption class="figure-caption">Markov Model for dishonest casino</figcaption>
</figure>
</div>
<p>The emission probabilities are the probability of each outcome (die roll) at its current state. The transition probabilities define the probability of transitioning to a state (fair, loaded), and the start probabilities define the starting probability of being in each state.</p>
<p>From the hmmlearn library, the CategoricalHMM model (derived from the MultinomialHMM model), uses the Baum-Welch algorithm for training hidden Markov models (HMMs). The Baum-Welch algorithm, also known as the Forward-Backward algorithm or the Expectation-Maximization (EM) algorithm for HMMs, is an iterative procedure for estimating the parameters of an HMM given a set of observed data.</p>
<p>You can read more on the training of the Hidden Markov Model and the probability theory behind identifying the sequence state part at the end of this blog.</p>
<p>In the block of code below, we initialize the probabilities, initialize the CategoricalHMM method which takes in n_components as the number of possible states, the number of iterations for training. The other parameters (such as init_param, algorithm, etc.) details can be found <a href="https://hmmlearn.readthedocs.io/en/latest/api.html#categoricalhmm">here</a>.</p>
<p>We then use the sample() method to generate die roll and corresponding state samples.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">from</span> hmmlearn <span class="im">import</span> hmm</span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a>gen_model <span class="op">=</span> hmm.CategoricalHMM(n_components<span class="op">=</span><span class="dv">2</span>, n_iter<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a></span>
<span id="cb2-5"><a href="#cb2-5"></a>gen_model.startprob_ <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a>gen_model.transmat_ <span class="op">=</span> np.array([[<span class="fl">0.95</span>, <span class="fl">0.05</span>],</span>
<span id="cb2-8"><a href="#cb2-8"></a>                                [<span class="fl">0.1</span>, <span class="fl">0.9</span>]])</span>
<span id="cb2-9"><a href="#cb2-9"></a></span>
<span id="cb2-10"><a href="#cb2-10"></a>gen_model.emissionprob_ <span class="op">=</span> <span class="op">\</span></span>
<span id="cb2-11"><a href="#cb2-11"></a>    np.array([[<span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>],</span>
<span id="cb2-12"><a href="#cb2-12"></a>              [<span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">2</span>]])</span>
<span id="cb2-13"><a href="#cb2-13"></a></span>
<span id="cb2-14"><a href="#cb2-14"></a>rolls, gen_states <span class="op">=</span> gen_model.sample(<span class="dv">30000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-stdout">
<pre><code>Transition Model:
Emission Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-4-output-2.png" width="466" height="463"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Fair</th>
<th data-quarto-table-cell-role="th">Unfair</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0.166667</td>
<td>0.1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0.166667</td>
<td>0.1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0.166667</td>
<td>0.1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>0.166667</td>
<td>0.1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>0.166667</td>
<td>0.1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-stdout">
<pre><code>Sample of Dice Rolls generated</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Roll</th>
<th data-quarto-table-cell-role="th">Coin_State</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>6</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Plotting the states of the first 500 generated coin flips:</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>ax.plot(gen_states[:<span class="dv">500</span>])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'States over time'</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Time (# of rolls)'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'State'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-6-output-1.png" width="589" height="449"></p>
</div>
</div>
<p>Plotting the rolls for the fair and loaded states</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>ax.hist(rolls[gen_states <span class="op">==</span> <span class="dv">0</span>], label<span class="op">=</span><span class="st">'fair'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        bins<span class="op">=</span>np.arange(<span class="dv">7</span>) <span class="op">-</span> <span class="fl">0.5</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>ax.hist(rolls[gen_states <span class="op">==</span> <span class="dv">1</span>], label<span class="op">=</span><span class="st">'loaded'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        bins<span class="op">=</span>np.arange(<span class="dv">7</span>) <span class="op">-</span> <span class="fl">0.5</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Roll probabilities by state'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Count'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Roll'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-7-output-1.png" width="589" height="449"></p>
</div>
</div>
<p>In the code below, we are performing a 50%-50% train-test dataset split. We are then fitting the model on our train set and obtaining the score for the model which is simply the log probability under the model. Then, we make use of the predict method which implements the Viterbi algorithm to predict the best sequence of states for the given observations (dice rolls).</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># split our data into training and validation sets (50/50 split)</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>X_train <span class="op">=</span> rolls[:rolls.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb7-3"><a href="#cb7-3"></a>X_test <span class="op">=</span> rolls[rolls.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb7-4"><a href="#cb7-4"></a>y_test <span class="op">=</span> np.array(gen_states[gen_states.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>:])</span>
<span id="cb7-5"><a href="#cb7-5"></a>gen_model <span class="op">=</span> gen_model.fit(X_train)</span>
<span id="cb7-6"><a href="#cb7-6"></a></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co"># check base score (non-tuned model)</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>gen_score <span class="op">=</span> gen_model.score(X_test)</span>
<span id="cb7-9"><a href="#cb7-9"></a></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="bu">print</span>(<span class="ss">f'Generated score: </span><span class="sc">{</span>gen_score<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb7-11"><a href="#cb7-11"></a></span>
<span id="cb7-12"><a href="#cb7-12"></a><span class="co"># use the Viterbi algorithm to predict the most likely sequence of states</span></span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="co"># given the model</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>states <span class="op">=</span> gen_model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'
Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'
Even though the 'emissionprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'e'</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Generated score: -26294.052443752364</code></pre>
</div>
</div>
<p>Recovered states vs Generated states:</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>ax.plot(gen_states[:<span class="dv">500</span>], label<span class="op">=</span><span class="st">'generated'</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>ax.plot(states[:<span class="dv">500</span>] <span class="op">+</span> <span class="fl">1.5</span>, label<span class="op">=</span><span class="st">'recovered'</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>ax.set_yticks([])</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'States compared to generated'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Time (# rolls)'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'State'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-9-output-1.png" width="540" height="449"></p>
</div>
</div>
<p>Updated Markov Model probabilities after training the HMM on the dataset with the Baum-Welch algorithm.</p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>Transition Model:
Emission Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-10-output-2.png" width="466" height="463"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Fair</th>
<th data-quarto-table-cell-role="th">Unfair</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0.226</td>
<td>0.138</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0.341</td>
<td>0.133</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0.099</td>
<td>0.145</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>0.198</td>
<td>0.147</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>0.127</td>
<td>0.144</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Results of the model in the form of a confusion matrix to identify how many times the model predicted â€˜Fairâ€™ and â€˜Loadedâ€™ coin correctly given the dice roll.</p>
<p>As we can see from the results below, the accuracy of the model is not considered to be extremely good. This is because we are dealing with a truly probabilistic model, the results are based on the â€˜likelihoodâ€™ parameter. Also, the model has been trained on sample data which may not mimic true data to the fullest.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report, ConfusionMatrixDisplay</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> RocCurveDisplay</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># True states (hidden states)</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>true_states <span class="op">=</span> y_test</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>predicted_states <span class="op">=</span> states</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate confusion matrix</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(true_states, predicted_states)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display confusion matrix</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:"</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>conf_matrix, display_labels<span class="op">=</span>[<span class="st">'Fair'</span>, <span class="st">'Loaded'</span>])</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>disp.plot()</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate classification report</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>class_report <span class="op">=</span> classification_report(true_states, predicted_states)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Display classification report</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report:"</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(class_report)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>RocCurveDisplay.from_predictions(true_states, predicted_states)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix:
Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.00      0.00     10162
           1       0.32      1.00      0.49      4838

    accuracy                           0.32     15000
   macro avg       0.66      0.50      0.24     15000
weighted avg       0.78      0.32      0.16     15000
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-11-output-2.png" width="561" height="429"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>&lt;sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x22aaa00af50&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Probability_files/figure-html/cell-11-output-4.png" width="589" height="429"></p>
</div>
</div>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_numpy(string_val, <span class="bu">type</span>):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    str_int <span class="op">=</span> []</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"rolls"</span>:</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> string_val:</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>            str_int.append(np.array([<span class="bu">int</span>(i)<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        dice <span class="op">=</span> {<span class="st">'F'</span>:<span class="dv">0</span>, <span class="st">'L'</span>:<span class="dv">1</span>}</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> string_val:</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>            str_int.append(np.array(dice[i]))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> str_int</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_string(string_die):</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    dice <span class="op">=</span> {<span class="dv">0</span>: <span class="st">'F'</span>, <span class="dv">1</span>:<span class="st">'L'</span>}</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    string <span class="op">=</span> <span class="st">""</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> string_die:</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        string<span class="op">+=</span>dice[i]</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> string</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Testing the model on an example taken from the textbook: <img src="posts/Probability/HMM_test_sets.JPG" class="img-fluid" alt="HMM example">{width = 60%}</p>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>test_rolls1 <span class="op">=</span> <span class="st">"315116246446644245311321631164152133625144543631656626566666"</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>y_true1 <span class="op">=</span> <span class="st">"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLL"</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>test_rolls2 <span class="op">=</span> <span class="st">"222555441666566563564324364131513465146353411126414626253356"</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>y_true2 <span class="op">=</span> <span class="st">"FFFFFFFFLLLLLLLLLLLLLFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFL"</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>X_test_1 <span class="op">=</span> convert_to_numpy(test_rolls1, <span class="st">"rolls"</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>y_test_1 <span class="op">=</span> gen_model.predict(X_test_1)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> convert_to_string(y_test_1)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output:</span><span class="sc">{</span>test_rolls1<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Die:</span><span class="sc">{</span>y_true1<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Viterbi:</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>X_test_2 <span class="op">=</span> convert_to_numpy(test_rolls2, <span class="st">"rolls"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>y_test_2 <span class="op">=</span> gen_model.predict(X_test_2)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> convert_to_string(y_test_2)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output:</span><span class="sc">{</span>test_rolls2<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Die:</span><span class="sc">{</span>y_true2<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Viterbi:</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Output:315116246446644245311321631164152133625144543631656626566666 
Die:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLL 
Viterbi:FLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL
Output:222555441666566563564324364131513465146353411126414626253356 
Die:FFFFFFFFLLLLLLLLLLLLLFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFL 
Viterbi:FFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL</code></pre>
</div>
</div>
<p>Detailing the probability theory behind the Hidden Markov Model The Baum-Welch algorithm, also known as the Forward-Backward algorithm, is a parameter estimation technique for Hidden Markov Models (HMMs). Named after Leonard Baum and Lloyd Welch, this algorithm is a form of the Expectation-Maximization (EM) algorithm. Its primary goal is to iteratively refine the parameters of an HMM based on observed data, making it a powerful tool for model training.</p>
<p>The algorithm consists of two main steps, the expectation step and the maximization step.</p>
<p>The parameters of a HMM are given by <span class="math inline">\(\theta=(A,B,\pi)\)</span>, where:</p>
<ul>
<li><span class="math inline">\(A\)</span> is the state transition matrix, which defines the probability of transitioning from one state to another.</li>
<li><span class="math inline">\(B\)</span> is the emission matrix, which defines the probability of emitting a given observation from a given state.</li>
<li><span class="math inline">\(\pi\)</span> is the initial state distribution, which defines the probability of being in each state at the beginning of the sequence.</li>
</ul>
<p><span class="math inline">\(A=\{a_{ij}\}=P(X_{t}=j|X_{t-1}=i) is the state transition matrix\)</span></p>
<p><span class="math inline">\(\pi=\{\pi_{i}\}=P(X_{1}=i) is the initial state distribution\)</span></p>
<p><span class="math inline">\(B=\{b_{j}(y_{t})\}=P(Y_{t}=y_{t}|X_{t}=j) is the emission matrix\)</span></p>
<p>Given observation sequences <span class="math inline">\((Y=(Y_{1}=y_{1},Y_{2}=y_{2},...,Y_{T}=y_{T}))\)</span> the algorithm tries to find the parameters <span class="math inline">\((\theta)\)</span> that maximise the probability of the observation.</p>
<p>The algorithm starts by choosing some initial values for the HMM parameters <span class="math inline">\(\theta = (A, B, \pi)\)</span>. Then, it repeats the following steps until convergence:</p>
<ol type="1">
<li>Determine probable state paths. This involves calculating the probability of each possible state path, given the observed sequence of emissions.</li>
<li>Count the expected number of transitions and emissions. This involves counting the number of times each state transition is taken and each emission is made, weighted by the probability of each state path.</li>
<li>Re-estimate the HMM parameters. This involves using the expected number of transitions and emissions to update the HMM parameters <span class="math inline">\(\theta\)</span>.</li>
</ol>
<p>The forward-backward algorithm is used for finding probable paths.</p>
<p>$$ Forward Procedure (<em>{i}(t)=P(Y</em>{1}=y_{1},â€¦,Y_{t}=y_{t},X_{t}=i|)) be the probability of seeing (y_{1},â€¦,y_{t}) and being in state i at time t. Found recursively using:</p>
<p>(<em>{i}(1)=</em>{i}b_{i}(y_{1}))</p>
<p>(<em>{j}(t+1)=b</em>{j}(y_{t+1})<em>{i=1}^{N}</em>{i}(t)a_{ij})</p>
<p>Backward Procedure (<em>{i}(t)=P(Y</em>{t+1}=y_{t+1},â€¦,Y_{T}=y_{T}|X_{t}=i,)) be the probability of ending partial sequence (y_{t+1},â€¦,y_{T}) given starting state i at time t.</p>
<p>(_{i}(t)) is computed recursively as:</p>
<p>(<em>{i}(T)=1) (</em>{i}(t)=<em>{j=1}^{N}</em>{j}(t+1)a_{ij}b_{j}(y_{t+1})) $$</p>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward(states, sequence, a, b, pi, key):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> pi[key] <span class="co"># prob of state i, since 2 states, let's half it be 0.5, 0.5 initially</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> key <span class="co"># holds the first state</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for all possible states, and the first actual state (alpha)</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i.e. alpha i for all i has been caluclated given yt</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> np.zeros((N, T))</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    alpha[:,<span class="dv">0</span>] <span class="op">=</span> pi <span class="op">*</span> b[:,<span class="bu">int</span>(sequence[<span class="dv">0</span>])] <span class="op">+</span> pseudocount</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># next, we have to do iterations to calculate alpha at different times t</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we need all alpha values since it is going to be summed up to calculate gamma</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, T):</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>            alpha[j][t] <span class="op">=</span> <span class="bu">sum</span>(alpha[i][t<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span>a[i][j]<span class="op">*</span>b[j][<span class="bu">int</span>(sequence[t])] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N)) <span class="op">+</span> pseudocount</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> alpha</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(states, sequence, a, b):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.zeros((N, T))</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialization</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    beta[:, <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Set the last column to 1</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Recursion</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T <span class="op">-</span> <span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>            beta[i, t] <span class="op">=</span> <span class="bu">sum</span>(a[i, j] <span class="op">*</span> b[j, <span class="bu">int</span>(sequence[t <span class="op">+</span> <span class="dv">1</span>])] <span class="op">*</span> beta[j, t <span class="op">+</span> <span class="dv">1</span>] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N)) <span class="op">+</span> pseudocount</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The Expectation step: Calculate the probabilities of being in each state at each time step given the observed sequence using the Forward-Backward algorithm. These probabilities represent the likelihood of the system being in state <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> given the entire observed sequence. Calculate the joint probabilities of transitioning from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> at consecutive time steps given the observed sequence.</p>
<p>$$ _t(i) = </p>
<p>_t(i, j) = $$</p>
<p>The Maximization step: Update the model parameters, including the initial state probabilities, transition probabilities, and emission probabilities. The updated parameters are computed by normalizing the expected counts derived from the E-step.</p>
<p>$$</p>
<p>_i = _1(i)</p>
<p>_{ij} = </p>
<p>_i(k) = </p>
<p>$$</p>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(a, b, pi, sequence, states, key, n_iterations <span class="op">=</span> <span class="dv">100</span>, tol<span class="op">=</span><span class="fl">1e-6</span>):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Baum-Welch algorithm for HMM</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate gamma, xi, and then update a and b parameters</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># M is the number of possible observations i.e. number of columns</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> b.shape[<span class="dv">1</span>]</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    prev_log_likelihood <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> forward(states, sequence, a, b, pi, key)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        beta <span class="op">=</span> backward(states, sequence, a, b)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Alpha: </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Beta:</span><span class="sc">{</span>beta<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        gamma <span class="op">=</span> alpha <span class="op">*</span> beta</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(gamma)</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>        denominator <span class="op">=</span> np.<span class="bu">sum</span>(gamma, axis<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>) <span class="co"># same for all i</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>        gamma <span class="op">=</span> gamma<span class="op">/</span>denominator <span class="op">+</span> pseudocount</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"gamma:</span><span class="sc">{</span>gamma<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        xi <span class="op">=</span> np.zeros((N, N, T <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>                    numerator <span class="op">=</span> alpha[i, t] <span class="op">*</span> a[i, j] <span class="op">*</span> b[j, <span class="bu">int</span>(sequence[t <span class="op">+</span> <span class="dv">1</span>])] <span class="op">*</span> beta[j, t <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>                    denominator <span class="op">=</span> np.<span class="bu">sum</span>(alpha[k, t] <span class="op">*</span> a[k, l] <span class="op">*</span> b[l, <span class="bu">int</span>(sequence[t <span class="op">+</span> <span class="dv">1</span>])] <span class="op">*</span> beta[l, t <span class="op">+</span> <span class="dv">1</span>] <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(N) <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(N))</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>                    xi[i, j, t] <span class="op">=</span> (numerator <span class="op">/</span> denominator) <span class="op">+</span> pseudocount</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Xi: </span><span class="sc">{</span>xi<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># update a and b</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># M-step</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="co">        sequence == k creates a boolean array of the same length as sequence, where each element is True if the corresponding element in sequence is equal to k, and False otherwise.</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="co">    mask = (sequence == k) assigns this boolean array to the variable mask.</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="co">    In the context of the Baum-Welch algorithm or similar algorithms for Hidden Markov Models (HMMs), this kind of mask is often used to select specific observations in the computation of probabilities. For example, </span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a><span class="co">    it might be used to sum over only the observations that match a particular value, which is relevant when updating the emission matrix b.</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># a = (np.sum(xi, axis=2) + pseudocount)/ np.sum(gamma[:, :-1], axis=1, keepdims=True) </span></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):  <span class="co"># N is the number of states</span></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):  <span class="co"># N is the number of states</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>                numerator <span class="op">=</span> np.<span class="bu">sum</span>(xi[i, j, :])</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>                denominator <span class="op">=</span> np.<span class="bu">sum</span>(gamma[i, :])</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>                a[i, j] <span class="op">=</span> (numerator<span class="op">+</span>pseudocount) <span class="op">/</span> (denominator<span class="op">+</span>pseudocount) </span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> np.zeros((N, M))</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(gamma.shape)</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>        gamma_sum <span class="op">=</span> np.<span class="bu">sum</span>(gamma, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>        obs <span class="op">=</span> []</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> sequence:</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>            obs.append(<span class="bu">int</span>(i))</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>        obs <span class="op">=</span> np.array(obs)</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>                mask <span class="op">=</span> (obs<span class="op">==</span>k) <span class="co"># for indicative function i.e. 1 if observed = yt, else 0</span></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>                b[j, k] <span class="op">=</span> (np.<span class="bu">sum</span>(gamma[j]<span class="op">*</span>mask)<span class="op">+</span> pseudocount) <span class="op">/</span> (np.<span class="bu">sum</span>(gamma[j]) <span class="op">+</span> pseudocount) </span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize rows to ensure each row sums to 1.0</span></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> a <span class="op">/</span> np.<span class="bu">sum</span>(a, axis<span class="op">=</span><span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> b <span class="op">/</span> np.<span class="bu">sum</span>(b, axis<span class="op">=</span><span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"a = </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">, b = </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log Likelihood Calculation</span></span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>        log_likelihood <span class="op">=</span> np.<span class="bu">sum</span>(np.log(np.<span class="bu">sum</span>(alpha, axis<span class="op">=</span><span class="dv">0</span>)))</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convergence Check</span></span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.<span class="bu">abs</span>(log_likelihood <span class="op">-</span> prev_log_likelihood) <span class="op">&lt;</span> tol:</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Converged after </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> iterations."</span>)</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>        prev_log_likelihood <span class="op">=</span> log_likelihood</span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a, b, pi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The Viterbi algorithm is a dynamic programming algorithm used for decoding Hidden Markov Models (HMMs) and finding the most likely sequence of hidden states given an observed sequence. The algorithm efficiently determines the optimal state sequence by considering the probabilities of transitions and emissions.</p>
<p>The core idea behind the Viterbi algorithm is to iteratively compute the most likely path to each state at each time step, incorporating both the current observation and the previously calculated probabilities.</p>
<p><span class="math display">\[
Î´_i(t) = max_j Î´_j(t - 1) a_ji b_i(Y_t)
\]</span></p>
<p><span class="math display">\[
Ïˆ_i(t) = argmax_j Î´_j(t - 1) a_ji
\]</span></p>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(sequence, states, a, b, pi):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Makes use of the viterbi algorithm to predict best path</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize Variables</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    viterbi_table <span class="op">=</span> np.zeros((N, T)) <span class="co"># delta</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    backpointer <span class="op">=</span> np.zeros((N, T)) <span class="co"># psi</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialization step, for t = 0</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">int</span>(sequence[<span class="dv">0</span>]))</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    viterbi_table[:, <span class="dv">0</span>] <span class="op">=</span> pi <span class="op">*</span> b[:, <span class="bu">int</span>(sequence[<span class="dv">0</span>])] <span class="op">+</span> pseudocount</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate Probabilities</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, T):</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>            max_prob <span class="op">=</span> <span class="bu">max</span>(viterbi_table[prev_s][t<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> a[prev_s][s] <span class="cf">for</span> prev_s <span class="kw">in</span> <span class="bu">range</span>(N)) <span class="op">*</span> b[s][<span class="bu">int</span>(sequence[t])] </span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>            viterbi_table[s][t] <span class="op">=</span> max_prob <span class="op">+</span> pseudocount</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>            backpointer[s][t] <span class="op">=</span> np.argmax([viterbi_table[prev_s][t<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> a[prev_s][s]<span class="cf">for</span> prev_s <span class="kw">in</span> <span class="bu">range</span>(N)])</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Traceback and Find Best Path</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    best_path <span class="op">=</span> []</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    last_state <span class="op">=</span> np.argmax(viterbi_table[:, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    best_path.append(last_state)</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    best_prob <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        last_state <span class="op">=</span> last_state <span class="op">=</span> np.argmax(viterbi_table[:, t])</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        best_prob <span class="op">*=</span> (viterbi_table[last_state, t] <span class="op">+</span> pseudocount)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        best_path.append(last_state) <span class="co"># i.e. add to start of list</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_path</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>


<!-- -->


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb22" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Probability Theory"</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Anushka S"</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-12-03"</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Probability Theory, Machine Learning, Random Variables, Hidden Markov Models, Viterbi algorithm, Baum Welch]</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>Hidden Markov Models (HMMs) are a powerful statistical tool used in various fields, including speech recognition, bioinformatics, and natural language processing. Grounded in probability theory, HMMs are a type of stochastic model that represents a system evolving over time with hidden states. The model assumes that the observed data result from a probabilistic process involving these hidden states, making it particularly effective in situations where the underlying dynamics are not directly observable but can be inferred through observed data and the probabilities governing state transitions and emissions. Probability theory forms the backbone of HMMs, allowing them to make predictions and decisions based on the likelihood of sequences of observations given the model's parameters.</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>The <span class="co">[</span><span class="ot">hmmlearn</span><span class="co">](https://hmmlearn.readthedocs.io/en/latest/)</span> library in Python performs Unsupervised learning and inference of Hidden Markov Models.  </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>Let us take the common Hidden Markov Model example of the ocassionally dishonest casino. In a casino, they use a fair die most of the time, but switch to the loaded die once in a while. The purpose of making use of the Hidden Markov Model is to identify instances when the dice roll is probabilistically from the fair die or the loaded die. </span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>The probabilities for the various outcome variables have been adapted from <span class="co">[</span><span class="ot">this textbook</span><span class="co">](https://doi.org/10.1017/CBO9780511790492)</span>.</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="al">![Markov Model for dishonest casino](dice_prob.JPG)</span>{width=30%}</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>The emission probabilities are the probability of each outcome (die roll) at its current state. The transition probabilities define the probability of transitioning to a state (fair, loaded), and the start probabilities define the starting probability of being in each state.</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>From the hmmlearn library, the CategoricalHMM model (derived from the MultinomialHMM model), uses the Baum-Welch algorithm for training hidden Markov models (HMMs). The Baum-Welch algorithm, also known as the Forward-Backward algorithm or the Expectation-Maximization (EM) algorithm for HMMs, is an iterative procedure for estimating the parameters of an HMM given a set of observed data.</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>You can read more on the training of the Hidden Markov Model and the probability theory behind identifying the sequence state part at the end of this blog.</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>In the block of code below, we initialize the probabilities, initialize the CategoricalHMM method which takes in n_components as the number of possible states, the number of iterations for training. The other parameters (such as init_param, algorithm, etc.) details can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://hmmlearn.readthedocs.io/en/latest/api.html#categoricalhmm)</span>.</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>We then use the sample() method to generate die roll and corresponding state samples.</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-line-numbers: true</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hmmlearn <span class="im">import</span> hmm</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>gen_model <span class="op">=</span> hmm.CategoricalHMM(n_components<span class="op">=</span><span class="dv">2</span>, n_iter<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>gen_model.startprob_ <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>gen_model.transmat_ <span class="op">=</span> np.array([[<span class="fl">0.95</span>, <span class="fl">0.05</span>],</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>                                [<span class="fl">0.1</span>, <span class="fl">0.9</span>]])</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>gen_model.emissionprob_ <span class="op">=</span> <span class="op">\</span></span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>    np.array([[<span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">6</span>],</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">10</span>, <span class="dv">1</span> <span class="op">/</span> <span class="dv">2</span>]])</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>rolls, gen_states <span class="op">=</span> gen_model.sample(<span class="dv">30000</span>)</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the MarkovChain class from markovchain.py</span></span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> markovchain <span class="im">import</span> MarkovChain</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> gen_model.transmat_</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>mc <span class="op">=</span> MarkovChain(P, [<span class="st">'Fair'</span>, <span class="st">'Loaded'</span>])</span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Transition Model:"</span>)</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>mc.draw()</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'Fair'</span>: gen_model.emissionprob_[<span class="dv">0</span>], <span class="st">'Unfair'</span>: gen_model.emissionprob_[<span class="dv">1</span>]}</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>df_emission <span class="op">=</span> pd.DataFrame(data, index<span class="op">=</span>[<span class="st">'1'</span>, <span class="st">'2'</span>, <span class="st">'3'</span>, <span class="st">'4'</span>, <span class="st">'5'</span>, <span class="st">'6'</span>])</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Emission Matrix:"</span>)</span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>df_emission.head()</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sample of Dice Rolls generated"</span>)</span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">'Roll'</span>: rolls.flatten()[<span class="dv">0</span>:<span class="dv">10</span>]<span class="op">+</span><span class="dv">1</span>, <span class="st">'Coin_State'</span>: gen_states.flatten()[<span class="dv">0</span>:<span class="dv">10</span>]}).head()</span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a>Plotting the states of the first 500 generated coin flips:</span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a>ax.plot(gen_states[:<span class="dv">500</span>])</span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'States over time'</span>)</span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Time (# of rolls)'</span>)</span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'State'</span>)</span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a>fig.show()</span>
<span id="cb22-99"><a href="#cb22-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-100"><a href="#cb22-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-101"><a href="#cb22-101" aria-hidden="true" tabindex="-1"></a>Plotting the rolls for the fair and loaded states</span>
<span id="cb22-104"><a href="#cb22-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-105"><a href="#cb22-105" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb22-106"><a href="#cb22-106" aria-hidden="true" tabindex="-1"></a>ax.hist(rolls[gen_states <span class="op">==</span> <span class="dv">0</span>], label<span class="op">=</span><span class="st">'fair'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb22-107"><a href="#cb22-107" aria-hidden="true" tabindex="-1"></a>        bins<span class="op">=</span>np.arange(<span class="dv">7</span>) <span class="op">-</span> <span class="fl">0.5</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-108"><a href="#cb22-108" aria-hidden="true" tabindex="-1"></a>ax.hist(rolls[gen_states <span class="op">==</span> <span class="dv">1</span>], label<span class="op">=</span><span class="st">'loaded'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb22-109"><a href="#cb22-109" aria-hidden="true" tabindex="-1"></a>        bins<span class="op">=</span>np.arange(<span class="dv">7</span>) <span class="op">-</span> <span class="fl">0.5</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-110"><a href="#cb22-110" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Roll probabilities by state'</span>)</span>
<span id="cb22-111"><a href="#cb22-111" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Count'</span>)</span>
<span id="cb22-112"><a href="#cb22-112" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Roll'</span>)</span>
<span id="cb22-113"><a href="#cb22-113" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb22-114"><a href="#cb22-114" aria-hidden="true" tabindex="-1"></a>fig.show()</span>
<span id="cb22-115"><a href="#cb22-115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-116"><a href="#cb22-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-117"><a href="#cb22-117" aria-hidden="true" tabindex="-1"></a>In the code below, we are performing a 50%-50% train-test dataset split. </span>
<span id="cb22-118"><a href="#cb22-118" aria-hidden="true" tabindex="-1"></a>We are then fitting the model on our train set and obtaining the score for the model which is simply the log probability under the model.</span>
<span id="cb22-119"><a href="#cb22-119" aria-hidden="true" tabindex="-1"></a>Then, we make use of the predict method which implements the Viterbi algorithm to predict the best sequence of states for the given observations (dice rolls).</span>
<span id="cb22-120"><a href="#cb22-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-123"><a href="#cb22-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-124"><a href="#cb22-124" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb22-125"><a href="#cb22-125" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-line-numbers: true</span></span>
<span id="cb22-126"><a href="#cb22-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-127"><a href="#cb22-127" aria-hidden="true" tabindex="-1"></a><span class="co"># split our data into training and validation sets (50/50 split)</span></span>
<span id="cb22-128"><a href="#cb22-128" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> rolls[:rolls.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb22-129"><a href="#cb22-129" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> rolls[rolls.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb22-130"><a href="#cb22-130" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> np.array(gen_states[gen_states.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>:])</span>
<span id="cb22-131"><a href="#cb22-131" aria-hidden="true" tabindex="-1"></a>gen_model <span class="op">=</span> gen_model.fit(X_train)</span>
<span id="cb22-132"><a href="#cb22-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-133"><a href="#cb22-133" aria-hidden="true" tabindex="-1"></a><span class="co"># check base score (non-tuned model)</span></span>
<span id="cb22-134"><a href="#cb22-134" aria-hidden="true" tabindex="-1"></a>gen_score <span class="op">=</span> gen_model.score(X_test)</span>
<span id="cb22-135"><a href="#cb22-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-136"><a href="#cb22-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Generated score: </span><span class="sc">{</span>gen_score<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-137"><a href="#cb22-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-138"><a href="#cb22-138" aria-hidden="true" tabindex="-1"></a><span class="co"># use the Viterbi algorithm to predict the most likely sequence of states</span></span>
<span id="cb22-139"><a href="#cb22-139" aria-hidden="true" tabindex="-1"></a><span class="co"># given the model</span></span>
<span id="cb22-140"><a href="#cb22-140" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> gen_model.predict(X_test)</span>
<span id="cb22-141"><a href="#cb22-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-142"><a href="#cb22-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-143"><a href="#cb22-143" aria-hidden="true" tabindex="-1"></a>Recovered states vs Generated states:</span>
<span id="cb22-144"><a href="#cb22-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-147"><a href="#cb22-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-148"><a href="#cb22-148" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb22-149"><a href="#cb22-149" aria-hidden="true" tabindex="-1"></a>ax.plot(gen_states[:<span class="dv">500</span>], label<span class="op">=</span><span class="st">'generated'</span>)</span>
<span id="cb22-150"><a href="#cb22-150" aria-hidden="true" tabindex="-1"></a>ax.plot(states[:<span class="dv">500</span>] <span class="op">+</span> <span class="fl">1.5</span>, label<span class="op">=</span><span class="st">'recovered'</span>)</span>
<span id="cb22-151"><a href="#cb22-151" aria-hidden="true" tabindex="-1"></a>ax.set_yticks([])</span>
<span id="cb22-152"><a href="#cb22-152" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'States compared to generated'</span>)</span>
<span id="cb22-153"><a href="#cb22-153" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Time (# rolls)'</span>)</span>
<span id="cb22-154"><a href="#cb22-154" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'State'</span>)</span>
<span id="cb22-155"><a href="#cb22-155" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb22-156"><a href="#cb22-156" aria-hidden="true" tabindex="-1"></a>fig.show()</span>
<span id="cb22-157"><a href="#cb22-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-158"><a href="#cb22-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-159"><a href="#cb22-159" aria-hidden="true" tabindex="-1"></a>Updated Markov Model probabilities after training the HMM on the dataset with the Baum-Welch algorithm.</span>
<span id="cb22-162"><a href="#cb22-162" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-163"><a href="#cb22-163" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb22-164"><a href="#cb22-164" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb22-165"><a href="#cb22-165" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the MarkovChain class from markovchain.py</span></span>
<span id="cb22-166"><a href="#cb22-166" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> markovchain <span class="im">import</span> MarkovChain</span>
<span id="cb22-167"><a href="#cb22-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-168"><a href="#cb22-168" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> gen_model.transmat_.<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb22-169"><a href="#cb22-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-170"><a href="#cb22-170" aria-hidden="true" tabindex="-1"></a>mc <span class="op">=</span> MarkovChain(P, [<span class="st">'Fair'</span>, <span class="st">'Loaded'</span>])</span>
<span id="cb22-171"><a href="#cb22-171" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Transition Model:"</span>)</span>
<span id="cb22-172"><a href="#cb22-172" aria-hidden="true" tabindex="-1"></a>mc.draw()</span>
<span id="cb22-173"><a href="#cb22-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-174"><a href="#cb22-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-175"><a href="#cb22-175" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'Fair'</span>: gen_model.emissionprob_.<span class="bu">round</span>(<span class="dv">3</span>)[<span class="dv">0</span>], <span class="st">'Unfair'</span>: gen_model.emissionprob_.<span class="bu">round</span>(<span class="dv">3</span>)[<span class="dv">1</span>]}</span>
<span id="cb22-176"><a href="#cb22-176" aria-hidden="true" tabindex="-1"></a>df_emission <span class="op">=</span> pd.DataFrame(data, index<span class="op">=</span>[<span class="st">'1'</span>, <span class="st">'2'</span>, <span class="st">'3'</span>, <span class="st">'4'</span>, <span class="st">'5'</span>, <span class="st">'6'</span>])</span>
<span id="cb22-177"><a href="#cb22-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-178"><a href="#cb22-178" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Emission Matrix:"</span>)</span>
<span id="cb22-179"><a href="#cb22-179" aria-hidden="true" tabindex="-1"></a>df_emission.head()</span>
<span id="cb22-180"><a href="#cb22-180" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-181"><a href="#cb22-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-182"><a href="#cb22-182" aria-hidden="true" tabindex="-1"></a>Results of the model in the form of a confusion matrix to identify how many times the model predicted 'Fair' and 'Loaded' coin correctly given the dice roll.</span>
<span id="cb22-183"><a href="#cb22-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-184"><a href="#cb22-184" aria-hidden="true" tabindex="-1"></a>As we can see from the results below, the accuracy of the model is not considered to be extremely good. This is because we are dealing with a truly probabilistic model, the results are based on the 'likelihood' parameter. Also, the model has been trained on sample data which may not mimic true data to the fullest. </span>
<span id="cb22-187"><a href="#cb22-187" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-188"><a href="#cb22-188" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report, ConfusionMatrixDisplay</span>
<span id="cb22-189"><a href="#cb22-189" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> RocCurveDisplay</span>
<span id="cb22-190"><a href="#cb22-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-191"><a href="#cb22-191" aria-hidden="true" tabindex="-1"></a><span class="co"># True states (hidden states)</span></span>
<span id="cb22-192"><a href="#cb22-192" aria-hidden="true" tabindex="-1"></a>true_states <span class="op">=</span> y_test</span>
<span id="cb22-193"><a href="#cb22-193" aria-hidden="true" tabindex="-1"></a>predicted_states <span class="op">=</span> states</span>
<span id="cb22-194"><a href="#cb22-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-195"><a href="#cb22-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate confusion matrix</span></span>
<span id="cb22-196"><a href="#cb22-196" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(true_states, predicted_states)</span>
<span id="cb22-197"><a href="#cb22-197" aria-hidden="true" tabindex="-1"></a><span class="co"># Display confusion matrix</span></span>
<span id="cb22-198"><a href="#cb22-198" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:"</span>)</span>
<span id="cb22-199"><a href="#cb22-199" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>conf_matrix, display_labels<span class="op">=</span>[<span class="st">'Fair'</span>, <span class="st">'Loaded'</span>])</span>
<span id="cb22-200"><a href="#cb22-200" aria-hidden="true" tabindex="-1"></a>disp.plot()</span>
<span id="cb22-201"><a href="#cb22-201" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-202"><a href="#cb22-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-203"><a href="#cb22-203" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate classification report</span></span>
<span id="cb22-204"><a href="#cb22-204" aria-hidden="true" tabindex="-1"></a>class_report <span class="op">=</span> classification_report(true_states, predicted_states)</span>
<span id="cb22-205"><a href="#cb22-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-206"><a href="#cb22-206" aria-hidden="true" tabindex="-1"></a><span class="co"># Display classification report</span></span>
<span id="cb22-207"><a href="#cb22-207" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report:"</span>)</span>
<span id="cb22-208"><a href="#cb22-208" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(class_report)</span>
<span id="cb22-209"><a href="#cb22-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-210"><a href="#cb22-210" aria-hidden="true" tabindex="-1"></a>RocCurveDisplay.from_predictions(true_states, predicted_states)</span>
<span id="cb22-211"><a href="#cb22-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-212"><a href="#cb22-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-215"><a href="#cb22-215" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-216"><a href="#cb22-216" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_numpy(string_val, <span class="bu">type</span>):</span>
<span id="cb22-217"><a href="#cb22-217" aria-hidden="true" tabindex="-1"></a>    str_int <span class="op">=</span> []</span>
<span id="cb22-218"><a href="#cb22-218" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">type</span> <span class="op">==</span> <span class="st">"rolls"</span>:</span>
<span id="cb22-219"><a href="#cb22-219" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> string_val:</span>
<span id="cb22-220"><a href="#cb22-220" aria-hidden="true" tabindex="-1"></a>            str_int.append(np.array([<span class="bu">int</span>(i)<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb22-221"><a href="#cb22-221" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb22-222"><a href="#cb22-222" aria-hidden="true" tabindex="-1"></a>        dice <span class="op">=</span> {<span class="st">'F'</span>:<span class="dv">0</span>, <span class="st">'L'</span>:<span class="dv">1</span>}</span>
<span id="cb22-223"><a href="#cb22-223" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> string_val:</span>
<span id="cb22-224"><a href="#cb22-224" aria-hidden="true" tabindex="-1"></a>            str_int.append(np.array(dice[i]))</span>
<span id="cb22-225"><a href="#cb22-225" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> str_int</span>
<span id="cb22-226"><a href="#cb22-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-227"><a href="#cb22-227" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_string(string_die):</span>
<span id="cb22-228"><a href="#cb22-228" aria-hidden="true" tabindex="-1"></a>    dice <span class="op">=</span> {<span class="dv">0</span>: <span class="st">'F'</span>, <span class="dv">1</span>:<span class="st">'L'</span>}</span>
<span id="cb22-229"><a href="#cb22-229" aria-hidden="true" tabindex="-1"></a>    string <span class="op">=</span> <span class="st">""</span></span>
<span id="cb22-230"><a href="#cb22-230" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> string_die:</span>
<span id="cb22-231"><a href="#cb22-231" aria-hidden="true" tabindex="-1"></a>        string<span class="op">+=</span>dice[i]</span>
<span id="cb22-232"><a href="#cb22-232" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> string</span>
<span id="cb22-233"><a href="#cb22-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-234"><a href="#cb22-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-235"><a href="#cb22-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-236"><a href="#cb22-236" aria-hidden="true" tabindex="-1"></a>Testing the model on an example taken from the textbook:</span>
<span id="cb22-237"><a href="#cb22-237" aria-hidden="true" tabindex="-1"></a><span class="al">![HMM example](posts/Probability/HMM_test_sets.JPG)</span>{width = 60%}</span>
<span id="cb22-238"><a href="#cb22-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-241"><a href="#cb22-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-242"><a href="#cb22-242" aria-hidden="true" tabindex="-1"></a>test_rolls1 <span class="op">=</span> <span class="st">"315116246446644245311321631164152133625144543631656626566666"</span></span>
<span id="cb22-243"><a href="#cb22-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-244"><a href="#cb22-244" aria-hidden="true" tabindex="-1"></a>y_true1 <span class="op">=</span> <span class="st">"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLL"</span></span>
<span id="cb22-245"><a href="#cb22-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-246"><a href="#cb22-246" aria-hidden="true" tabindex="-1"></a>test_rolls2 <span class="op">=</span> <span class="st">"222555441666566563564324364131513465146353411126414626253356"</span></span>
<span id="cb22-247"><a href="#cb22-247" aria-hidden="true" tabindex="-1"></a>y_true2 <span class="op">=</span> <span class="st">"FFFFFFFFLLLLLLLLLLLLLFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFL"</span></span>
<span id="cb22-248"><a href="#cb22-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-249"><a href="#cb22-249" aria-hidden="true" tabindex="-1"></a>X_test_1 <span class="op">=</span> convert_to_numpy(test_rolls1, <span class="st">"rolls"</span>)</span>
<span id="cb22-250"><a href="#cb22-250" aria-hidden="true" tabindex="-1"></a>y_test_1 <span class="op">=</span> gen_model.predict(X_test_1)</span>
<span id="cb22-251"><a href="#cb22-251" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> convert_to_string(y_test_1)</span>
<span id="cb22-252"><a href="#cb22-252" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output:</span><span class="sc">{</span>test_rolls1<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Die:</span><span class="sc">{</span>y_true1<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Viterbi:</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-253"><a href="#cb22-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-254"><a href="#cb22-254" aria-hidden="true" tabindex="-1"></a>X_test_2 <span class="op">=</span> convert_to_numpy(test_rolls2, <span class="st">"rolls"</span>)</span>
<span id="cb22-255"><a href="#cb22-255" aria-hidden="true" tabindex="-1"></a>y_test_2 <span class="op">=</span> gen_model.predict(X_test_2)</span>
<span id="cb22-256"><a href="#cb22-256" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> convert_to_string(y_test_2)</span>
<span id="cb22-257"><a href="#cb22-257" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output:</span><span class="sc">{</span>test_rolls2<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Die:</span><span class="sc">{</span>y_true2<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">Viterbi:</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-258"><a href="#cb22-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-259"><a href="#cb22-259" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-260"><a href="#cb22-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-261"><a href="#cb22-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-262"><a href="#cb22-262" aria-hidden="true" tabindex="-1"></a>\huge Detailing the probability theory behind the Hidden Markov Model</span>
<span id="cb22-263"><a href="#cb22-263" aria-hidden="true" tabindex="-1"></a>The Baum-Welch algorithm, also known as the Forward-Backward algorithm, is a parameter estimation technique for Hidden Markov Models (HMMs). Named after Leonard Baum and Lloyd Welch, this algorithm is a form of the Expectation-Maximization (EM) algorithm. Its primary goal is to iteratively refine the parameters of an HMM based on observed data, making it a powerful tool for model training.</span>
<span id="cb22-264"><a href="#cb22-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-265"><a href="#cb22-265" aria-hidden="true" tabindex="-1"></a>The algorithm consists of two main steps, the expectation step and the maximization step.</span>
<span id="cb22-266"><a href="#cb22-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-267"><a href="#cb22-267" aria-hidden="true" tabindex="-1"></a>The parameters of a HMM are given by $\theta=(A,B,\pi)$, where:</span>
<span id="cb22-268"><a href="#cb22-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-269"><a href="#cb22-269" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$A$ is the state transition matrix, which defines the probability of transitioning from one state to another.</span>
<span id="cb22-270"><a href="#cb22-270" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$B$ is the emission matrix, which defines the probability of emitting a given observation from a given state.</span>
<span id="cb22-271"><a href="#cb22-271" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\pi$ is the initial state distribution, which defines the probability of being in each state at the beginning of the sequence.</span>
<span id="cb22-272"><a href="#cb22-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-273"><a href="#cb22-273" aria-hidden="true" tabindex="-1"></a>$A=<span class="sc">\{</span>a_{ij}<span class="sc">\}</span>=P(X_{t}=j|X_{t-1}=i) is the state transition matrix$</span>
<span id="cb22-274"><a href="#cb22-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-275"><a href="#cb22-275" aria-hidden="true" tabindex="-1"></a>$\pi=<span class="sc">\{</span>\pi_{i}<span class="sc">\}</span>=P(X_{1}=i) is the initial state distribution$</span>
<span id="cb22-276"><a href="#cb22-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-277"><a href="#cb22-277" aria-hidden="true" tabindex="-1"></a>$B=<span class="sc">\{</span>b_{j}(y_{t})<span class="sc">\}</span>=P(Y_{t}=y_{t}|X_{t}=j) is the emission matrix$</span>
<span id="cb22-278"><a href="#cb22-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-279"><a href="#cb22-279" aria-hidden="true" tabindex="-1"></a>Given observation sequences $(Y=(Y_{1}=y_{1},Y_{2}=y_{2},...,Y_{T}=y_{T}))$ the</span>
<span id="cb22-280"><a href="#cb22-280" aria-hidden="true" tabindex="-1"></a>algorithm tries to find the parameters $(\theta)$ that maximise the probability of the</span>
<span id="cb22-281"><a href="#cb22-281" aria-hidden="true" tabindex="-1"></a>observation.</span>
<span id="cb22-282"><a href="#cb22-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-283"><a href="#cb22-283" aria-hidden="true" tabindex="-1"></a>The algorithm starts by choosing some initial values for the HMM parameters $\theta = (A, B, \pi)$. Then, it repeats the following steps until convergence:</span>
<span id="cb22-284"><a href="#cb22-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-285"><a href="#cb22-285" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Determine probable state paths. This involves calculating the probability of each possible state path, given the observed sequence of emissions.</span>
<span id="cb22-286"><a href="#cb22-286" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Count the expected number of transitions and emissions. This involves counting the number of times each state transition is taken and each emission is made, weighted by the probability of each state path.</span>
<span id="cb22-287"><a href="#cb22-287" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Re-estimate the HMM parameters. This involves using the expected number of transitions and emissions to update the HMM parameters $\theta$.</span>
<span id="cb22-288"><a href="#cb22-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-289"><a href="#cb22-289" aria-hidden="true" tabindex="-1"></a>The forward-backward algorithm is used for finding probable paths.</span>
<span id="cb22-290"><a href="#cb22-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-291"><a href="#cb22-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-292"><a href="#cb22-292" aria-hidden="true" tabindex="-1"></a>Forward Procedure</span>
<span id="cb22-293"><a href="#cb22-293" aria-hidden="true" tabindex="-1"></a>(\alpha_{i}(t)=P(Y_{1}=y_{1},...,Y_{t}=y_{t},X_{t}=i|\theta)) be the probability of seeing (y_{1},...,y_{t}) and being in state i at time t. Found recursively using:</span>
<span id="cb22-294"><a href="#cb22-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-295"><a href="#cb22-295" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>\alpha_{i}(1)=\pi_{i}b_{i}(y_{1})<span class="sc">\)</span></span>
<span id="cb22-296"><a href="#cb22-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-297"><a href="#cb22-297" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>\alpha_{j}(t+1)=b_{j}(y_{t+1})\sum_{i=1}^{N}\alpha_{i}(t)a_{ij}<span class="sc">\)</span></span>
<span id="cb22-298"><a href="#cb22-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-299"><a href="#cb22-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-300"><a href="#cb22-300" aria-hidden="true" tabindex="-1"></a>Backward Procedure</span>
<span id="cb22-301"><a href="#cb22-301" aria-hidden="true" tabindex="-1"></a>(\beta_{i}(t)=P(Y_{t+1}=y_{t+1},...,Y_{T}=y_{T}|X_{t}=i,\theta)) be the probability of ending partial sequence (y_{t+1},...,y_{T}) given starting state i at time t. </span>
<span id="cb22-302"><a href="#cb22-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-303"><a href="#cb22-303" aria-hidden="true" tabindex="-1"></a>(\beta_{i}(t)) is computed recursively as:</span>
<span id="cb22-304"><a href="#cb22-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-305"><a href="#cb22-305" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>\beta_{i}(T)=1<span class="sc">\)</span></span>
<span id="cb22-306"><a href="#cb22-306" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>\beta_{i}(t)=\sum_{j=1}^{N}\beta_{j}(t+1)a_{ij}b_{j}(y_{t+1}))</span>
<span id="cb22-307"><a href="#cb22-307" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-308"><a href="#cb22-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-311"><a href="#cb22-311" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-312"><a href="#cb22-312" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward(states, sequence, a, b, pi, key):</span>
<span id="cb22-313"><a href="#cb22-313" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb22-314"><a href="#cb22-314" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb22-315"><a href="#cb22-315" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> pi[key] <span class="co"># prob of state i, since 2 states, let's half it be 0.5, 0.5 initially</span></span>
<span id="cb22-316"><a href="#cb22-316" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> key <span class="co"># holds the first state</span></span>
<span id="cb22-317"><a href="#cb22-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-318"><a href="#cb22-318" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb22-319"><a href="#cb22-319" aria-hidden="true" tabindex="-1"></a>    pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb22-320"><a href="#cb22-320" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for all possible states, and the first actual state (alpha)</span></span>
<span id="cb22-321"><a href="#cb22-321" aria-hidden="true" tabindex="-1"></a>    <span class="co"># i.e. alpha i for all i has been caluclated given yt</span></span>
<span id="cb22-322"><a href="#cb22-322" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> np.zeros((N, T))</span>
<span id="cb22-323"><a href="#cb22-323" aria-hidden="true" tabindex="-1"></a>    alpha[:,<span class="dv">0</span>] <span class="op">=</span> pi <span class="op">*</span> b[:,<span class="bu">int</span>(sequence[<span class="dv">0</span>])] <span class="op">+</span> pseudocount</span>
<span id="cb22-324"><a href="#cb22-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-325"><a href="#cb22-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-326"><a href="#cb22-326" aria-hidden="true" tabindex="-1"></a>    <span class="co"># next, we have to do iterations to calculate alpha at different times t</span></span>
<span id="cb22-327"><a href="#cb22-327" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we need all alpha values since it is going to be summed up to calculate gamma</span></span>
<span id="cb22-328"><a href="#cb22-328" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-329"><a href="#cb22-329" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, T):</span>
<span id="cb22-330"><a href="#cb22-330" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb22-331"><a href="#cb22-331" aria-hidden="true" tabindex="-1"></a>            alpha[j][t] <span class="op">=</span> <span class="bu">sum</span>(alpha[i][t<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span>a[i][j]<span class="op">*</span>b[j][<span class="bu">int</span>(sequence[t])] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N)) <span class="op">+</span> pseudocount</span>
<span id="cb22-332"><a href="#cb22-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-333"><a href="#cb22-333" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> alpha</span>
<span id="cb22-334"><a href="#cb22-334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-335"><a href="#cb22-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-338"><a href="#cb22-338" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-339"><a href="#cb22-339" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(states, sequence, a, b):</span>
<span id="cb22-340"><a href="#cb22-340" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb22-341"><a href="#cb22-341" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb22-342"><a href="#cb22-342" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.zeros((N, T))</span>
<span id="cb22-343"><a href="#cb22-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-344"><a href="#cb22-344" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb22-345"><a href="#cb22-345" aria-hidden="true" tabindex="-1"></a>    pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb22-346"><a href="#cb22-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-347"><a href="#cb22-347" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialization</span></span>
<span id="cb22-348"><a href="#cb22-348" aria-hidden="true" tabindex="-1"></a>    beta[:, <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Set the last column to 1</span></span>
<span id="cb22-349"><a href="#cb22-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-350"><a href="#cb22-350" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Recursion</span></span>
<span id="cb22-351"><a href="#cb22-351" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T <span class="op">-</span> <span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb22-352"><a href="#cb22-352" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb22-353"><a href="#cb22-353" aria-hidden="true" tabindex="-1"></a>            beta[i, t] <span class="op">=</span> <span class="bu">sum</span>(a[i, j] <span class="op">*</span> b[j, <span class="bu">int</span>(sequence[t <span class="op">+</span> <span class="dv">1</span>])] <span class="op">*</span> beta[j, t <span class="op">+</span> <span class="dv">1</span>] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N)) <span class="op">+</span> pseudocount</span>
<span id="cb22-354"><a href="#cb22-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-355"><a href="#cb22-355" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> beta</span>
<span id="cb22-356"><a href="#cb22-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-357"><a href="#cb22-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-358"><a href="#cb22-358" aria-hidden="true" tabindex="-1"></a>The Expectation step:</span>
<span id="cb22-359"><a href="#cb22-359" aria-hidden="true" tabindex="-1"></a>Calculate the probabilities of being in each state at each time step given the observed sequence using the Forward-Backward algorithm. These probabilities represent the likelihood of the system being in state </span>
<span id="cb22-360"><a href="#cb22-360" aria-hidden="true" tabindex="-1"></a>$i$ at time $t$ given the entire observed sequence.</span>
<span id="cb22-361"><a href="#cb22-361" aria-hidden="true" tabindex="-1"></a>Calculate the joint probabilities of transitioning from state $i$ to state $j$ at consecutive time steps given the observed sequence. </span>
<span id="cb22-362"><a href="#cb22-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-363"><a href="#cb22-363" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-364"><a href="#cb22-364" aria-hidden="true" tabindex="-1"></a>\gamma_t(i) = \frac{\alpha_t(i) \cdot \beta_t(i)}{\sum_{j=1}^{N} \alpha_t(j) \cdot \beta_t(j)}</span>
<span id="cb22-365"><a href="#cb22-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-366"><a href="#cb22-366" aria-hidden="true" tabindex="-1"></a>\xi_t(i, j) = \frac{\alpha_t(i) \cdot a_{ij} \cdot b_j(o_{t+1}) \cdot \beta_{t+1}(j)}{\sum_{k=1}^{N} \sum_{l=1}^{N} \alpha_t(k) \cdot a_{kl} \cdot b_l(o_{t+1}) \cdot \beta_{t+1}(l)}</span>
<span id="cb22-367"><a href="#cb22-367" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-368"><a href="#cb22-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-369"><a href="#cb22-369" aria-hidden="true" tabindex="-1"></a>The Maximization step:</span>
<span id="cb22-370"><a href="#cb22-370" aria-hidden="true" tabindex="-1"></a>Update the model parameters, including the initial state probabilities, transition probabilities, and emission probabilities.</span>
<span id="cb22-371"><a href="#cb22-371" aria-hidden="true" tabindex="-1"></a>The updated parameters are computed by normalizing the expected counts derived from the E-step.</span>
<span id="cb22-372"><a href="#cb22-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-373"><a href="#cb22-373" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-374"><a href="#cb22-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-375"><a href="#cb22-375" aria-hidden="true" tabindex="-1"></a>\hat{\pi}_i = \gamma_1(i)</span>
<span id="cb22-376"><a href="#cb22-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-377"><a href="#cb22-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-378"><a href="#cb22-378" aria-hidden="true" tabindex="-1"></a>\hat{a}_{ij} = \frac{\sum_{t=1}^{T-1} \xi_t(i, j)}{\sum_{t=1}^{T-1} \gamma_t(i)}</span>
<span id="cb22-379"><a href="#cb22-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-380"><a href="#cb22-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-381"><a href="#cb22-381" aria-hidden="true" tabindex="-1"></a>\hat{b}_i(k) = \frac{\sum_{t=1}^{T} \gamma_t(i) \cdot \delta_{o_t, k}}{\sum_{t=1}^{T} \gamma_t(i)}</span>
<span id="cb22-382"><a href="#cb22-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-383"><a href="#cb22-383" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-384"><a href="#cb22-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-385"><a href="#cb22-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-388"><a href="#cb22-388" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-389"><a href="#cb22-389" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(a, b, pi, sequence, states, key, n_iterations <span class="op">=</span> <span class="dv">100</span>, tol<span class="op">=</span><span class="fl">1e-6</span>):</span>
<span id="cb22-390"><a href="#cb22-390" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Baum-Welch algorithm for HMM</span></span>
<span id="cb22-391"><a href="#cb22-391" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate gamma, xi, and then update a and b parameters</span></span>
<span id="cb22-392"><a href="#cb22-392" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb22-393"><a href="#cb22-393" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb22-394"><a href="#cb22-394" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-395"><a href="#cb22-395" aria-hidden="true" tabindex="-1"></a>    <span class="co"># M is the number of possible observations i.e. number of columns</span></span>
<span id="cb22-396"><a href="#cb22-396" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> b.shape[<span class="dv">1</span>]</span>
<span id="cb22-397"><a href="#cb22-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-398"><a href="#cb22-398" aria-hidden="true" tabindex="-1"></a>    prev_log_likelihood <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-399"><a href="#cb22-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-400"><a href="#cb22-400" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb22-401"><a href="#cb22-401" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> forward(states, sequence, a, b, pi, key)</span>
<span id="cb22-402"><a href="#cb22-402" aria-hidden="true" tabindex="-1"></a>        beta <span class="op">=</span> backward(states, sequence, a, b)</span>
<span id="cb22-403"><a href="#cb22-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-404"><a href="#cb22-404" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Alpha: </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-405"><a href="#cb22-405" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Beta:</span><span class="sc">{</span>beta<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-406"><a href="#cb22-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-407"><a href="#cb22-407" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb22-408"><a href="#cb22-408" aria-hidden="true" tabindex="-1"></a>        pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb22-409"><a href="#cb22-409" aria-hidden="true" tabindex="-1"></a>        gamma <span class="op">=</span> alpha <span class="op">*</span> beta</span>
<span id="cb22-410"><a href="#cb22-410" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(gamma)</span></span>
<span id="cb22-411"><a href="#cb22-411" aria-hidden="true" tabindex="-1"></a>        denominator <span class="op">=</span> np.<span class="bu">sum</span>(gamma, axis<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>) <span class="co"># same for all i</span></span>
<span id="cb22-412"><a href="#cb22-412" aria-hidden="true" tabindex="-1"></a>        gamma <span class="op">=</span> gamma<span class="op">/</span>denominator <span class="op">+</span> pseudocount</span>
<span id="cb22-413"><a href="#cb22-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-414"><a href="#cb22-414" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"gamma:</span><span class="sc">{</span>gamma<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb22-415"><a href="#cb22-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-416"><a href="#cb22-416" aria-hidden="true" tabindex="-1"></a>        xi <span class="op">=</span> np.zeros((N, N, T <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb22-417"><a href="#cb22-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-418"><a href="#cb22-418" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb22-419"><a href="#cb22-419" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb22-420"><a href="#cb22-420" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb22-421"><a href="#cb22-421" aria-hidden="true" tabindex="-1"></a>                    numerator <span class="op">=</span> alpha[i, t] <span class="op">*</span> a[i, j] <span class="op">*</span> b[j, <span class="bu">int</span>(sequence[t <span class="op">+</span> <span class="dv">1</span>])] <span class="op">*</span> beta[j, t <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb22-422"><a href="#cb22-422" aria-hidden="true" tabindex="-1"></a>                    denominator <span class="op">=</span> np.<span class="bu">sum</span>(alpha[k, t] <span class="op">*</span> a[k, l] <span class="op">*</span> b[l, <span class="bu">int</span>(sequence[t <span class="op">+</span> <span class="dv">1</span>])] <span class="op">*</span> beta[l, t <span class="op">+</span> <span class="dv">1</span>] <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(N) <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(N))</span>
<span id="cb22-423"><a href="#cb22-423" aria-hidden="true" tabindex="-1"></a>                    xi[i, j, t] <span class="op">=</span> (numerator <span class="op">/</span> denominator) <span class="op">+</span> pseudocount</span>
<span id="cb22-424"><a href="#cb22-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-425"><a href="#cb22-425" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Xi: </span><span class="sc">{</span>xi<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-426"><a href="#cb22-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-427"><a href="#cb22-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-428"><a href="#cb22-428" aria-hidden="true" tabindex="-1"></a>        <span class="co"># update a and b</span></span>
<span id="cb22-429"><a href="#cb22-429" aria-hidden="true" tabindex="-1"></a>        <span class="co"># M-step</span></span>
<span id="cb22-430"><a href="#cb22-430" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb22-431"><a href="#cb22-431" aria-hidden="true" tabindex="-1"></a><span class="co">        sequence == k creates a boolean array of the same length as sequence, where each element is True if the corresponding element in sequence is equal to k, and False otherwise.</span></span>
<span id="cb22-432"><a href="#cb22-432" aria-hidden="true" tabindex="-1"></a><span class="co">    mask = (sequence == k) assigns this boolean array to the variable mask.</span></span>
<span id="cb22-433"><a href="#cb22-433" aria-hidden="true" tabindex="-1"></a><span class="co">    In the context of the Baum-Welch algorithm or similar algorithms for Hidden Markov Models (HMMs), this kind of mask is often used to select specific observations in the computation of probabilities. For example, </span></span>
<span id="cb22-434"><a href="#cb22-434" aria-hidden="true" tabindex="-1"></a><span class="co">    it might be used to sum over only the observations that match a particular value, which is relevant when updating the emission matrix b.</span></span>
<span id="cb22-435"><a href="#cb22-435" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb22-436"><a href="#cb22-436" aria-hidden="true" tabindex="-1"></a>        <span class="co"># a = (np.sum(xi, axis=2) + pseudocount)/ np.sum(gamma[:, :-1], axis=1, keepdims=True) </span></span>
<span id="cb22-437"><a href="#cb22-437" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):  <span class="co"># N is the number of states</span></span>
<span id="cb22-438"><a href="#cb22-438" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):  <span class="co"># N is the number of states</span></span>
<span id="cb22-439"><a href="#cb22-439" aria-hidden="true" tabindex="-1"></a>                numerator <span class="op">=</span> np.<span class="bu">sum</span>(xi[i, j, :])</span>
<span id="cb22-440"><a href="#cb22-440" aria-hidden="true" tabindex="-1"></a>                denominator <span class="op">=</span> np.<span class="bu">sum</span>(gamma[i, :])</span>
<span id="cb22-441"><a href="#cb22-441" aria-hidden="true" tabindex="-1"></a>                a[i, j] <span class="op">=</span> (numerator<span class="op">+</span>pseudocount) <span class="op">/</span> (denominator<span class="op">+</span>pseudocount) </span>
<span id="cb22-442"><a href="#cb22-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-443"><a href="#cb22-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-444"><a href="#cb22-444" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> np.zeros((N, M))</span>
<span id="cb22-445"><a href="#cb22-445" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(gamma.shape)</span></span>
<span id="cb22-446"><a href="#cb22-446" aria-hidden="true" tabindex="-1"></a>        gamma_sum <span class="op">=</span> np.<span class="bu">sum</span>(gamma, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-447"><a href="#cb22-447" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-448"><a href="#cb22-448" aria-hidden="true" tabindex="-1"></a>        obs <span class="op">=</span> []</span>
<span id="cb22-449"><a href="#cb22-449" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> sequence:</span>
<span id="cb22-450"><a href="#cb22-450" aria-hidden="true" tabindex="-1"></a>            obs.append(<span class="bu">int</span>(i))</span>
<span id="cb22-451"><a href="#cb22-451" aria-hidden="true" tabindex="-1"></a>        obs <span class="op">=</span> np.array(obs)</span>
<span id="cb22-452"><a href="#cb22-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-453"><a href="#cb22-453" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb22-454"><a href="#cb22-454" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb22-455"><a href="#cb22-455" aria-hidden="true" tabindex="-1"></a>                mask <span class="op">=</span> (obs<span class="op">==</span>k) <span class="co"># for indicative function i.e. 1 if observed = yt, else 0</span></span>
<span id="cb22-456"><a href="#cb22-456" aria-hidden="true" tabindex="-1"></a>                b[j, k] <span class="op">=</span> (np.<span class="bu">sum</span>(gamma[j]<span class="op">*</span>mask)<span class="op">+</span> pseudocount) <span class="op">/</span> (np.<span class="bu">sum</span>(gamma[j]) <span class="op">+</span> pseudocount) </span>
<span id="cb22-457"><a href="#cb22-457" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-458"><a href="#cb22-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-459"><a href="#cb22-459" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize rows to ensure each row sums to 1.0</span></span>
<span id="cb22-460"><a href="#cb22-460" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> a <span class="op">/</span> np.<span class="bu">sum</span>(a, axis<span class="op">=</span><span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb22-461"><a href="#cb22-461" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> b <span class="op">/</span> np.<span class="bu">sum</span>(b, axis<span class="op">=</span><span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb22-462"><a href="#cb22-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-463"><a href="#cb22-463" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"a = </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">, b = </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-464"><a href="#cb22-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-465"><a href="#cb22-465" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Log Likelihood Calculation</span></span>
<span id="cb22-466"><a href="#cb22-466" aria-hidden="true" tabindex="-1"></a>        log_likelihood <span class="op">=</span> np.<span class="bu">sum</span>(np.log(np.<span class="bu">sum</span>(alpha, axis<span class="op">=</span><span class="dv">0</span>)))</span>
<span id="cb22-467"><a href="#cb22-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-468"><a href="#cb22-468" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convergence Check</span></span>
<span id="cb22-469"><a href="#cb22-469" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.<span class="bu">abs</span>(log_likelihood <span class="op">-</span> prev_log_likelihood) <span class="op">&lt;</span> tol:</span>
<span id="cb22-470"><a href="#cb22-470" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Converged after </span><span class="sc">{</span>iteration <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> iterations."</span>)</span>
<span id="cb22-471"><a href="#cb22-471" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb22-472"><a href="#cb22-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-473"><a href="#cb22-473" aria-hidden="true" tabindex="-1"></a>        prev_log_likelihood <span class="op">=</span> log_likelihood</span>
<span id="cb22-474"><a href="#cb22-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-475"><a href="#cb22-475" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a, b, pi</span>
<span id="cb22-476"><a href="#cb22-476" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb22-477"><a href="#cb22-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-478"><a href="#cb22-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-479"><a href="#cb22-479" aria-hidden="true" tabindex="-1"></a>The Viterbi algorithm is a dynamic programming algorithm used for decoding Hidden Markov Models (HMMs) and finding the most likely sequence of hidden states given an observed sequence. </span>
<span id="cb22-480"><a href="#cb22-480" aria-hidden="true" tabindex="-1"></a>The algorithm efficiently determines the optimal state sequence by considering the probabilities of transitions and emissions.</span>
<span id="cb22-481"><a href="#cb22-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-482"><a href="#cb22-482" aria-hidden="true" tabindex="-1"></a>The core idea behind the Viterbi algorithm is to iteratively compute the most likely path to each state at each time step, incorporating both the current observation and the previously calculated probabilities.</span>
<span id="cb22-483"><a href="#cb22-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-484"><a href="#cb22-484" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-485"><a href="#cb22-485" aria-hidden="true" tabindex="-1"></a>Î´_i(t) = max_j Î´_j(t - 1) a_ji b_i(Y_t)</span>
<span id="cb22-486"><a href="#cb22-486" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-487"><a href="#cb22-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-488"><a href="#cb22-488" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-489"><a href="#cb22-489" aria-hidden="true" tabindex="-1"></a>Ïˆ_i(t) = argmax_j Î´_j(t - 1) a_ji</span>
<span id="cb22-490"><a href="#cb22-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb22-491"><a href="#cb22-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-494"><a href="#cb22-494" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb22-495"><a href="#cb22-495" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(sequence, states, a, b, pi):</span>
<span id="cb22-496"><a href="#cb22-496" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Makes use of the viterbi algorithm to predict best path</span></span>
<span id="cb22-497"><a href="#cb22-497" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize Variables</span></span>
<span id="cb22-498"><a href="#cb22-498" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(sequence)</span>
<span id="cb22-499"><a href="#cb22-499" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(states)</span>
<span id="cb22-500"><a href="#cb22-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-501"><a href="#cb22-501" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pseudocount to handle zeros</span></span>
<span id="cb22-502"><a href="#cb22-502" aria-hidden="true" tabindex="-1"></a>    pseudocount <span class="op">=</span> <span class="fl">1e-100</span></span>
<span id="cb22-503"><a href="#cb22-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-504"><a href="#cb22-504" aria-hidden="true" tabindex="-1"></a>    viterbi_table <span class="op">=</span> np.zeros((N, T)) <span class="co"># delta</span></span>
<span id="cb22-505"><a href="#cb22-505" aria-hidden="true" tabindex="-1"></a>    backpointer <span class="op">=</span> np.zeros((N, T)) <span class="co"># psi</span></span>
<span id="cb22-506"><a href="#cb22-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-507"><a href="#cb22-507" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialization step, for t = 0</span></span>
<span id="cb22-508"><a href="#cb22-508" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">int</span>(sequence[<span class="dv">0</span>]))</span>
<span id="cb22-509"><a href="#cb22-509" aria-hidden="true" tabindex="-1"></a>    viterbi_table[:, <span class="dv">0</span>] <span class="op">=</span> pi <span class="op">*</span> b[:, <span class="bu">int</span>(sequence[<span class="dv">0</span>])] <span class="op">+</span> pseudocount</span>
<span id="cb22-510"><a href="#cb22-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-511"><a href="#cb22-511" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate Probabilities</span></span>
<span id="cb22-512"><a href="#cb22-512" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, T):</span>
<span id="cb22-513"><a href="#cb22-513" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb22-514"><a href="#cb22-514" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb22-515"><a href="#cb22-515" aria-hidden="true" tabindex="-1"></a>            max_prob <span class="op">=</span> <span class="bu">max</span>(viterbi_table[prev_s][t<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> a[prev_s][s] <span class="cf">for</span> prev_s <span class="kw">in</span> <span class="bu">range</span>(N)) <span class="op">*</span> b[s][<span class="bu">int</span>(sequence[t])] </span>
<span id="cb22-516"><a href="#cb22-516" aria-hidden="true" tabindex="-1"></a>            viterbi_table[s][t] <span class="op">=</span> max_prob <span class="op">+</span> pseudocount</span>
<span id="cb22-517"><a href="#cb22-517" aria-hidden="true" tabindex="-1"></a>            backpointer[s][t] <span class="op">=</span> np.argmax([viterbi_table[prev_s][t<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> a[prev_s][s]<span class="cf">for</span> prev_s <span class="kw">in</span> <span class="bu">range</span>(N)])</span>
<span id="cb22-518"><a href="#cb22-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-519"><a href="#cb22-519" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Traceback and Find Best Path</span></span>
<span id="cb22-520"><a href="#cb22-520" aria-hidden="true" tabindex="-1"></a>    best_path <span class="op">=</span> []</span>
<span id="cb22-521"><a href="#cb22-521" aria-hidden="true" tabindex="-1"></a>    last_state <span class="op">=</span> np.argmax(viterbi_table[:, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb22-522"><a href="#cb22-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-523"><a href="#cb22-523" aria-hidden="true" tabindex="-1"></a>    best_path.append(last_state)</span>
<span id="cb22-524"><a href="#cb22-524" aria-hidden="true" tabindex="-1"></a>    best_prob <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb22-525"><a href="#cb22-525" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb22-526"><a href="#cb22-526" aria-hidden="true" tabindex="-1"></a>        last_state <span class="op">=</span> last_state <span class="op">=</span> np.argmax(viterbi_table[:, t])</span>
<span id="cb22-527"><a href="#cb22-527" aria-hidden="true" tabindex="-1"></a>        best_prob <span class="op">*=</span> (viterbi_table[last_state, t] <span class="op">+</span> pseudocount)</span>
<span id="cb22-528"><a href="#cb22-528" aria-hidden="true" tabindex="-1"></a>        best_path.append(last_state) <span class="co"># i.e. add to start of list</span></span>
<span id="cb22-529"><a href="#cb22-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-530"><a href="#cb22-530" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-531"><a href="#cb22-531" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_path</span>
<span id="cb22-532"><a href="#cb22-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-533"><a href="#cb22-533" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>