{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(states, sequence, a, b, pi, key):\n",
    "    N = len(states)\n",
    "    T = len(sequence)\n",
    "    pi = pi[key] # prob of state i, since 2 states, let's half it be 0.5, 0.5 initially\n",
    "    i = key # holds the first state\n",
    "\n",
    "    # Pseudocount to handle zeros\n",
    "    pseudocount = 1e-10\n",
    "    # for all possible states, and the first actual state (alpha)\n",
    "    # i.e. alpha i for all i has been caluclated given yt\n",
    "    alpha = np.zeros((N, T))\n",
    "    alpha[:,0] = pi * b[:,int(sequence[0])] + pseudocount\n",
    "\n",
    "\n",
    "    # next, we have to do iterations to calculate alpha at different times t\n",
    "    # we need all alpha values since it is going to be summed up to calculate gamma\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            alpha[j][t] = sum(alpha[i][t-1]*a[i][j]*b[j][int(sequence[t])] for i in range(N)) + pseudocount\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(states, sequence, a, b):\n",
    "    N = len(states)\n",
    "    T = len(sequence)\n",
    "    beta = np.zeros((N, T))\n",
    "\n",
    "    # Pseudocount to handle zeros\n",
    "    pseudocount = 1e-10\n",
    "\n",
    "    # Initialization\n",
    "    beta[:, -1] = 1  # Set the last column to 1\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        for i in range(N):\n",
    "            beta[i, t] = sum(a[i, j] * b[j, int(sequence[t + 1])] * beta[j, t + 1] for j in range(N)) + pseudocount\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(a, b, pi, sequence, states, key, n_iterations = 100, tol=1e-6):\n",
    "    #Baum-Welch algorithm for HMM\n",
    "    # calculate gamma, xi, and then update a and b parameters\n",
    "    N = len(states)\n",
    "    T = len(sequence)\n",
    "    \n",
    "    # M is the number of possible observations i.e. number of columns\n",
    "    M = b.shape[1]\n",
    "\n",
    "    prev_log_likelihood = 0\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        alpha = forward(states, sequence, a, b, pi, key)\n",
    "        beta = backward(states, sequence, a, b)\n",
    "\n",
    "        print(f\"Alpha: {alpha}\")\n",
    "        print(f\"Beta:{beta}\")\n",
    "\n",
    "        # Pseudocount to handle zeros\n",
    "        pseudocount = 1e-10\n",
    "        gamma = alpha * beta\n",
    "        # print(gamma)\n",
    "        denominator = np.sum(gamma, axis=0, keepdims=True) # same for all i\n",
    "        gamma = gamma/denominator + pseudocount\n",
    "\n",
    "        print(f\"gamma:{gamma}\") \n",
    "\n",
    "        xi = np.zeros((N, N, T - 1))\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                for t in range(T - 1):\n",
    "                    numerator = alpha[i, t] * a[i, j] * b[j, int(sequence[t + 1])] * beta[j, t + 1]\n",
    "                    denominator = np.sum(alpha[k, t] * a[k, l] * b[l, int(sequence[t + 1])] * beta[l, t + 1] for k in range(N) for l in range(N))\n",
    "                    xi[i, j, t] = (numerator / denominator) + pseudocount\n",
    "\n",
    "        print(f\"Xi: {xi}\")\n",
    "\n",
    "\n",
    "        # update a and b\n",
    "        # M-step\n",
    "        '''\n",
    "        sequence == k creates a boolean array of the same length as sequence, where each element is True if the corresponding element in sequence is equal to k, and False otherwise.\n",
    "    mask = (sequence == k) assigns this boolean array to the variable mask.\n",
    "    In the context of the Baum-Welch algorithm or similar algorithms for Hidden Markov Models (HMMs), this kind of mask is often used to select specific observations in the computation of probabilities. For example, \n",
    "    it might be used to sum over only the observations that match a particular value, which is relevant when updating the emission matrix b.\n",
    "        '''\n",
    "        # a = (np.sum(xi, axis=2) + pseudocount)/ np.sum(gamma[:, :-1], axis=1, keepdims=True) \n",
    "        for i in range(N):  # N is the number of states\n",
    "            for j in range(N):  # N is the number of states\n",
    "                numerator = np.sum(xi[i, j, :])\n",
    "                denominator = np.sum(gamma[i, :])\n",
    "                a[i, j] = (numerator+pseudocount) / (denominator+pseudocount) \n",
    "\n",
    "\n",
    "        b = np.zeros((N, M))\n",
    "        # print(gamma.shape)\n",
    "        gamma_sum = np.sum(gamma, axis=1)\n",
    "        \n",
    "        obs = []\n",
    "        for i in sequence:\n",
    "            obs.append(int(i))\n",
    "        obs = np.array(obs)\n",
    "\n",
    "        for j in range(N):\n",
    "            for k in range(M):\n",
    "                mask = (obs==k) # for indicative function i.e. 1 if observed = yt, else 0\n",
    "                b[j, k] = (np.sum(gamma[j]*mask)+ pseudocount) / (np.sum(gamma[j]) + pseudocount) \n",
    "        \n",
    "\n",
    "        # Normalize rows to ensure each row sums to 1.0\n",
    "        a = a / np.sum(a, axis=1)[:, np.newaxis]\n",
    "        b = b / np.sum(b, axis=1)[:, np.newaxis]\n",
    "\n",
    "        print(f\"a = {a}, b = {b}\")\n",
    "\n",
    "        # Log Likelihood Calculation\n",
    "        log_likelihood = np.sum(np.log(np.sum(alpha, axis=0)))\n",
    "\n",
    "        # Convergence Check\n",
    "        if np.abs(log_likelihood - prev_log_likelihood) < tol:\n",
    "            print(f\"Converged after {iteration + 1} iterations.\")\n",
    "            break\n",
    "\n",
    "        prev_log_likelihood = log_likelihood\n",
    "\n",
    "    return a, b, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sequence, states, trained_A, trained_B, pi):\n",
    "    # Makes use of the viterbi algorithm to predict best path\n",
    "    # Initialize Variables\n",
    "    T = len(sequence)\n",
    "    N = len(states)\n",
    "\n",
    "    # Pseudocount to handle zeros\n",
    "    pseudocount = 1e-10\n",
    "\n",
    "    viterbi_table = np.zeros((N, T)) # delta\n",
    "    backpointer = np.zeros((N, T)) # psi\n",
    "\n",
    "    # Initialization step, for t = 0\n",
    "    print(int(sequence[0]))\n",
    "    viterbi_table[:, 0] = pi * trained_B[:, int(sequence[0])] + pseudocount\n",
    "\n",
    "    # Calculate Probabilities\n",
    "    for t in range(1, T):\n",
    "        for s in range(N):\n",
    "            \n",
    "            max_prob = max(viterbi_table[prev_s][t-1] * a[prev_s][s] for prev_s in range(N)) * b[s][int(sequence[t])] \n",
    "            viterbi_table[s][t] = max_prob + pseudocount\n",
    "            backpointer[s][t] = np.argmax([viterbi_table[prev_s][t-1] * a[prev_s][s]for prev_s in range(N)])\n",
    "\n",
    "    #Traceback and Find Best Path\n",
    "    best_path = []\n",
    "    last_state = np.argmax(viterbi_table[:, -1])\n",
    "\n",
    "    best_path.append(last_state)\n",
    "    best_prob = 1.0\n",
    "    for t in range(T-2, -1, -1):\n",
    "        last_state = last_state = np.argmax(viterbi_table[:, t])\n",
    "        best_prob *= (viterbi_table[last_state, t] + pseudocount)\n",
    "        best_path.append(last_state) # i.e. add to start of list\n",
    "\n",
    "        \n",
    "    return best_path"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
