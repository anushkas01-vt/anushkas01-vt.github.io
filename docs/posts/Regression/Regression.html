<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Anushka S">
<meta name="dcterms.date" content="2023-12-03">

<title>CS5805 - Regression Analysis: Linear Regression and Non-Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">CS5805</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Regression Analysis: Linear Regression and Non-Linear Regression</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Regression</div>
                <div class="quarto-category">Machine Learning</div>
                <div class="quarto-category">Supervised Learning</div>
                <div class="quarto-category">SVM</div>
                <div class="quarto-category">Random Forest</div>
                <div class="quarto-category">Decision Tree</div>
                <div class="quarto-category">Gradient Boost</div>
                <div class="quarto-category">Linear</div>
                <div class="quarto-category">Non-Linear</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Anushka S </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><a href="https://www.ibm.com/topics/supervised-learning#:~:text=Supervised%20learning%2C%20also%20known%20as,data%20or%20predict%20outcomes%20accurately.">Supervised learning</a>, also known as supervised machine learning, is a subcategory of machine learning and artificial intelligence. It is defined by its use of labeled datasets to train algorithms that to classify data or predict outcomes accurately.</p>
<p>Machine Learning Regression is a technique for investigating the relationship between independent variables or features and a dependent variable or outcome. It’s used as a method for predictive modelling in machine learning, in which an algorithm is used to predict continuous outcomes. You can read more about it <a href="https://www.seldon.io/machine-learning-regression-explained#:~:text=Machine%20Learning%20Regression%20is%20a,used%20to%20predict%20continuous%20outcomes.">here!</a></p>
<p>In this blog, we will discuss two types of regression problems, Linear Regression, and Non-Linear Regression. For each, we will compare a handful of machine learning models (linear and non-linear models) and present their results on evaluation metrics.</p>
<p><strong>Linear Regression</strong> This form of analysis estimates the coefficients of the linear equation, involving one or more independent variables that best predict the value of the dependent variable. Linear regression fits a straight line or surface that minimizes the discrepancies between predicted and actual output values.</p>
<p>We’ll make use of the <a href="https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand">Seoul Bike Sharing dataset</a> which contains count of public bicycles rented per hour in the Seoul Bike Sharing System, with corresponding weather data and holiday information. The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. A sample of the dataset can be seen below. The aim is to predict the bike count required at each hour for the stable supply of rental bikes.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>df_bike <span class="op">=</span> pd.read_csv(<span class="st">"SeoulBikeData.csv"</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>df_bike.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Date</th>
<th data-quarto-table-cell-role="th">Rented Bike Count</th>
<th data-quarto-table-cell-role="th">Hour</th>
<th data-quarto-table-cell-role="th">Temperature(C)</th>
<th data-quarto-table-cell-role="th">Humidity(%)</th>
<th data-quarto-table-cell-role="th">Wind speed (m/s)</th>
<th data-quarto-table-cell-role="th">Visibility (10m)</th>
<th data-quarto-table-cell-role="th">Dew point temperature(C)</th>
<th data-quarto-table-cell-role="th">Solar Radiation (MJ/m2)</th>
<th data-quarto-table-cell-role="th">Rainfall(mm)</th>
<th data-quarto-table-cell-role="th">Snowfall (cm)</th>
<th data-quarto-table-cell-role="th">Seasons</th>
<th data-quarto-table-cell-role="th">Holiday</th>
<th data-quarto-table-cell-role="th">Functioning Day</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>01/12/2017</td>
<td>254</td>
<td>0</td>
<td>-5.2</td>
<td>37</td>
<td>2.2</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>01/12/2017</td>
<td>204</td>
<td>1</td>
<td>-5.5</td>
<td>38</td>
<td>0.8</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>01/12/2017</td>
<td>173</td>
<td>2</td>
<td>-6.0</td>
<td>39</td>
<td>1.0</td>
<td>2000</td>
<td>-17.7</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>01/12/2017</td>
<td>107</td>
<td>3</td>
<td>-6.2</td>
<td>40</td>
<td>0.9</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>01/12/2017</td>
<td>78</td>
<td>4</td>
<td>-6.0</td>
<td>36</td>
<td>2.3</td>
<td>2000</td>
<td>-18.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>It is important to check the dataset for any missing values before it is used for model training and testing.</p>
<div class="cell" data-execution_count="2">
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 8760 entries, 0 to 8759
Data columns (total 14 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Date                      8760 non-null   object 
 1   Rented Bike Count         8760 non-null   int64  
 2   Hour                      8760 non-null   int64  
 3   Temperature(C)            8760 non-null   float64
 4   Humidity(%)               8760 non-null   int64  
 5   Wind speed (m/s)          8760 non-null   float64
 6   Visibility (10m)          8760 non-null   int64  
 7   Dew point temperature(C)  8760 non-null   float64
 8   Solar Radiation (MJ/m2)   8760 non-null   float64
 9   Rainfall(mm)              8760 non-null   float64
 10  Snowfall (cm)             8760 non-null   float64
 11  Seasons                   8760 non-null   object 
 12  Holiday                   8760 non-null   object 
 13  Functioning Day           8760 non-null   object 
dtypes: float64(6), int64(4), object(4)
memory usage: 958.2+ KB
None
Date                        0
Rented Bike Count           0
Hour                        0
Temperature(C)              0
Humidity(%)                 0
Wind speed (m/s)            0
Visibility (10m)            0
Dew point temperature(C)    0
Solar Radiation (MJ/m2)     0
Rainfall(mm)                0
Snowfall (cm)               0
Seasons                     0
Holiday                     0
Functioning Day             0
dtype: int64
Date                        0
Rented Bike Count           0
Hour                        0
Temperature(C)              0
Humidity(%)                 0
Wind speed (m/s)            0
Visibility (10m)            0
Dew point temperature(C)    0
Solar Radiation (MJ/m2)     0
Rainfall(mm)                0
Snowfall (cm)               0
Seasons                     0
Holiday                     0
Functioning Day             0
dtype: int64</code></pre>
</div>
</div>
<p>This dataset seems to have no missing values so we’re good!</p>
<p>Let’s format the dataset to ease data processing down the line. Beginning with breaking down the ‘Date’ into ‘Day’, ‘Month’, and ‘Year’ columns in the dataset.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can break the date into date, month, year columns and convert them into integers (from strings) for the purpose of correlation map</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>days <span class="op">=</span> [<span class="bu">int</span>((df_bike[<span class="st">'Date'</span>].iloc[i])[<span class="dv">0</span>:<span class="dv">2</span>]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_bike))]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>month <span class="op">=</span> [<span class="bu">int</span>((df_bike[<span class="st">'Date'</span>].iloc[i])[<span class="dv">3</span>:<span class="dv">5</span>]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_bike))]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>year <span class="op">=</span> [<span class="bu">int</span>((df_bike[<span class="st">'Date'</span>].iloc[i])[<span class="dv">6</span>:]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_bike))]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>df_bike[<span class="st">'Day'</span>], df_bike[<span class="st">'Month'</span>], df_bike[<span class="st">'Year'</span>] <span class="op">=</span> days, month, year</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>df_bike.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Date</th>
<th data-quarto-table-cell-role="th">Rented Bike Count</th>
<th data-quarto-table-cell-role="th">Hour</th>
<th data-quarto-table-cell-role="th">Temperature(C)</th>
<th data-quarto-table-cell-role="th">Humidity(%)</th>
<th data-quarto-table-cell-role="th">Wind speed (m/s)</th>
<th data-quarto-table-cell-role="th">Visibility (10m)</th>
<th data-quarto-table-cell-role="th">Dew point temperature(C)</th>
<th data-quarto-table-cell-role="th">Solar Radiation (MJ/m2)</th>
<th data-quarto-table-cell-role="th">Rainfall(mm)</th>
<th data-quarto-table-cell-role="th">Snowfall (cm)</th>
<th data-quarto-table-cell-role="th">Seasons</th>
<th data-quarto-table-cell-role="th">Holiday</th>
<th data-quarto-table-cell-role="th">Functioning Day</th>
<th data-quarto-table-cell-role="th">Day</th>
<th data-quarto-table-cell-role="th">Month</th>
<th data-quarto-table-cell-role="th">Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>01/12/2017</td>
<td>254</td>
<td>0</td>
<td>-5.2</td>
<td>37</td>
<td>2.2</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>01/12/2017</td>
<td>204</td>
<td>1</td>
<td>-5.5</td>
<td>38</td>
<td>0.8</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>01/12/2017</td>
<td>173</td>
<td>2</td>
<td>-6.0</td>
<td>39</td>
<td>1.0</td>
<td>2000</td>
<td>-17.7</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>01/12/2017</td>
<td>107</td>
<td>3</td>
<td>-6.2</td>
<td>40</td>
<td>0.9</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>01/12/2017</td>
<td>78</td>
<td>4</td>
<td>-6.0</td>
<td>36</td>
<td>2.3</td>
<td>2000</td>
<td>-18.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Winter</td>
<td>No Holiday</td>
<td>Yes</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Next, we convert string values such as the values in the ‘Seasons’, ‘Functioning Day’, and ‘Holiday’ columns. We are able to do this by mapping the discrete set of string values to a discrete set of integer values.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df1_bike <span class="op">=</span> df_bike.drop(columns <span class="op">=</span> [<span class="st">'Date'</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># map unique season to numbers, map holiday to binary, and functioning day to binary</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>seasons <span class="op">=</span> {}</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(df_bike[<span class="st">'Seasons'</span>].drop_duplicates()):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    seasons[i] <span class="op">=</span> idx</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>holiday <span class="op">=</span> {<span class="st">"No Holiday"</span>: <span class="dv">0</span>, <span class="st">"Holiday"</span>: <span class="dv">1</span>}</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>functioning <span class="op">=</span> {<span class="st">"Yes"</span>: <span class="dv">0</span>, <span class="st">"No"</span>: <span class="dv">1</span>}</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>df1_bike.Holiday <span class="op">=</span> [holiday[item] <span class="cf">for</span> item <span class="kw">in</span> df_bike.Holiday]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>df1_bike.Seasons <span class="op">=</span> [seasons[item] <span class="cf">for</span> item <span class="kw">in</span> df_bike.Seasons]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>df1_bike[<span class="st">'Functioning Day'</span>] <span class="op">=</span> [functioning[item] <span class="cf">for</span> item <span class="kw">in</span> df1_bike[<span class="st">'Functioning Day'</span>] ]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>df1_bike.head(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Rented Bike Count</th>
<th data-quarto-table-cell-role="th">Hour</th>
<th data-quarto-table-cell-role="th">Temperature(C)</th>
<th data-quarto-table-cell-role="th">Humidity(%)</th>
<th data-quarto-table-cell-role="th">Wind speed (m/s)</th>
<th data-quarto-table-cell-role="th">Visibility (10m)</th>
<th data-quarto-table-cell-role="th">Dew point temperature(C)</th>
<th data-quarto-table-cell-role="th">Solar Radiation (MJ/m2)</th>
<th data-quarto-table-cell-role="th">Rainfall(mm)</th>
<th data-quarto-table-cell-role="th">Snowfall (cm)</th>
<th data-quarto-table-cell-role="th">Seasons</th>
<th data-quarto-table-cell-role="th">Holiday</th>
<th data-quarto-table-cell-role="th">Functioning Day</th>
<th data-quarto-table-cell-role="th">Day</th>
<th data-quarto-table-cell-role="th">Month</th>
<th data-quarto-table-cell-role="th">Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>254</td>
<td>0</td>
<td>-5.2</td>
<td>37</td>
<td>2.2</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>204</td>
<td>1</td>
<td>-5.5</td>
<td>38</td>
<td>0.8</td>
<td>2000</td>
<td>-17.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>173</td>
<td>2</td>
<td>-6.0</td>
<td>39</td>
<td>1.0</td>
<td>2000</td>
<td>-17.7</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>12</td>
<td>2017</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Plotting the correlation matrix to identify the relationship, and the strength of relationship between the features(variables) in the dataset and also understand how strongly they are correlated with the target variable which is the rented bike count.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>f, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> df1_bike.corr()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span>sns.diverging_palette(<span class="dv">220</span>, <span class="dv">10</span>, as_cmap<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    vmin<span class="op">=-</span><span class="fl">1.0</span>, vmax<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    square<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-6-output-2.png" width="912" height="800"></p>
</div>
</div>
<p>Below, we can plot visualizations to see how each feature (variable) effects the target: Rented Bike Count.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))<span class="op">;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># hour vs bike count</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Hour'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">0</span>][<span class="dv">0</span>], palette<span class="op">=</span><span class="st">'viridis'</span>)<span class="op">;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>][<span class="dv">0</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Hour'</span>)<span class="op">;</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Functioning vs bike count</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Functioning Day'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">0</span>][<span class="dv">1</span>], palette<span class="op">=</span><span class="st">'inferno'</span>)<span class="op">;</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>][<span class="dv">1</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Functioning Day'</span>)<span class="op">;</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>][<span class="dv">1</span>].set_xticklabels([<span class="st">'Yes'</span>, <span class="st">'No'</span>])</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># season vs bike count</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Seasons'</span>, y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">1</span>][<span class="dv">0</span>], palette<span class="op">=</span><span class="st">'plasma'</span>)<span class="op">;</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>][<span class="dv">0</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Seasons'</span>)<span class="op">;</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>][<span class="dv">0</span>].set_xticklabels([<span class="st">'Winter'</span>, <span class="st">'Spring'</span>, <span class="st">'Summer'</span>, <span class="st">'Autumn'</span>])</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># month vs bike count</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Month'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">1</span>][<span class="dv">1</span>], palette<span class="op">=</span><span class="st">'cividis'</span>)<span class="op">;</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>][<span class="dv">1</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Month '</span>)<span class="op">;</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-7-output-1.png" width="955" height="758"></p>
</div>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>fig,ax<span class="op">=</span>plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>sns.pointplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Hour'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,hue<span class="op">=</span><span class="st">'Seasons'</span>,ax<span class="op">=</span>ax)<span class="op">;</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to seasons and hour of the day'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-8-output-1.png" width="950" height="758"></p>
</div>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))<span class="op">;</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># temperature vs bike count</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert temperature in groups of 5C and average the rented bike counts for that range (rounding to 5s)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>temp_min, temp_max <span class="op">=</span> <span class="bu">round</span>(<span class="bu">min</span>(df1_bike[<span class="st">'Temperature(C)'</span>])<span class="op">/</span><span class="dv">5</span>)<span class="op">*</span><span class="dv">5</span>, <span class="bu">round</span>(<span class="bu">max</span>(df1_bike[<span class="st">'Temperature(C)'</span>])<span class="op">/</span><span class="dv">5</span>)<span class="op">*</span><span class="dv">5</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>dict_temp <span class="op">=</span> {}</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(temp_min, temp_max, <span class="dv">5</span>):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter rows based on the temperature interval</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    filtered_df <span class="op">=</span> df1_bike[(df1_bike[<span class="st">'Temperature(C)'</span>] <span class="op">&gt;=</span> i) <span class="op">&amp;</span> (df1_bike[<span class="st">'Temperature(C)'</span>] <span class="op">&lt;</span> i<span class="op">+</span><span class="dv">5</span>)]</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    dict_temp[i] <span class="op">=</span> filtered_df[<span class="st">'Rented Bike Count'</span>].mean()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print(dict_temp)</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># print(temp_max, temp_min)</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>dict_temp,ax<span class="op">=</span>ax, palette<span class="op">=</span><span class="st">'plasma'</span>)<span class="op">;</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Temperature'</span>)<span class="op">;</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-9-output-1.png" width="950" height="758"></p>
</div>
</div>
<p>Printing the regression plot (Dependent Features vs Target Varibale).</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>fig,ax<span class="op">=</span>plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>)) <span class="co"># since we know there are 16 features</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, col <span class="kw">in</span> <span class="bu">enumerate</span>(df1_bike.columns):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  sns.regplot(x<span class="op">=</span>df1_bike[col],y<span class="op">=</span>df1_bike[<span class="st">'Rented Bike Count'</span>],scatter_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">'blue'</span>}, line_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"black"</span>}, ax<span class="op">=</span>ax[idx<span class="op">//</span><span class="dv">4</span>][idx<span class="op">%</span><span class="dv">4</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-10-output-1.png" width="950" height="950"></p>
</div>
</div>
<p>To train and evaluate the machine learning models we need to split the dataset appropriately into the training and testing datasets. Hence, we perform an 80-20 train-test split here.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df1_bike[<span class="st">'Rented Bike Count'</span>]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> (df1_bike.drop(columns <span class="op">=</span> [<span class="st">'Rented Bike Count'</span>])).to_numpy()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The following are the models used for estimating the number of bikes rented given other data. The code implementations for each can be found in the scikit-learn library (linked for each model), and the model paramters used are default parameters. 1. <em>Linear regression model</em> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear regression</a> is a simple yet powerful algorithm that models the relationship between the input features and the target variable by fitting a linear equation to the observed data. The main algorithm involves finding the coefficients that minimize the sum of squared differences between the predicted and actual values. This is typically achieved using the Ordinary Least Squares (OLS) method, aiming to optimize the line’s parameters to best represent the data points.</p>
<ol start="2" type="1">
<li><p><em>Support Vector Machine (Regressor)</em> In regression tasks, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR">Support Vector Machines</a> (SVM) aim to find the hyperplane that best represents the relationship between the input features and the target variable. The primary algorithm involves identifying the support vectors and determining the optimal hyperplane to maximize the margin while minimizing the error. SVM uses a loss function that penalizes deviations from the regression line, and the algorithm seeks to find the coefficients that minimize this loss.</p></li>
<li><p><em>Ridge Regression</em> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge">Ridge Regression</a> is an extension of linear regression that introduces a regularization term to prevent overfitting. The main algorithm involves adding a penalty term to the linear regression objective function, which is proportional to the square of the L2 norm of the coefficients. This regularization term helps stabilize the model by shrinking the coefficients, particularly useful when dealing with multicollinearity.</p></li>
<li><p><em>Lasso Regression</em> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso">Lasso Regression</a>, similar to Ridge Regression, introduces regularization to linear regression. The main algorithm incorporates a penalty term, but in this case, it is proportional to the absolute value of the L1 norm of the coefficients. Lasso regression is effective for feature selection as it tends to produce sparse coefficient vectors, driving some coefficients to exactly zero.</p></li>
<li><p><em>Gradient Boosting Regressor</em> <a href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html">Gradient Boosting Regressor</a> is an ensemble learning method that builds a series of decision trees sequentially. The main algorithm involves fitting a weak learner (usually a shallow decision tree) to the residuals of the previous trees. The predictions of individual trees are combined to improve overall accuracy. The algorithm minimizes a loss function by adjusting the weights of the weak learners.</p></li>
<li><p><em>Random Forest Regressor</em> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">Random Forest Regressor</a> is an ensemble learning method that constructs multiple decision trees during training. The main algorithm involves training each tree on a random subset of the training data and features. The predictions of individual trees are then averaged or aggregated to reduce overfitting and improve generalization. Random Forest leverages the diversity among trees for robust predictions.</p></li>
<li><p><em>Decision Tree Regressor</em> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor">Decision Tree Regressor</a> models the relationship between input features and the target variable by recursively splitting the data based on feature thresholds. The main algorithm involves selecting the best split at each node to minimize the variance of the target variable. Decision trees are constructed until a stopping criterion is met, creating a tree structure that facilitates predictive modeling.</p></li>
</ol>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> linear_model</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score, explained_variance_score</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>model_names <span class="op">=</span> [<span class="st">'Linear Regression Model'</span>,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a> <span class="st">'Support Vector Machine (Regression)'</span>,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a> <span class="st">'Ridge Regression'</span>,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Lasso Regression'</span>,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a> <span class="st">'Gradient Boosting Regression'</span>,</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Random Forest'</span>,</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Decision Tree'</span>]</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [LinearRegression(),</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    SVR(), </span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    linear_model.Ridge(), </span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    linear_model.Lasso(),</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    GradientBoostingRegressor(),</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    RandomForestRegressor(),</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    DecisionTreeRegressor()]</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>evaluation_metrics <span class="op">=</span> [<span class="st">'Mean Squared Error (MSE)'</span>,</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a> <span class="st">'Root MSE (RMSE)'</span>,</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Mean Absolute Error'</span>,</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>  <span class="st">'R2 Score'</span>, </span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Explained Variance Score'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The model is fit on the training data, and predicted for the testing data. Regression models are commonly evaluated on the following metrics: 1. <em>Mean Squared Error (MSE)</em>: MSE calculates the average squared difference between the predicted and actual values, providing a measure of the model’s precision. $ = _{i=1}^{n} (y_i - _i)^2$</p>
<ol start="2" type="1">
<li><p><em>Root Mean Squared Error (RMSE)</em>: RMSE is the square root of MSE and represents the average magnitude of the residuals in the same units as the target variable. $ = $</p></li>
<li><p><em>Mean Absolute Error (MAE)</em>: MAE calculates the average absolute difference between the predicted and actual values, providing a measure of the model’s accuracy. $ = _{i=1}^{n} |y_i - _i|$</p></li>
<li><p><em>R2 Score</em>: R2 Score, or the coefficient of determination, measures the proportion of the variance in the dependent variable that is predictable from the independent variables. $ R^2 = 1 - where is the sum of squared residuals, and is the total sum of squares.$</p></li>
<li><p><em>Explained Variance Score</em>: The Explained Variance Score measures the proportion by which the model’s variance is reduced compared to a simple mean baseline. $ = 1 - where where y is the actual values and is the predicted values$</p></li>
</ol>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>y_preds <span class="op">=</span> [] <span class="co"># list of model predictions</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>model_scores <span class="op">=</span> [] <span class="co"># list of model scores based on the evaluation metrics defined</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> models:</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    reg <span class="op">=</span> model</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    reg.fit(X_train, y_train)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    y_preds.append(y_pred)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_test.values, y_pred)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test.values, y_pred)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test.values, y_pred)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    evs <span class="op">=</span> explained_variance_score(y_test.values, y_pred)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    model_scores.append([mse, rmse, mae, r2, evs])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us visualize the outputs of the linear models ‘Linear Regression Model’,‘Support Vector Machine (Regression)’, ‘Ridge Regression’, and ‘Lasso Regression’. and evaluate the results.</p>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> [<span class="dv">10</span>,<span class="dv">7</span>]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'tight'</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'off'</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>table1 <span class="op">=</span> axs.table(cellText<span class="op">=</span>model_scores[<span class="dv">0</span>:<span class="dv">4</span>],</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>                      cellLoc <span class="op">=</span> <span class="st">'left'</span>,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>                      rowLabels <span class="op">=</span> model_names[<span class="dv">0</span>:<span class="dv">4</span>],</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                      rowColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>                      colLabels<span class="op">=</span>evaluation_metrics,</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>                      colColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>                      loc<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight cells with minimum value in each column</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col_idx, metric <span class="kw">in</span> <span class="bu">enumerate</span>(evaluation_metrics):</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    col_values <span class="op">=</span> [row[col_idx] <span class="cf">for</span> row <span class="kw">in</span> model_scores[<span class="dv">0</span>:<span class="dv">4</span>]]</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    min_value_idx <span class="op">=</span> col_values.index(<span class="bu">min</span>(col_values))</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight the cell with minimum value in coral color</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    table1[min_value_idx <span class="op">+</span> <span class="dv">1</span>, col_idx].set_facecolor(<span class="st">"coral"</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>table1.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>table1.set_fontsize(<span class="dv">14</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>table1.scale(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-14-output-1.png" width="950" height="662"></p>
</div>
</div>
<p>Now, let us compare the performance of the linear models against non linear models on Linear Regression.</p>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">7</span>]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'tight'</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'off'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>table2 <span class="op">=</span> axs.table(cellText<span class="op">=</span>model_scores,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                      cellLoc <span class="op">=</span> <span class="st">'left'</span>,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>                      rowLabels <span class="op">=</span> model_names,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>                      rowColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                      colLabels<span class="op">=</span>evaluation_metrics,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>                      colColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>                      loc<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight cells with minimum value in each column</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col_idx, metric <span class="kw">in</span> <span class="bu">enumerate</span>(evaluation_metrics):</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    col_values <span class="op">=</span> [row[col_idx] <span class="cf">for</span> row <span class="kw">in</span> model_scores]</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    min_value_idx <span class="op">=</span> col_values.index(<span class="bu">min</span>(col_values))</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight the cell with minimum value in coral color</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    table2[min_value_idx <span class="op">+</span> <span class="dv">1</span>, col_idx].set_facecolor(<span class="st">"coral"</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>table2.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>table2.set_fontsize(<span class="dv">14</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>table2.scale(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-15-output-1.png" width="950" height="662"></p>
</div>
</div>
<p>As we can see, non-linear models, due to their complex structure and abilty to map and analyze/learn from complex data, perform better on this task. However, it is not always that non-linear models are better than linear models since we must keep in mind the computational expense and efficiency of a model for a task, as well as the <a href="https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html">bias-variance</a> tradeoff which again, is dependent not only on the model but also on the dataset/application at hand.</p>
<p>Analysing the difference between the actual and predicted values for the regression task by each model on 3 randomly chosen data points.</p>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># printing how far the predicted value is to the actual value for a random row in X</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))<span class="op">;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>length <span class="op">=</span> <span class="bu">len</span>(model_names)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> random.randint(<span class="dv">0</span>,<span class="bu">len</span>(y_test)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(length), [(y_test.values)[idx]]<span class="op">*</span>length, label<span class="op">=</span><span class="st">'True Value'</span>)<span class="op">;</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    plt.scatter(<span class="bu">range</span>(length), [y_preds[q][idx] <span class="cf">for</span> q <span class="kw">in</span> <span class="bu">range</span>(length)], label<span class="op">=</span><span class="st">'Predicted Values'</span>)<span class="op">;</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(length):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        plt.plot([j, j], [(y_test.values)[idx], y_preds[j][idx]], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(length), model_names)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-16-output-1.png" width="940" height="469"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-16-output-2.png" width="940" height="661"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-16-output-3.png" width="940" height="661"></p>
</div>
</div>
<p><strong>Non Linear Regression</strong> <a href="https://www.mathworks.com/discovery/nonlinear-regression.html">Nonlinear regression</a> is a statistical technique that helps describe nonlinear relationships in experimental data. Nonlinear regression models are generally assumed to be parametric, where the model is described as a nonlinear equation. Typically machine learning methods are used for non-parametric nonlinear regression. Parametric nonlinear regression models the dependent variable (also called the response) as a function of a combination of nonlinear parameters and one or more independent variables (called predictors). The model can be univariate (single response variable) or multivariate (multiple response variables).The parameters can take the form of an exponential, trigonometric, power, or any other nonlinear function.</p>
<p>The non-linear <a href="https://github.com/Lawrence-Krukrubo">dataset</a> models China’s GDP value for each year from 1960-2014. A sample of the dataset and the dataset visualization can be seen below.</p>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_gdp <span class="op">=</span> pd.read_csv(<span class="st">"China_GDP.csv"</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_gdp.info())</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_gdp.isna().<span class="bu">sum</span>())</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>df_gdp.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 55 entries, 0 to 54
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   Year    55 non-null     int64  
 1   Value   55 non-null     float64
dtypes: float64(1), int64(1)
memory usage: 1008.0 bytes
None
Year     0
Value    0
dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Year</th>
<th data-quarto-table-cell-role="th">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1960</td>
<td>5.918412e+10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1961</td>
<td>4.955705e+10</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1962</td>
<td>4.668518e+10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1963</td>
<td>5.009730e+10</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1964</td>
<td>5.906225e+10</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Year vs GDP_value</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df_gdp, x <span class="op">=</span> <span class="st">'Value'</span>, y <span class="op">=</span> <span class="st">'Year'</span>)<span class="op">;</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-18-output-1.png" width="950" height="662"></p>
</div>
</div>
<p>We try to apply a regression line plot for the data. We see that the regression line is not able to accurately capture a linear relationship due to the non-linear relationship between the variables.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression line plot</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>sns.regplot(x<span class="op">=</span>df_gdp[<span class="st">'Value'</span>],y<span class="op">=</span>df_gdp[<span class="st">'Year'</span>],scatter_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">'blue'</span>}, line_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"black"</span>})</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-19-output-1.png" width="950" height="662"></p>
</div>
</div>
<p>Splitting the dataset into 80-20 training-testing set to train and evaluate the aforementioned models.</p>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_gdp[<span class="st">'Year'</span>]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> (df_gdp.drop(columns <span class="op">=</span> [<span class="st">'Year'</span>])).to_numpy()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can plot the training set points as well as the true test set points and predicted test set points for each model (Linear and Non-Linear) to visualize model accuracy and performance. Again, we see that the linear models struggle to accurately predict the target value for a non-linear dataset.</p>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, model <span class="kw">in</span> <span class="bu">enumerate</span>(models[<span class="dv">0</span>:<span class="dv">4</span>]):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    reg <span class="op">=</span> model</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    reg.fit(X_train, y_train)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for training set</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].scatter(X_train, y_train, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Train'</span>)<span class="op">;</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (true)</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].scatter(X_test, y_test, color<span class="op">=</span><span class="st">'purple'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'True'</span>)<span class="op">;</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (predicted)</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].scatter(X_test, y_pred, color<span class="op">=</span><span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>)<span class="op">;</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].set_title(model_names[idx])</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].set_xlabel(<span class="st">"GDP"</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].set_xlabel(<span class="st">"Year"</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].legend()</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"True vs Predicted Performance of Linear Regression Models"</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-21-output-1.png" width="979" height="950"></p>
</div>
</div>
<p>However, the complex, non-linear models are able to capture and analyze the non-linearity and predict the target variable value more accurately.</p>
<div class="cell" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>y_preds <span class="op">=</span> [] <span class="co"># list of model predictions</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>model_scores <span class="op">=</span> [] <span class="co"># list of model scores based on the evaluation metrics defined</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, model <span class="kw">in</span> <span class="bu">enumerate</span>(models[<span class="dv">4</span>:]):</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    reg <span class="op">=</span> model</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    reg.fit(X_train, y_train)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for training set</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(X_train, y_train, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Train'</span>)<span class="op">;</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (true)</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(X_test, y_test, color<span class="op">=</span><span class="st">'purple'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'True'</span>)<span class="op">;</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (predicted)</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(X_test, y_pred, color<span class="op">=</span><span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>)<span class="op">;</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_title(model_names[<span class="dv">4</span><span class="op">+</span>idx])</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_xlabel(<span class="st">"GDP"</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_xlabel(<span class="st">"Year"</span>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    ax[idx].legend()</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    y_preds.append(y_pred)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_test.values, y_pred)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test.values, y_pred)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test.values, y_pred)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    evs <span class="op">=</span> explained_variance_score(y_test.values, y_pred)</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>    model_scores.append([mse, rmse, mae, r2, evs])</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"True vs Predicted Performance of Non-Linear Regression Models"</span>)</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-22-output-1.png" width="950" height="950"></p>
</div>
</div>
<p>We chart the model performance for the non-linear models. The models used for non-linear regression are <em>Random Forest Regressor</em>, <em>Decision Tree Regressor</em>, and <em>Gradient Boost Regressor</em>.</p>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">7</span>]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'tight'</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'off'</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>table1 <span class="op">=</span> axs.table(cellText<span class="op">=</span>model_scores,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                      cellLoc <span class="op">=</span> <span class="st">'left'</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>                      rowLabels <span class="op">=</span> model_names[<span class="dv">4</span>:],</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>                      rowColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>                      colLabels<span class="op">=</span>evaluation_metrics,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>                      colColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>                      loc<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight cells with minimum value in each column</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col_idx, metric <span class="kw">in</span> <span class="bu">enumerate</span>(evaluation_metrics):</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    col_values <span class="op">=</span> [row[col_idx] <span class="cf">for</span> row <span class="kw">in</span> model_scores]</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    min_value_idx <span class="op">=</span> col_values.index(<span class="bu">min</span>(col_values))</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight the cell with minimum value in coral color</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    table1[min_value_idx <span class="op">+</span> <span class="dv">1</span>, col_idx].set_facecolor(<span class="st">"coral"</span>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>table1.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>table1.set_fontsize(<span class="dv">14</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>table1.scale(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-23-output-1.png" width="950" height="662"></p>
</div>
</div>
<p>Once again, we analyze the difference between the actual and predicted values for the regression task by each model on 3 randomly chosen data points.</p>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># printing how far the predicted value is to the actual value for a random row in X</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))<span class="op">;</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>length <span class="op">=</span> <span class="bu">len</span>(model_names[<span class="dv">4</span>:])</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> random.randint(<span class="dv">0</span>,<span class="bu">len</span>(y_test)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(length), [(y_test.values)[idx]]<span class="op">*</span>length, label<span class="op">=</span><span class="st">'True Value'</span>)<span class="op">;</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    plt.scatter(<span class="bu">range</span>(length), [y_preds[q][idx] <span class="cf">for</span> q <span class="kw">in</span> <span class="bu">range</span>(length)], label<span class="op">=</span><span class="st">'Predicted Values'</span>)<span class="op">;</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(length):</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        plt.plot([j, j], [(y_test.values)[idx], y_preds[j][idx]], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(length), model_names[<span class="dv">4</span>:])</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-24-output-1.png" width="945" height="469"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-24-output-2.png" width="945" height="661"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Regression_files/figure-html/cell-24-output-3.png" width="940" height="661"></p>
</div>
</div>
<p>From this blog, we get a glimpse into the performance and approach to applying the appropriate based on the type of dataset at hand.</p>


<!-- -->


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Regression Analysis: Linear Regression and Non-Linear Regression"</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Anushka S"</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-12-03"</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Regression, Machine Learning, Supervised Learning, SVM, Random Forest, Decision Tree, Gradient Boost, Linear, Non-Linear]</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Supervised learning</span><span class="co">](https://www.ibm.com/topics/supervised-learning#:~:text=Supervised%20learning%2C%20also%20known%20as,data%20or%20predict%20outcomes%20accurately.)</span>, also known as supervised machine learning, is a subcategory of machine learning and artificial intelligence. It is defined by its use of labeled datasets to train algorithms that to classify data or predict outcomes accurately.</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>Machine Learning Regression is a technique for investigating the relationship between independent variables or features and a dependent variable or outcome. It’s used as a method for predictive modelling in machine learning, in which an algorithm is used to predict continuous outcomes. You can read more about it <span class="co">[</span><span class="ot">here!</span><span class="co">](https://www.seldon.io/machine-learning-regression-explained#:~:text=Machine%20Learning%20Regression%20is%20a,used%20to%20predict%20continuous%20outcomes.)</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>In this blog, we will discuss two types of regression problems, Linear Regression, and Non-Linear Regression. For each, we will compare a handful of machine learning models (linear and non-linear models) and present their results on evaluation metrics.</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>**Linear Regression**</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>This form of analysis estimates the coefficients of the linear equation, involving one or more independent variables that best predict the value of the dependent variable. Linear regression fits a straight line or surface that minimizes the discrepancies between predicted and actual output values.</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>We'll make use of the <span class="co">[</span><span class="ot">Seoul Bike Sharing dataset</span><span class="co">](https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand)</span> which contains count of public bicycles rented per hour in the Seoul Bike Sharing System, with corresponding weather data and holiday information. </span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. A sample of the dataset can be seen below. </span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>The aim is to predict the bike count required at each hour for the stable supply of rental bikes. </span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>df_bike <span class="op">=</span> pd.read_csv(<span class="st">"SeoulBikeData.csv"</span>)</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>df_bike.head(<span class="dv">5</span>)</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>It is important to check the dataset for any missing values before it is used for model training and testing.</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_bike.info())</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a><span class="co">#check for count of missing values in each column.</span></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_bike.isna().<span class="bu">sum</span>())</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_bike.isnull().<span class="bu">sum</span>())</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>This dataset seems to have no missing values so we're good!</span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>Let's format the dataset to ease data processing down the line. Beginning with breaking down the 'Date' into 'Day', 'Month', and 'Year' columns in the dataset.</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Can break the date into date, month, year columns and convert them into integers (from strings) for the purpose of correlation map</span></span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>days <span class="op">=</span> [<span class="bu">int</span>((df_bike[<span class="st">'Date'</span>].iloc[i])[<span class="dv">0</span>:<span class="dv">2</span>]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_bike))]</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>month <span class="op">=</span> [<span class="bu">int</span>((df_bike[<span class="st">'Date'</span>].iloc[i])[<span class="dv">3</span>:<span class="dv">5</span>]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_bike))]</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>year <span class="op">=</span> [<span class="bu">int</span>((df_bike[<span class="st">'Date'</span>].iloc[i])[<span class="dv">6</span>:]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_bike))]</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>df_bike[<span class="st">'Day'</span>], df_bike[<span class="st">'Month'</span>], df_bike[<span class="st">'Year'</span>] <span class="op">=</span> days, month, year</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>df_bike.head(<span class="dv">5</span>)</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>Next, we convert string values such as the values in the 'Seasons', 'Functioning Day', and 'Holiday' columns. We are able to do this by mapping the discrete set of string values to a discrete set of integer values.</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a>df1_bike <span class="op">=</span> df_bike.drop(columns <span class="op">=</span> [<span class="st">'Date'</span>])</span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a><span class="co"># map unique season to numbers, map holiday to binary, and functioning day to binary</span></span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>seasons <span class="op">=</span> {}</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(df_bike[<span class="st">'Seasons'</span>].drop_duplicates()):</span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>    seasons[i] <span class="op">=</span> idx</span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a>holiday <span class="op">=</span> {<span class="st">"No Holiday"</span>: <span class="dv">0</span>, <span class="st">"Holiday"</span>: <span class="dv">1</span>}</span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>functioning <span class="op">=</span> {<span class="st">"Yes"</span>: <span class="dv">0</span>, <span class="st">"No"</span>: <span class="dv">1</span>}</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>df1_bike.Holiday <span class="op">=</span> [holiday[item] <span class="cf">for</span> item <span class="kw">in</span> df_bike.Holiday]</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>df1_bike.Seasons <span class="op">=</span> [seasons[item] <span class="cf">for</span> item <span class="kw">in</span> df_bike.Seasons]</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>df1_bike[<span class="st">'Functioning Day'</span>] <span class="op">=</span> [functioning[item] <span class="cf">for</span> item <span class="kw">in</span> df1_bike[<span class="st">'Functioning Day'</span>] ]</span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>df1_bike.head(<span class="dv">3</span>)</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a>Plotting the correlation matrix to identify the relationship, and the strength of relationship between the features(variables) in the dataset and also understand how strongly they are correlated with the target variable which is the rented bike count.</span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>f, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> df1_bike.corr()</span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr,</span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span>sns.diverging_palette(<span class="dv">220</span>, <span class="dv">10</span>, as_cmap<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>    vmin<span class="op">=-</span><span class="fl">1.0</span>, vmax<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>    square<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a>Below, we can plot visualizations to see how each feature (variable) effects the target: Rented Bike Count.</span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))<span class="op">;</span></span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a><span class="co"># hour vs bike count</span></span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Hour'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">0</span>][<span class="dv">0</span>], palette<span class="op">=</span><span class="st">'viridis'</span>)<span class="op">;</span></span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>][<span class="dv">0</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Hour'</span>)<span class="op">;</span></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Functioning vs bike count</span></span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Functioning Day'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">0</span>][<span class="dv">1</span>], palette<span class="op">=</span><span class="st">'inferno'</span>)<span class="op">;</span></span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>][<span class="dv">1</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Functioning Day'</span>)<span class="op">;</span></span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>][<span class="dv">1</span>].set_xticklabels([<span class="st">'Yes'</span>, <span class="st">'No'</span>])</span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a><span class="co"># season vs bike count</span></span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Seasons'</span>, y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">1</span>][<span class="dv">0</span>], palette<span class="op">=</span><span class="st">'plasma'</span>)<span class="op">;</span></span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>][<span class="dv">0</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Seasons'</span>)<span class="op">;</span></span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>][<span class="dv">0</span>].set_xticklabels([<span class="st">'Winter'</span>, <span class="st">'Spring'</span>, <span class="st">'Summer'</span>, <span class="st">'Autumn'</span>])</span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a><span class="co"># month vs bike count</span></span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Month'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,ax<span class="op">=</span>ax[<span class="dv">1</span>][<span class="dv">1</span>], palette<span class="op">=</span><span class="st">'cividis'</span>)<span class="op">;</span></span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>][<span class="dv">1</span>].<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Month '</span>)<span class="op">;</span></span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a>fig,ax<span class="op">=</span>plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>sns.pointplot(data<span class="op">=</span>df1_bike,x<span class="op">=</span><span class="st">'Hour'</span>,y<span class="op">=</span><span class="st">'Rented Bike Count'</span>,hue<span class="op">=</span><span class="st">'Seasons'</span>,ax<span class="op">=</span>ax)<span class="op">;</span></span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to seasons and hour of the day'</span>)<span class="op">;</span></span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))<span class="op">;</span></span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a><span class="co"># temperature vs bike count</span></span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert temperature in groups of 5C and average the rented bike counts for that range (rounding to 5s)</span></span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>temp_min, temp_max <span class="op">=</span> <span class="bu">round</span>(<span class="bu">min</span>(df1_bike[<span class="st">'Temperature(C)'</span>])<span class="op">/</span><span class="dv">5</span>)<span class="op">*</span><span class="dv">5</span>, <span class="bu">round</span>(<span class="bu">max</span>(df1_bike[<span class="st">'Temperature(C)'</span>])<span class="op">/</span><span class="dv">5</span>)<span class="op">*</span><span class="dv">5</span></span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a>dict_temp <span class="op">=</span> {}</span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(temp_min, temp_max, <span class="dv">5</span>):</span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter rows based on the temperature interval</span></span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a>    filtered_df <span class="op">=</span> df1_bike[(df1_bike[<span class="st">'Temperature(C)'</span>] <span class="op">&gt;=</span> i) <span class="op">&amp;</span> (df1_bike[<span class="st">'Temperature(C)'</span>] <span class="op">&lt;</span> i<span class="op">+</span><span class="dv">5</span>)]</span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a>    dict_temp[i] <span class="op">=</span> filtered_df[<span class="st">'Rented Bike Count'</span>].mean()</span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a><span class="co"># print(dict_temp)</span></span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a><span class="co"># print(temp_max, temp_min)</span></span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>dict_temp,ax<span class="op">=</span>ax, palette<span class="op">=</span><span class="st">'plasma'</span>)<span class="op">;</span></span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Count of Rented bikes acording to Temperature'</span>)<span class="op">;</span></span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a>Printing the regression plot (Dependent Features vs Target Varibale).</span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a>fig,ax<span class="op">=</span>plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>)) <span class="co"># since we know there are 16 features</span></span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, col <span class="kw">in</span> <span class="bu">enumerate</span>(df1_bike.columns):</span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a>  sns.regplot(x<span class="op">=</span>df1_bike[col],y<span class="op">=</span>df1_bike[<span class="st">'Rented Bike Count'</span>],scatter_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">'blue'</span>}, line_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"black"</span>}, ax<span class="op">=</span>ax[idx<span class="op">//</span><span class="dv">4</span>][idx<span class="op">%</span><span class="dv">4</span>])</span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a>To train and evaluate the machine learning models we need to split the dataset appropriately into the training and testing datasets.</span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a>Hence, we perform an 80-20 train-test split here.</span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df1_bike[<span class="st">'Rented Bike Count'</span>]</span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> (df1_bike.drop(columns <span class="op">=</span> [<span class="st">'Rented Bike Count'</span>])).to_numpy()</span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a>The following are the models used for estimating the number of bikes rented given other data.</span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a>The code implementations for each can be found in the scikit-learn library (linked for each model), and the model paramters used are default parameters.</span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>*Linear regression model*</span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Linear regression</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)</span> is a simple yet powerful algorithm that models the relationship between the input features and the target variable by fitting a linear equation to the observed data. The main algorithm involves finding the coefficients that minimize the sum of squared differences between the predicted and actual values. This is typically achieved using the Ordinary Least Squares (OLS) method, aiming to optimize the line's parameters to best represent the data points.</span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>*Support Vector Machine (Regressor)*</span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a>In regression tasks, <span class="co">[</span><span class="ot">Support Vector Machines</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)</span> (SVM) aim to find the hyperplane that best represents the relationship between the input features and the target variable. The primary algorithm involves identifying the support vectors and determining the optimal hyperplane to maximize the margin while minimizing the error. SVM uses a loss function that penalizes deviations from the regression line, and the algorithm seeks to find the coefficients that minimize this loss.</span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>*Ridge Regression*</span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Ridge Regression</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)</span> is an extension of linear regression that introduces a regularization term to prevent overfitting. The main algorithm involves adding a penalty term to the linear regression objective function, which is proportional to the square of the L2 norm of the coefficients. This regularization term helps stabilize the model by shrinking the coefficients, particularly useful when dealing with multicollinearity.</span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>*Lasso Regression*</span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Lasso Regression</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)</span>, similar to Ridge Regression, introduces regularization to linear regression. The main algorithm incorporates a penalty term, but in this case, it is proportional to the absolute value of the L1 norm of the coefficients. Lasso regression is effective for feature selection as it tends to produce sparse coefficient vectors, driving some coefficients to exactly zero.</span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>*Gradient Boosting Regressor*</span>
<span id="cb26-194"><a href="#cb26-194" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Gradient Boosting Regressor</span><span class="co">](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html)</span> is an ensemble learning method that builds a series of decision trees sequentially. The main algorithm involves fitting a weak learner (usually a shallow decision tree) to the residuals of the previous trees. The predictions of individual trees are combined to improve overall accuracy. The algorithm minimizes a loss function by adjusting the weights of the weak learners.</span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>*Random Forest Regressor*</span>
<span id="cb26-197"><a href="#cb26-197" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Random Forest Regressor</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)</span> is an ensemble learning method that constructs multiple decision trees during training. The main algorithm involves training each tree on a random subset of the training data and features. The predictions of individual trees are then averaged or aggregated to reduce overfitting and improve generalization. Random Forest leverages the diversity among trees for robust predictions.</span>
<span id="cb26-198"><a href="#cb26-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>*Decision Tree Regressor*</span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Decision Tree Regressor</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)</span> models the relationship between input features and the target variable by recursively splitting the data based on feature thresholds. The main algorithm involves selecting the best split at each node to minimize the variance of the target variable. Decision trees are constructed until a stopping criterion is met, creating a tree structure that facilitates predictive modeling.</span>
<span id="cb26-201"><a href="#cb26-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-202"><a href="#cb26-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-205"><a href="#cb26-205" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-206"><a href="#cb26-206" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-207"><a href="#cb26-207" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb26-208"><a href="#cb26-208" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb26-209"><a href="#cb26-209" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> linear_model</span>
<span id="cb26-210"><a href="#cb26-210" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb26-211"><a href="#cb26-211" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb26-212"><a href="#cb26-212" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb26-213"><a href="#cb26-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-214"><a href="#cb26-214" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score, explained_variance_score</span>
<span id="cb26-215"><a href="#cb26-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-216"><a href="#cb26-216" aria-hidden="true" tabindex="-1"></a>model_names <span class="op">=</span> [<span class="st">'Linear Regression Model'</span>,</span>
<span id="cb26-217"><a href="#cb26-217" aria-hidden="true" tabindex="-1"></a> <span class="st">'Support Vector Machine (Regression)'</span>,</span>
<span id="cb26-218"><a href="#cb26-218" aria-hidden="true" tabindex="-1"></a> <span class="st">'Ridge Regression'</span>,</span>
<span id="cb26-219"><a href="#cb26-219" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Lasso Regression'</span>,</span>
<span id="cb26-220"><a href="#cb26-220" aria-hidden="true" tabindex="-1"></a> <span class="st">'Gradient Boosting Regression'</span>,</span>
<span id="cb26-221"><a href="#cb26-221" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Random Forest'</span>,</span>
<span id="cb26-222"><a href="#cb26-222" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Decision Tree'</span>]</span>
<span id="cb26-223"><a href="#cb26-223" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [LinearRegression(),</span>
<span id="cb26-224"><a href="#cb26-224" aria-hidden="true" tabindex="-1"></a>    SVR(), </span>
<span id="cb26-225"><a href="#cb26-225" aria-hidden="true" tabindex="-1"></a>    linear_model.Ridge(), </span>
<span id="cb26-226"><a href="#cb26-226" aria-hidden="true" tabindex="-1"></a>    linear_model.Lasso(),</span>
<span id="cb26-227"><a href="#cb26-227" aria-hidden="true" tabindex="-1"></a>    GradientBoostingRegressor(),</span>
<span id="cb26-228"><a href="#cb26-228" aria-hidden="true" tabindex="-1"></a>    RandomForestRegressor(),</span>
<span id="cb26-229"><a href="#cb26-229" aria-hidden="true" tabindex="-1"></a>    DecisionTreeRegressor()]</span>
<span id="cb26-230"><a href="#cb26-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-231"><a href="#cb26-231" aria-hidden="true" tabindex="-1"></a>evaluation_metrics <span class="op">=</span> [<span class="st">'Mean Squared Error (MSE)'</span>,</span>
<span id="cb26-232"><a href="#cb26-232" aria-hidden="true" tabindex="-1"></a> <span class="st">'Root MSE (RMSE)'</span>,</span>
<span id="cb26-233"><a href="#cb26-233" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Mean Absolute Error'</span>,</span>
<span id="cb26-234"><a href="#cb26-234" aria-hidden="true" tabindex="-1"></a>  <span class="st">'R2 Score'</span>, </span>
<span id="cb26-235"><a href="#cb26-235" aria-hidden="true" tabindex="-1"></a>  <span class="st">'Explained Variance Score'</span>]</span>
<span id="cb26-236"><a href="#cb26-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-237"><a href="#cb26-237" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-238"><a href="#cb26-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-239"><a href="#cb26-239" aria-hidden="true" tabindex="-1"></a>The model is fit on the training data, and predicted for the testing data. Regression models are commonly evaluated on the following metrics:</span>
<span id="cb26-240"><a href="#cb26-240" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>*Mean Squared Error (MSE)*: MSE calculates the average squared difference between the predicted and actual values, providing a measure of the model's precision.</span>
<span id="cb26-241"><a href="#cb26-241" aria-hidden="true" tabindex="-1"></a>$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$</span>
<span id="cb26-242"><a href="#cb26-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-243"><a href="#cb26-243" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>*Root Mean Squared Error (RMSE)*: RMSE is the square root of MSE and represents the average magnitude of the residuals in the same units as the target variable.</span>
<span id="cb26-244"><a href="#cb26-244" aria-hidden="true" tabindex="-1"></a>$ \text{RMSE} = \sqrt{\text{MSE}}$</span>
<span id="cb26-245"><a href="#cb26-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-246"><a href="#cb26-246" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>*Mean Absolute Error (MAE)*: MAE calculates the average absolute difference between the predicted and actual values, providing a measure of the model's accuracy.</span>
<span id="cb26-247"><a href="#cb26-247" aria-hidden="true" tabindex="-1"></a>$ \text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$</span>
<span id="cb26-248"><a href="#cb26-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-249"><a href="#cb26-249" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>*R2 Score*: R2 Score, or the coefficient of determination, measures the proportion of the variance in the dependent variable that is predictable from the independent variables.</span>
<span id="cb26-250"><a href="#cb26-250" aria-hidden="true" tabindex="-1"></a>$ R^2 = 1 - \frac{\text{SSR}}{\text{SST}} where \text{SSR} is the sum of squared residuals, and \text{SST} is the total sum of squares.$</span>
<span id="cb26-251"><a href="#cb26-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-252"><a href="#cb26-252" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>*Explained Variance Score*: The Explained Variance Score measures the proportion by which the model's variance is reduced compared to a simple mean baseline.</span>
<span id="cb26-253"><a href="#cb26-253" aria-hidden="true" tabindex="-1"></a>$ \text{Explained Variance} = 1 - \frac{\text{Var}(y - \hat{y})}{\text{Var}(y)} where where y is the actual values and \hat{y} is the predicted values$</span>
<span id="cb26-254"><a href="#cb26-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-257"><a href="#cb26-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-258"><a href="#cb26-258" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-259"><a href="#cb26-259" aria-hidden="true" tabindex="-1"></a>y_preds <span class="op">=</span> [] <span class="co"># list of model predictions</span></span>
<span id="cb26-260"><a href="#cb26-260" aria-hidden="true" tabindex="-1"></a>model_scores <span class="op">=</span> [] <span class="co"># list of model scores based on the evaluation metrics defined</span></span>
<span id="cb26-261"><a href="#cb26-261" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> models:</span>
<span id="cb26-262"><a href="#cb26-262" aria-hidden="true" tabindex="-1"></a>    reg <span class="op">=</span> model</span>
<span id="cb26-263"><a href="#cb26-263" aria-hidden="true" tabindex="-1"></a>    reg.fit(X_train, y_train)</span>
<span id="cb26-264"><a href="#cb26-264" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb26-265"><a href="#cb26-265" aria-hidden="true" tabindex="-1"></a>    y_preds.append(y_pred)</span>
<span id="cb26-266"><a href="#cb26-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-267"><a href="#cb26-267" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_test.values, y_pred)</span>
<span id="cb26-268"><a href="#cb26-268" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb26-269"><a href="#cb26-269" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test.values, y_pred)</span>
<span id="cb26-270"><a href="#cb26-270" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test.values, y_pred)</span>
<span id="cb26-271"><a href="#cb26-271" aria-hidden="true" tabindex="-1"></a>    evs <span class="op">=</span> explained_variance_score(y_test.values, y_pred)</span>
<span id="cb26-272"><a href="#cb26-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-273"><a href="#cb26-273" aria-hidden="true" tabindex="-1"></a>    model_scores.append([mse, rmse, mae, r2, evs])</span>
<span id="cb26-274"><a href="#cb26-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-275"><a href="#cb26-275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-276"><a href="#cb26-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-277"><a href="#cb26-277" aria-hidden="true" tabindex="-1"></a>Let us visualize the outputs of the linear models 'Linear Regression Model','Support Vector Machine (Regression)',</span>
<span id="cb26-278"><a href="#cb26-278" aria-hidden="true" tabindex="-1"></a>'Ridge Regression', and 'Lasso Regression'. and evaluate the results.</span>
<span id="cb26-281"><a href="#cb26-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-282"><a href="#cb26-282" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> [<span class="dv">10</span>,<span class="dv">7</span>]</span>
<span id="cb26-283"><a href="#cb26-283" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-284"><a href="#cb26-284" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb26-285"><a href="#cb26-285" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'tight'</span>)</span>
<span id="cb26-286"><a href="#cb26-286" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'off'</span>)</span>
<span id="cb26-287"><a href="#cb26-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-288"><a href="#cb26-288" aria-hidden="true" tabindex="-1"></a>table1 <span class="op">=</span> axs.table(cellText<span class="op">=</span>model_scores[<span class="dv">0</span>:<span class="dv">4</span>],</span>
<span id="cb26-289"><a href="#cb26-289" aria-hidden="true" tabindex="-1"></a>                      cellLoc <span class="op">=</span> <span class="st">'left'</span>,</span>
<span id="cb26-290"><a href="#cb26-290" aria-hidden="true" tabindex="-1"></a>                      rowLabels <span class="op">=</span> model_names[<span class="dv">0</span>:<span class="dv">4</span>],</span>
<span id="cb26-291"><a href="#cb26-291" aria-hidden="true" tabindex="-1"></a>                      rowColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb26-292"><a href="#cb26-292" aria-hidden="true" tabindex="-1"></a>                      colLabels<span class="op">=</span>evaluation_metrics,</span>
<span id="cb26-293"><a href="#cb26-293" aria-hidden="true" tabindex="-1"></a>                      colColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb26-294"><a href="#cb26-294" aria-hidden="true" tabindex="-1"></a>                      loc<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb26-295"><a href="#cb26-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-296"><a href="#cb26-296" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight cells with minimum value in each column</span></span>
<span id="cb26-297"><a href="#cb26-297" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col_idx, metric <span class="kw">in</span> <span class="bu">enumerate</span>(evaluation_metrics):</span>
<span id="cb26-298"><a href="#cb26-298" aria-hidden="true" tabindex="-1"></a>    col_values <span class="op">=</span> [row[col_idx] <span class="cf">for</span> row <span class="kw">in</span> model_scores[<span class="dv">0</span>:<span class="dv">4</span>]]</span>
<span id="cb26-299"><a href="#cb26-299" aria-hidden="true" tabindex="-1"></a>    min_value_idx <span class="op">=</span> col_values.index(<span class="bu">min</span>(col_values))</span>
<span id="cb26-300"><a href="#cb26-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-301"><a href="#cb26-301" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight the cell with minimum value in coral color</span></span>
<span id="cb26-302"><a href="#cb26-302" aria-hidden="true" tabindex="-1"></a>    table1[min_value_idx <span class="op">+</span> <span class="dv">1</span>, col_idx].set_facecolor(<span class="st">"coral"</span>)</span>
<span id="cb26-303"><a href="#cb26-303" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-304"><a href="#cb26-304" aria-hidden="true" tabindex="-1"></a>table1.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb26-305"><a href="#cb26-305" aria-hidden="true" tabindex="-1"></a>table1.set_fontsize(<span class="dv">14</span>)</span>
<span id="cb26-306"><a href="#cb26-306" aria-hidden="true" tabindex="-1"></a>table1.scale(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb26-307"><a href="#cb26-307" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb26-308"><a href="#cb26-308" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-309"><a href="#cb26-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-310"><a href="#cb26-310" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-311"><a href="#cb26-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-312"><a href="#cb26-312" aria-hidden="true" tabindex="-1"></a>Now, let us compare the performance of the linear models against non linear models on Linear Regression.</span>
<span id="cb26-315"><a href="#cb26-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-316"><a href="#cb26-316" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">7</span>]</span>
<span id="cb26-317"><a href="#cb26-317" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-318"><a href="#cb26-318" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb26-319"><a href="#cb26-319" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'tight'</span>)</span>
<span id="cb26-320"><a href="#cb26-320" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'off'</span>)</span>
<span id="cb26-321"><a href="#cb26-321" aria-hidden="true" tabindex="-1"></a>table2 <span class="op">=</span> axs.table(cellText<span class="op">=</span>model_scores,</span>
<span id="cb26-322"><a href="#cb26-322" aria-hidden="true" tabindex="-1"></a>                      cellLoc <span class="op">=</span> <span class="st">'left'</span>,</span>
<span id="cb26-323"><a href="#cb26-323" aria-hidden="true" tabindex="-1"></a>                      rowLabels <span class="op">=</span> model_names,</span>
<span id="cb26-324"><a href="#cb26-324" aria-hidden="true" tabindex="-1"></a>                      rowColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb26-325"><a href="#cb26-325" aria-hidden="true" tabindex="-1"></a>                      colLabels<span class="op">=</span>evaluation_metrics,</span>
<span id="cb26-326"><a href="#cb26-326" aria-hidden="true" tabindex="-1"></a>                      colColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb26-327"><a href="#cb26-327" aria-hidden="true" tabindex="-1"></a>                      loc<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb26-328"><a href="#cb26-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-329"><a href="#cb26-329" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight cells with minimum value in each column</span></span>
<span id="cb26-330"><a href="#cb26-330" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col_idx, metric <span class="kw">in</span> <span class="bu">enumerate</span>(evaluation_metrics):</span>
<span id="cb26-331"><a href="#cb26-331" aria-hidden="true" tabindex="-1"></a>    col_values <span class="op">=</span> [row[col_idx] <span class="cf">for</span> row <span class="kw">in</span> model_scores]</span>
<span id="cb26-332"><a href="#cb26-332" aria-hidden="true" tabindex="-1"></a>    min_value_idx <span class="op">=</span> col_values.index(<span class="bu">min</span>(col_values))</span>
<span id="cb26-333"><a href="#cb26-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-334"><a href="#cb26-334" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight the cell with minimum value in coral color</span></span>
<span id="cb26-335"><a href="#cb26-335" aria-hidden="true" tabindex="-1"></a>    table2[min_value_idx <span class="op">+</span> <span class="dv">1</span>, col_idx].set_facecolor(<span class="st">"coral"</span>)</span>
<span id="cb26-336"><a href="#cb26-336" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-337"><a href="#cb26-337" aria-hidden="true" tabindex="-1"></a>table2.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb26-338"><a href="#cb26-338" aria-hidden="true" tabindex="-1"></a>table2.set_fontsize(<span class="dv">14</span>)</span>
<span id="cb26-339"><a href="#cb26-339" aria-hidden="true" tabindex="-1"></a>table2.scale(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb26-340"><a href="#cb26-340" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb26-341"><a href="#cb26-341" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-342"><a href="#cb26-342" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-343"><a href="#cb26-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-344"><a href="#cb26-344" aria-hidden="true" tabindex="-1"></a>As we can see, non-linear models, due to their complex structure and abilty to map and analyze/learn from complex data, perform better on this task. However, it is not always that non-linear models are better than linear models since we must keep in mind the computational expense and efficiency of a model for a task, as well as the <span class="co">[</span><span class="ot">bias-variance</span><span class="co">](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html)</span> tradeoff which again, is dependent not only on the model but also on the dataset/application at hand.</span>
<span id="cb26-345"><a href="#cb26-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-346"><a href="#cb26-346" aria-hidden="true" tabindex="-1"></a>Analysing the difference between the actual and predicted values for the regression task by each model on 3 randomly chosen data points.</span>
<span id="cb26-349"><a href="#cb26-349" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-350"><a href="#cb26-350" aria-hidden="true" tabindex="-1"></a><span class="co"># printing how far the predicted value is to the actual value for a random row in X</span></span>
<span id="cb26-351"><a href="#cb26-351" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb26-352"><a href="#cb26-352" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))<span class="op">;</span></span>
<span id="cb26-353"><a href="#cb26-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-354"><a href="#cb26-354" aria-hidden="true" tabindex="-1"></a>length <span class="op">=</span> <span class="bu">len</span>(model_names)</span>
<span id="cb26-355"><a href="#cb26-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-356"><a href="#cb26-356" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb26-357"><a href="#cb26-357" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> random.randint(<span class="dv">0</span>,<span class="bu">len</span>(y_test)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-358"><a href="#cb26-358" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(length), [(y_test.values)[idx]]<span class="op">*</span>length, label<span class="op">=</span><span class="st">'True Value'</span>)<span class="op">;</span></span>
<span id="cb26-359"><a href="#cb26-359" aria-hidden="true" tabindex="-1"></a>    plt.scatter(<span class="bu">range</span>(length), [y_preds[q][idx] <span class="cf">for</span> q <span class="kw">in</span> <span class="bu">range</span>(length)], label<span class="op">=</span><span class="st">'Predicted Values'</span>)<span class="op">;</span></span>
<span id="cb26-360"><a href="#cb26-360" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(length):</span>
<span id="cb26-361"><a href="#cb26-361" aria-hidden="true" tabindex="-1"></a>        plt.plot([j, j], [(y_test.values)[idx], y_preds[j][idx]], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb26-362"><a href="#cb26-362" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(length), model_names)</span>
<span id="cb26-363"><a href="#cb26-363" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb26-364"><a href="#cb26-364" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-365"><a href="#cb26-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-366"><a href="#cb26-366" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-367"><a href="#cb26-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-368"><a href="#cb26-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-369"><a href="#cb26-369" aria-hidden="true" tabindex="-1"></a>**Non Linear Regression**</span>
<span id="cb26-370"><a href="#cb26-370" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Nonlinear regression</span><span class="co">](https://www.mathworks.com/discovery/nonlinear-regression.html)</span> is a statistical technique that helps describe nonlinear relationships in experimental data. Nonlinear regression models are generally assumed to be parametric, where the model is described as a nonlinear equation. Typically machine learning methods are used for non-parametric nonlinear regression.</span>
<span id="cb26-371"><a href="#cb26-371" aria-hidden="true" tabindex="-1"></a>Parametric nonlinear regression models the dependent variable (also called the response) as a function of a combination of nonlinear parameters and one or more independent variables (called predictors). The model can be univariate (single response variable) or multivariate (multiple response variables).The parameters can take the form of an exponential, trigonometric, power, or any other nonlinear function. </span>
<span id="cb26-372"><a href="#cb26-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-373"><a href="#cb26-373" aria-hidden="true" tabindex="-1"></a>The non-linear <span class="co">[</span><span class="ot">dataset</span><span class="co">](https://github.com/Lawrence-Krukrubo)</span> models China's GDP value for each year from 1960-2014. A sample of the dataset and the dataset visualization can be seen below.</span>
<span id="cb26-374"><a href="#cb26-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-377"><a href="#cb26-377" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-378"><a href="#cb26-378" aria-hidden="true" tabindex="-1"></a>df_gdp <span class="op">=</span> pd.read_csv(<span class="st">"China_GDP.csv"</span>)</span>
<span id="cb26-379"><a href="#cb26-379" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_gdp.info())</span>
<span id="cb26-380"><a href="#cb26-380" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_gdp.isna().<span class="bu">sum</span>())</span>
<span id="cb26-381"><a href="#cb26-381" aria-hidden="true" tabindex="-1"></a>df_gdp.head(<span class="dv">5</span>)</span>
<span id="cb26-382"><a href="#cb26-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-383"><a href="#cb26-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-386"><a href="#cb26-386" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-387"><a href="#cb26-387" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-388"><a href="#cb26-388" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Year vs GDP_value</span></span>
<span id="cb26-389"><a href="#cb26-389" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df_gdp, x <span class="op">=</span> <span class="st">'Value'</span>, y <span class="op">=</span> <span class="st">'Year'</span>)<span class="op">;</span></span>
<span id="cb26-390"><a href="#cb26-390" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-391"><a href="#cb26-391" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-392"><a href="#cb26-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-393"><a href="#cb26-393" aria-hidden="true" tabindex="-1"></a>We try to apply a regression line plot for the data. We see that the regression line is not able to accurately capture a linear relationship due to the non-linear relationship between the variables.</span>
<span id="cb26-396"><a href="#cb26-396" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-397"><a href="#cb26-397" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb26-398"><a href="#cb26-398" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression line plot</span></span>
<span id="cb26-399"><a href="#cb26-399" aria-hidden="true" tabindex="-1"></a>sns.regplot(x<span class="op">=</span>df_gdp[<span class="st">'Value'</span>],y<span class="op">=</span>df_gdp[<span class="st">'Year'</span>],scatter_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">'blue'</span>}, line_kws<span class="op">=</span>{<span class="st">"color"</span>: <span class="st">"black"</span>})</span>
<span id="cb26-400"><a href="#cb26-400" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-401"><a href="#cb26-401" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-402"><a href="#cb26-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-403"><a href="#cb26-403" aria-hidden="true" tabindex="-1"></a>Splitting the dataset into 80-20 training-testing set to train and evaluate the aforementioned models. </span>
<span id="cb26-406"><a href="#cb26-406" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-407"><a href="#cb26-407" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb26-408"><a href="#cb26-408" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_gdp[<span class="st">'Year'</span>]</span>
<span id="cb26-409"><a href="#cb26-409" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> (df_gdp.drop(columns <span class="op">=</span> [<span class="st">'Year'</span>])).to_numpy()</span>
<span id="cb26-410"><a href="#cb26-410" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb26-411"><a href="#cb26-411" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-412"><a href="#cb26-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-413"><a href="#cb26-413" aria-hidden="true" tabindex="-1"></a>We can plot the training set points as well as the true test set points and predicted test set points for each model (Linear and Non-Linear) to visualize model accuracy and performance. Again, we see that the linear models struggle to accurately predict the target value for a non-linear dataset.</span>
<span id="cb26-414"><a href="#cb26-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-417"><a href="#cb26-417" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-418"><a href="#cb26-418" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span></span>
<span id="cb26-419"><a href="#cb26-419" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, model <span class="kw">in</span> <span class="bu">enumerate</span>(models[<span class="dv">0</span>:<span class="dv">4</span>]):</span>
<span id="cb26-420"><a href="#cb26-420" aria-hidden="true" tabindex="-1"></a>    reg <span class="op">=</span> model</span>
<span id="cb26-421"><a href="#cb26-421" aria-hidden="true" tabindex="-1"></a>    reg.fit(X_train, y_train)</span>
<span id="cb26-422"><a href="#cb26-422" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb26-423"><a href="#cb26-423" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for training set</span></span>
<span id="cb26-424"><a href="#cb26-424" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].scatter(X_train, y_train, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Train'</span>)<span class="op">;</span></span>
<span id="cb26-425"><a href="#cb26-425" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (true)</span></span>
<span id="cb26-426"><a href="#cb26-426" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].scatter(X_test, y_test, color<span class="op">=</span><span class="st">'purple'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'True'</span>)<span class="op">;</span></span>
<span id="cb26-427"><a href="#cb26-427" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (predicted)</span></span>
<span id="cb26-428"><a href="#cb26-428" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].scatter(X_test, y_pred, color<span class="op">=</span><span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>)<span class="op">;</span></span>
<span id="cb26-429"><a href="#cb26-429" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].set_title(model_names[idx])</span>
<span id="cb26-430"><a href="#cb26-430" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].set_xlabel(<span class="st">"GDP"</span>)</span>
<span id="cb26-431"><a href="#cb26-431" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].set_xlabel(<span class="st">"Year"</span>)</span>
<span id="cb26-432"><a href="#cb26-432" aria-hidden="true" tabindex="-1"></a>    ax[idx<span class="op">//</span><span class="dv">2</span>][idx<span class="op">%</span><span class="dv">2</span>].legend()</span>
<span id="cb26-433"><a href="#cb26-433" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"True vs Predicted Performance of Linear Regression Models"</span>)</span>
<span id="cb26-434"><a href="#cb26-434" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-435"><a href="#cb26-435" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-436"><a href="#cb26-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-437"><a href="#cb26-437" aria-hidden="true" tabindex="-1"></a>However, the complex, non-linear models are able to capture and analyze the non-linearity and predict the target variable value more accurately.</span>
<span id="cb26-440"><a href="#cb26-440" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-441"><a href="#cb26-441" aria-hidden="true" tabindex="-1"></a>y_preds <span class="op">=</span> [] <span class="co"># list of model predictions</span></span>
<span id="cb26-442"><a href="#cb26-442" aria-hidden="true" tabindex="-1"></a>model_scores <span class="op">=</span> [] <span class="co"># list of model scores based on the evaluation metrics defined</span></span>
<span id="cb26-443"><a href="#cb26-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-444"><a href="#cb26-444" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span></span>
<span id="cb26-445"><a href="#cb26-445" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, model <span class="kw">in</span> <span class="bu">enumerate</span>(models[<span class="dv">4</span>:]):</span>
<span id="cb26-446"><a href="#cb26-446" aria-hidden="true" tabindex="-1"></a>    reg <span class="op">=</span> model</span>
<span id="cb26-447"><a href="#cb26-447" aria-hidden="true" tabindex="-1"></a>    reg.fit(X_train, y_train)</span>
<span id="cb26-448"><a href="#cb26-448" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb26-449"><a href="#cb26-449" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for training set</span></span>
<span id="cb26-450"><a href="#cb26-450" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(X_train, y_train, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Train'</span>)<span class="op">;</span></span>
<span id="cb26-451"><a href="#cb26-451" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (true)</span></span>
<span id="cb26-452"><a href="#cb26-452" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(X_test, y_test, color<span class="op">=</span><span class="st">'purple'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'True'</span>)<span class="op">;</span></span>
<span id="cb26-453"><a href="#cb26-453" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data points for testing set (predicted)</span></span>
<span id="cb26-454"><a href="#cb26-454" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(X_test, y_pred, color<span class="op">=</span><span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>)<span class="op">;</span></span>
<span id="cb26-455"><a href="#cb26-455" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_title(model_names[<span class="dv">4</span><span class="op">+</span>idx])</span>
<span id="cb26-456"><a href="#cb26-456" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_xlabel(<span class="st">"GDP"</span>)</span>
<span id="cb26-457"><a href="#cb26-457" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_xlabel(<span class="st">"Year"</span>)</span>
<span id="cb26-458"><a href="#cb26-458" aria-hidden="true" tabindex="-1"></a>    ax[idx].legend()</span>
<span id="cb26-459"><a href="#cb26-459" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-460"><a href="#cb26-460" aria-hidden="true" tabindex="-1"></a>    y_preds.append(y_pred)</span>
<span id="cb26-461"><a href="#cb26-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-462"><a href="#cb26-462" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_test.values, y_pred)</span>
<span id="cb26-463"><a href="#cb26-463" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb26-464"><a href="#cb26-464" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test.values, y_pred)</span>
<span id="cb26-465"><a href="#cb26-465" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test.values, y_pred)</span>
<span id="cb26-466"><a href="#cb26-466" aria-hidden="true" tabindex="-1"></a>    evs <span class="op">=</span> explained_variance_score(y_test.values, y_pred)</span>
<span id="cb26-467"><a href="#cb26-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-468"><a href="#cb26-468" aria-hidden="true" tabindex="-1"></a>    model_scores.append([mse, rmse, mae, r2, evs])</span>
<span id="cb26-469"><a href="#cb26-469" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-470"><a href="#cb26-470" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"True vs Predicted Performance of Non-Linear Regression Models"</span>)</span>
<span id="cb26-471"><a href="#cb26-471" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-472"><a href="#cb26-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-473"><a href="#cb26-473" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-474"><a href="#cb26-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-475"><a href="#cb26-475" aria-hidden="true" tabindex="-1"></a>We chart the model performance for the non-linear models. The models used for non-linear regression are *Random Forest Regressor*, *Decision Tree Regressor*, and *Gradient Boost Regressor*.</span>
<span id="cb26-478"><a href="#cb26-478" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-479"><a href="#cb26-479" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.figsize"</span>] <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">7</span>]</span>
<span id="cb26-480"><a href="#cb26-480" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">"figure.autolayout"</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-481"><a href="#cb26-481" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb26-482"><a href="#cb26-482" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'tight'</span>)</span>
<span id="cb26-483"><a href="#cb26-483" aria-hidden="true" tabindex="-1"></a>axs.axis(<span class="st">'off'</span>)</span>
<span id="cb26-484"><a href="#cb26-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-485"><a href="#cb26-485" aria-hidden="true" tabindex="-1"></a>table1 <span class="op">=</span> axs.table(cellText<span class="op">=</span>model_scores,</span>
<span id="cb26-486"><a href="#cb26-486" aria-hidden="true" tabindex="-1"></a>                      cellLoc <span class="op">=</span> <span class="st">'left'</span>,</span>
<span id="cb26-487"><a href="#cb26-487" aria-hidden="true" tabindex="-1"></a>                      rowLabels <span class="op">=</span> model_names[<span class="dv">4</span>:],</span>
<span id="cb26-488"><a href="#cb26-488" aria-hidden="true" tabindex="-1"></a>                      rowColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb26-489"><a href="#cb26-489" aria-hidden="true" tabindex="-1"></a>                      colLabels<span class="op">=</span>evaluation_metrics,</span>
<span id="cb26-490"><a href="#cb26-490" aria-hidden="true" tabindex="-1"></a>                      colColours<span class="op">=</span> [<span class="st">"palegreen"</span>] <span class="op">*</span> <span class="dv">10</span>,</span>
<span id="cb26-491"><a href="#cb26-491" aria-hidden="true" tabindex="-1"></a>                      loc<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb26-492"><a href="#cb26-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-493"><a href="#cb26-493" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight cells with minimum value in each column</span></span>
<span id="cb26-494"><a href="#cb26-494" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col_idx, metric <span class="kw">in</span> <span class="bu">enumerate</span>(evaluation_metrics):</span>
<span id="cb26-495"><a href="#cb26-495" aria-hidden="true" tabindex="-1"></a>    col_values <span class="op">=</span> [row[col_idx] <span class="cf">for</span> row <span class="kw">in</span> model_scores]</span>
<span id="cb26-496"><a href="#cb26-496" aria-hidden="true" tabindex="-1"></a>    min_value_idx <span class="op">=</span> col_values.index(<span class="bu">min</span>(col_values))</span>
<span id="cb26-497"><a href="#cb26-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-498"><a href="#cb26-498" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight the cell with minimum value in coral color</span></span>
<span id="cb26-499"><a href="#cb26-499" aria-hidden="true" tabindex="-1"></a>    table1[min_value_idx <span class="op">+</span> <span class="dv">1</span>, col_idx].set_facecolor(<span class="st">"coral"</span>)</span>
<span id="cb26-500"><a href="#cb26-500" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-501"><a href="#cb26-501" aria-hidden="true" tabindex="-1"></a>table1.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb26-502"><a href="#cb26-502" aria-hidden="true" tabindex="-1"></a>table1.set_fontsize(<span class="dv">14</span>)</span>
<span id="cb26-503"><a href="#cb26-503" aria-hidden="true" tabindex="-1"></a>table1.scale(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb26-504"><a href="#cb26-504" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb26-505"><a href="#cb26-505" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-506"><a href="#cb26-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-507"><a href="#cb26-507" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-508"><a href="#cb26-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-509"><a href="#cb26-509" aria-hidden="true" tabindex="-1"></a>Once again, we analyze the difference between the actual and predicted values for the regression task by each model on 3 randomly chosen data points.</span>
<span id="cb26-512"><a href="#cb26-512" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-513"><a href="#cb26-513" aria-hidden="true" tabindex="-1"></a><span class="co"># printing how far the predicted value is to the actual value for a random row in X</span></span>
<span id="cb26-514"><a href="#cb26-514" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb26-515"><a href="#cb26-515" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))<span class="op">;</span></span>
<span id="cb26-516"><a href="#cb26-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-517"><a href="#cb26-517" aria-hidden="true" tabindex="-1"></a>length <span class="op">=</span> <span class="bu">len</span>(model_names[<span class="dv">4</span>:])</span>
<span id="cb26-518"><a href="#cb26-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-519"><a href="#cb26-519" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb26-520"><a href="#cb26-520" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> random.randint(<span class="dv">0</span>,<span class="bu">len</span>(y_test)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-521"><a href="#cb26-521" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(length), [(y_test.values)[idx]]<span class="op">*</span>length, label<span class="op">=</span><span class="st">'True Value'</span>)<span class="op">;</span></span>
<span id="cb26-522"><a href="#cb26-522" aria-hidden="true" tabindex="-1"></a>    plt.scatter(<span class="bu">range</span>(length), [y_preds[q][idx] <span class="cf">for</span> q <span class="kw">in</span> <span class="bu">range</span>(length)], label<span class="op">=</span><span class="st">'Predicted Values'</span>)<span class="op">;</span></span>
<span id="cb26-523"><a href="#cb26-523" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(length):</span>
<span id="cb26-524"><a href="#cb26-524" aria-hidden="true" tabindex="-1"></a>        plt.plot([j, j], [(y_test.values)[idx], y_preds[j][idx]], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb26-525"><a href="#cb26-525" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(length), model_names[<span class="dv">4</span>:])</span>
<span id="cb26-526"><a href="#cb26-526" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb26-527"><a href="#cb26-527" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-528"><a href="#cb26-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-529"><a href="#cb26-529" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-530"><a href="#cb26-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-531"><a href="#cb26-531" aria-hidden="true" tabindex="-1"></a>From this blog, we get a glimpse into the performance and approach to applying the appropriate based on the type of dataset at hand.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>